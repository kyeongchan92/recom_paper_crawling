{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e8e19a8-e328-46a7-8c15-d0c3746c544e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.vector_stores.kdbai import KDBAIVectorStore\n",
    "from getpass import getpass\n",
    "import kdbai_client as kdbai\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bc341bf4-fc1e-45db-92d9-b16b234968c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama-parse is async-first, running the async code in a notebook requires the use of nest_asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "# API access to llama-cloud\n",
    "# os.environ[\"LLAMA_CLOUD_API_KEY\"] = os.getenv('LLAMA_CLOUD_API_KEY')\n",
    "\n",
    "KDBAI_ENDPOINT = (os.environ[\"KDBAI_ENDPOINT\"] if \"KDBAI_ENDPOINT\" in os.environ else input(\"KDB.AI endpoint: \"))\n",
    "KDBAI_API_KEY = (os.environ[\"KDBAI_API_KEY\"] if \"KDBAI_API_KEY\" in os.environ else getpass(\"KDB.AI API key: \"))\n",
    "\n",
    "#connect to KDB.AI\n",
    "session = kdbai.Session(api_key=KDBAI_API_KEY, endpoint=KDBAI_ENDPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f7665c95-00d5-4b28-ab74-9f652f72e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect with kdbai database\n",
    "db = session.database(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2323dfcb-70fc-4275-89fb-71c4fabf4b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The schema contains two metadata columns (document_id, text) and one embeddings column\n",
    "schema = [\n",
    "        dict(name=\"document_id\", type=\"str\"),\n",
    "        dict(name=\"text\", type=\"str\"),\n",
    "        dict(name=\"embeddings\", type=\"float32s\"),\n",
    "    ]\n",
    "\n",
    "# indexflat, define the index name, type, column to apply the index to (embeddings)\n",
    "# and params which include thesearch metric (Euclidean distance), and dims\n",
    "indexFlat = {\n",
    "        \"name\": \"flat\",\n",
    "        \"type\": \"flat\",\n",
    "        \"column\": \"embeddings\",\n",
    "        \"params\": {'dims': 1536, 'metric': 'L2'},\n",
    "    }\n",
    "\n",
    "KDBAI_TABLE_NAME = \"LlamaParse_Table\"\n",
    "\n",
    "# First ensure the table does not already exist\n",
    "try:\n",
    "    db.table(KDBAI_TABLE_NAME).drop()\n",
    "except kdbai.KDBAIException:\n",
    "    pass\n",
    "\n",
    "#Create the table\n",
    "table = db.create_table(KDBAI_TABLE_NAME, schema, indexes=[indexFlat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "04bae3a7-f981-4e1c-9ba7-533dfb7aed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL  = \"text-embedding-3-small\"\n",
    "GENERATION_MODEL = \"gpt-4o\"\n",
    "\n",
    "llm = OpenAI(model=GENERATION_MODEL)\n",
    "embed_model = OpenAIEmbedding(model=EMBEDDING_MODEL)\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "pdf_file_name = './MACRec.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a0856908-1e18-4fa6-8016-4c21607d4475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document titled \"LLM In-Context Recall is Prompt Dependent\" is an academic preprint from April 2024, authored by Daniel Machlab and Rick Battle from the VMware NLP Lab. It explores the in-context recall capabilities of Large Language Models (LLMs) using a method called \"needle-in-a-haystack,\" where a specific factoid is embedded in a block of unrelated text. The study investigates how the recall performance of various LLMs is influenced by the content of prompts and the biases in their training data. The research involves testing multiple LLMs with varying context window sizes to assess their ability to recall information accurately when prompted differently. The paper includes detailed methodologies, results from numerous tests, discussions on the impact of prompt variations and training data, and conclusions on improving LLM utility in practical applications. It contains many tables. Answer questions using the information in this article and be precise.\n"
     ]
    }
   ],
   "source": [
    "parsing_instructions = '''The document titled \"LLM In-Context Recall is Prompt Dependent\" is an academic preprint from April 2024, authored by Daniel Machlab and Rick Battle from the VMware NLP Lab. It explores the in-context recall capabilities of Large Language Models (LLMs) using a method called \"needle-in-a-haystack,\" where a specific factoid is embedded in a block of unrelated text. The study investigates how the recall performance of various LLMs is influenced by the content of prompts and the biases in their training data. The research involves testing multiple LLMs with varying context window sizes to assess their ability to recall information accurately when prompted differently. The paper includes detailed methodologies, results from numerous tests, discussions on the impact of prompt variations and training data, and conclusions on improving LLM utility in practical applications. It contains many tables. Answer questions using the information in this article and be precise.'''\n",
    "print(parsing_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "76375284-1cc9-41b2-8852-9099239c4211",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 22a50657-dbcc-4c0b-9b0f-b8c13410cbe4\n"
     ]
    }
   ],
   "source": [
    "documents = LlamaParse(\n",
    "    result_type=\"markdown\", \n",
    "    parsing_instructions=parsing_instructions\n",
    ").load_data(pdf_file_name)\n",
    "# print(documents[0].text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "adc4634d-1439-40b1-b19e-13e567dffb21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i, doc in enumerate(documents, start=1):\n",
    "#     print(f\"{i}\".ljust(100, '-'))\n",
    "#     print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "66f86e59-e556-46cf-804f-8c2ed540741d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 23831.27it/s]\n",
      "1it [00:00, 17772.47it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Parse the documents using MarkdownElementNodeParser\n",
    "node_parser = MarkdownElementNodeParser(llm=llm, num_workers=8).from_defaults()\n",
    "\n",
    "# Retrieve nodes (text) and objects (table)\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "\n",
    "base_nodes, objects = node_parser.get_nodes_and_objects(nodes)\n",
    "\n",
    "# insert the table markdown into the text of each table object\n",
    "for i in range(len(objects)):\n",
    "  objects[i].text = objects[i].obj.text[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "13911fe1-e63d-49fd-b52e-3c75aad09b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356031b0-c77b-4d03-b2b9-555873bffdcc</td>\n",
       "      <td>MACRec: a Multi-Agent Collaboration Framework ...</td>\n",
       "      <td>[-0.0006405428, 0.043710317, 0.023421837, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6d6f1a20-f4c9-405f-bd93-2845a76bcc49</td>\n",
       "      <td>SIGIR ’24, July 14–18, 2024, Washington, DC, U...</td>\n",
       "      <td>[-0.0015050154, 0.035147697, 0.057046, 0.03038...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e7342dbe-cc04-462e-9bfb-eacd86ac6aca</td>\n",
       "      <td>Varying requirements for agents in different s...</td>\n",
       "      <td>[-0.00798005, 0.036461584, 0.043508563, 0.0049...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8caf5599-cf3b-45b6-9362-48371014407c</td>\n",
       "      <td>MACRec: a Multi-Agent Collaboration Framework ...</td>\n",
       "      <td>[-0.015942669, 0.057838522, 0.025760388, 0.002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4ec65281-8b81-4c32-a253-f618d4f27438</td>\n",
       "      <td>3.2.4 Searcher\\n\\nThe Searcher is responsible ...</td>\n",
       "      <td>[-0.018861674, 0.062203117, 0.015368288, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bc48bf62-58de-48d1-b58c-07e1f2ddaf76</td>\n",
       "      <td>Table 2: The agents’ selection for four applic...</td>\n",
       "      <td>[-0.016511856, 0.039699007, 0.07511063, 0.0198...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24918e1a-a405-4731-a68f-bcb70d9fa171</td>\n",
       "      <td>SIGIR ’24, July 14–18, 2024, Washington, DC, U...</td>\n",
       "      <td>[-0.025750577, 0.043229405, -0.009879337, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>229db0a6-d1c8-4e52-ada9-1f90cbacb251</td>\n",
       "      <td>The number of relevant items in the sequence i...</td>\n",
       "      <td>[-0.0059832996, 0.05207999, 0.013652036, 0.005...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2d87fe8c-fec1-48e5-9b8e-d6095f712c89</td>\n",
       "      <td>MACRec: a Multi-Agent Collaboration Framework ...</td>\n",
       "      <td>[-0.025487937, 0.009967705, 0.06465233, 0.0219...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b28069b7-3869-4ec2-9657-8c82ebdb404b</td>\n",
       "      <td>arXiv preprint arXiv:2308.09904 (2023).\\n12. P...</td>\n",
       "      <td>[-0.0062998543, 0.022451159, 0.04597343, 0.013...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>128b4088-b4f5-493a-99e6-4a49d25975e3</td>\n",
       "      <td>2022. Glm-130b: An open bilingual pre-trained ...</td>\n",
       "      <td>[-0.0017179978, -0.0010304812, 0.04113033, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>46ce82bd-a699-4e05-bcff-ffe8f34ef809</td>\n",
       "      <td>This table compares different models based on ...</td>\n",
       "      <td>[-0.048660647, 0.032023102, 0.05525446, -0.017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>d1a0df39-0d1c-44c5-9b95-b4e826b64670</td>\n",
       "      <td>The table outlines various tasks and their cor...</td>\n",
       "      <td>[-0.035323337, 0.068580985, 0.053885058, -0.02...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             document_id  \\\n",
       "0   356031b0-c77b-4d03-b2b9-555873bffdcc   \n",
       "1   6d6f1a20-f4c9-405f-bd93-2845a76bcc49   \n",
       "2   e7342dbe-cc04-462e-9bfb-eacd86ac6aca   \n",
       "3   8caf5599-cf3b-45b6-9362-48371014407c   \n",
       "4   4ec65281-8b81-4c32-a253-f618d4f27438   \n",
       "5   bc48bf62-58de-48d1-b58c-07e1f2ddaf76   \n",
       "6   24918e1a-a405-4731-a68f-bcb70d9fa171   \n",
       "7   229db0a6-d1c8-4e52-ada9-1f90cbacb251   \n",
       "8   2d87fe8c-fec1-48e5-9b8e-d6095f712c89   \n",
       "9   b28069b7-3869-4ec2-9657-8c82ebdb404b   \n",
       "10  128b4088-b4f5-493a-99e6-4a49d25975e3   \n",
       "11  46ce82bd-a699-4e05-bcff-ffe8f34ef809   \n",
       "12  d1a0df39-0d1c-44c5-9b95-b4e826b64670   \n",
       "\n",
       "                                                 text  \\\n",
       "0   MACRec: a Multi-Agent Collaboration Framework ...   \n",
       "1   SIGIR ’24, July 14–18, 2024, Washington, DC, U...   \n",
       "2   Varying requirements for agents in different s...   \n",
       "3   MACRec: a Multi-Agent Collaboration Framework ...   \n",
       "4   3.2.4 Searcher\\n\\nThe Searcher is responsible ...   \n",
       "5   Table 2: The agents’ selection for four applic...   \n",
       "6   SIGIR ’24, July 14–18, 2024, Washington, DC, U...   \n",
       "7   The number of relevant items in the sequence i...   \n",
       "8   MACRec: a Multi-Agent Collaboration Framework ...   \n",
       "9   arXiv preprint arXiv:2308.09904 (2023).\\n12. P...   \n",
       "10  2022. Glm-130b: An open bilingual pre-trained ...   \n",
       "11  This table compares different models based on ...   \n",
       "12  The table outlines various tasks and their cor...   \n",
       "\n",
       "                                           embeddings  \n",
       "0   [-0.0006405428, 0.043710317, 0.023421837, 0.02...  \n",
       "1   [-0.0015050154, 0.035147697, 0.057046, 0.03038...  \n",
       "2   [-0.00798005, 0.036461584, 0.043508563, 0.0049...  \n",
       "3   [-0.015942669, 0.057838522, 0.025760388, 0.002...  \n",
       "4   [-0.018861674, 0.062203117, 0.015368288, -0.02...  \n",
       "5   [-0.016511856, 0.039699007, 0.07511063, 0.0198...  \n",
       "6   [-0.025750577, 0.043229405, -0.009879337, 0.00...  \n",
       "7   [-0.0059832996, 0.05207999, 0.013652036, 0.005...  \n",
       "8   [-0.025487937, 0.009967705, 0.06465233, 0.0219...  \n",
       "9   [-0.0062998543, 0.022451159, 0.04597343, 0.013...  \n",
       "10  [-0.0017179978, -0.0010304812, 0.04113033, 0.0...  \n",
       "11  [-0.048660647, 0.032023102, 0.05525446, -0.017...  \n",
       "12  [-0.035323337, 0.068580985, 0.053885058, -0.02...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store = KDBAIVectorStore(table)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "#Create the index, inserts base_nodes and objects into KDB.AI\n",
    "recursive_index = VectorStoreIndex(\n",
    "    nodes= base_nodes + objects, storage_context=storage_context\n",
    ")\n",
    "\n",
    "# Query KDB.AI to ensure the nodes were inserted\n",
    "table.query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7c20dd18-5cdd-466b-867f-7b9b710dae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def embed_query(query):\n",
    "    query_embedding = client.embeddings.create(\n",
    "            input=query,\n",
    "            model=\"text-embedding-3-small\"\n",
    "        )\n",
    "    return query_embedding.data[0].embedding\n",
    "\n",
    "def retrieve_data(query):\n",
    "    query_embedding = embed_query(query)\n",
    "    results = table.search(vectors={'flat':[query_embedding]},n=5,filter=[('<>','document_id','4a9551df-5dec-4410-90bb-43d17d722918')])\n",
    "    retrieved_data_for_RAG = []\n",
    "    for index, row in results[0].iterrows():\n",
    "      retrieved_data_for_RAG.append(row['text'])\n",
    "    return retrieved_data_for_RAG\n",
    "\n",
    "def RAG(query):\n",
    "  question = \"You will answer this question based on the provided reference material: \" + query\n",
    "  messages = \"Here is the provided context: \" + \"\\n\"\n",
    "  results = retrieve_data(query)\n",
    "  if results:\n",
    "    for data in results:\n",
    "      messages += data + \"\\n\"\n",
    "  response = client.chat.completions.create(\n",
    "      model=\"gpt-4o\",\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": question},\n",
    "          {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "              {\"type\": \"text\", \"text\": messages},\n",
    "          ],\n",
    "          }\n",
    "      ],\n",
    "      # max_tokens=300,\n",
    "  )\n",
    "  content = response.choices[0].message.content\n",
    "  return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9646799a-5734-40b1-96e8-9229cc19bb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"needle in a haystack\" method is not specifically described in the provided context. However, based on the Searcher's role described in section 3.2.4 and the Search process outlined under \"APPLICATIONS ON RECOMMENDATION SCENARIOS,\" one could infer that a \"needle in a haystack\" type process involves meticulously searching through a large volume of data (like Wikipedia or other databases) to find the specific, relevant information needed to fulfill a query or recommendation task. In the described framework, the Searcher is tasked with executing targeted queries to retrieve relevant passages or entries, and further narrowing down the search results to directly relevant information to summarize for the Manager. This process resembles finding a \"needle\" (specific information) in a \"haystack\" (large database or set of documents).\n"
     ]
    }
   ],
   "source": [
    "print(RAG(\"describe the needle in a haystack method only using the provided information\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d1f5a8cd-8010-498f-9d02-949eed682c8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "answer = RAG(f\"\"\"Find this paper's References. Give me that References with the given json form. Don't return any other comments except that References\n",
    "\n",
    "EXAMPLE : \n",
    "{{\n",
    "    1 : {{\n",
    "    \"Title\" : \"Language models are few-shot learners\",\n",
    "    \"Author(s)\" : \"Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al\",\n",
    "    \"Conference\" : \"Advances in neural information processing systems 33 (2020), 1877–1901\"\n",
    "    }},\n",
    "    2 : {{\n",
    "        ...\n",
    "    }},\n",
    "    ...\n",
    "}}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "125bf082-3b17-405c-8ab1-6072b9c97573",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_dict = eval(answer.replace(\"```json\\n\", \"\").replace(\"```\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6d9af6a-bb07-44ff-820c-66e0f60be2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scholarly import scholarly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "034ef8de-d27b-4b90-a2cc-4f10eaeaaea6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m search_query \u001b[38;5;241m=\u001b[39m \u001b[43mscholarly\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_pubs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMACRec\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_scholarly.py:160\u001b[0m, in \u001b[0;36m_Scholarly.search_pubs\u001b[0;34m(self, query, patents, citations, year_low, year_high, sort_by, include_last_year, start_index)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Searches by query and returns a generator of Publication objects\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m:param query: terms to be searched\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_url(_PUBSEARCH\u001b[38;5;241m.\u001b[39mformat(requests\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mquote(query)), patents\u001b[38;5;241m=\u001b[39mpatents,\n\u001b[1;32m    158\u001b[0m                           citations\u001b[38;5;241m=\u001b[39mcitations, year_low\u001b[38;5;241m=\u001b[39myear_low, year_high\u001b[38;5;241m=\u001b[39myear_high,\n\u001b[1;32m    159\u001b[0m                           sort_by\u001b[38;5;241m=\u001b[39msort_by, include_last_year\u001b[38;5;241m=\u001b[39minclude_last_year, start_index\u001b[38;5;241m=\u001b[39mstart_index)\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__nav\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_publications\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:296\u001b[0m, in \u001b[0;36mNavigator.search_publications\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msearch_publications\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _SearchScholarIterator:\n\u001b[1;32m    289\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a Publication Generator given a url\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    :param url: the url where publications can be found.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    :rtype: {_SearchScholarIterator}\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_SearchScholarIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/publication_parser.py:53\u001b[0m, in \u001b[0;36m_SearchScholarIterator.__init__\u001b[0;34m(self, nav, url)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pubtype \u001b[38;5;241m=\u001b[39m PublicationSource\u001b[38;5;241m.\u001b[39mPUBLICATION_SEARCH_SNIPPET \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/scholar?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m url \u001b[38;5;28;01melse\u001b[39;00m PublicationSource\u001b[38;5;241m.\u001b[39mJOURNAL_CITATION_LIST\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nav \u001b[38;5;241m=\u001b[39m nav\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_total_results()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_parser \u001b[38;5;241m=\u001b[39m PublicationParser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nav)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/publication_parser.py:59\u001b[0m, in \u001b[0;36m_SearchScholarIterator._load_url\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_load_url\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# this is temporary until setup json file\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nav\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_soup\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgs_r gs_or gs_scl\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsc_mpat_ttl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:239\u001b[0m, in \u001b[0;36mNavigator._get_soup\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_soup\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BeautifulSoup:\n\u001b[1;32m    238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the BeautifulSoup for a page on scholar.google.com\"\"\"\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://scholar.google.com\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     html \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    241\u001b[0m     res \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:132\u001b[0m, in \u001b[0;36mNavigator._get_page\u001b[0;34m(self, pagerequest, premium)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m has_captcha:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot a captcha request.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 132\u001b[0m     session \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_captcha2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpagerequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Retry request within same session\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_proxy_generator.py:422\u001b[0m, in \u001b[0;36mProxyGenerator._handle_captcha2\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    421\u001b[0m     cur \u001b[38;5;241m=\u001b[39m cur \u001b[38;5;241m+\u001b[39m log_interval \u001b[38;5;66;03m# Update before exceptions can happen\u001b[39;00m\n\u001b[0;32m--> 422\u001b[0m     \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_webdriver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil_not\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdrv\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_webdriver_has_captcha\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutException:\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/selenium/webdriver/support/wait.py:127\u001b[0m, in \u001b[0;36mWebDriverWait.until_not\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "search_query = scholarly.search_pubs('MACRec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "656be372-216d-4be9-81f1-46355254c032",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in search_query:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0a3fba2e-1ba9-4265-ad6d-6780cfa3d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_paper_title = result['bib']['title']\n",
    "b_paper_authors = ', '.join(result['bib']['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "28e47d6e-8548-42c7-91d9-41b755780cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'container_type': 'Publication',\n",
       " 'source': <PublicationSource.PUBLICATION_SEARCH_SNIPPET: 'PUBLICATION_SEARCH_SNIPPET'>,\n",
       " 'bib': {'title': 'Language models are few-shot learners',\n",
       "  'author': ['T Brown', 'B Mann', 'N Ryder'],\n",
       "  'pub_year': '2020',\n",
       "  'venue': 'Advances in neural …',\n",
       "  'abstract': 'We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text'},\n",
       " 'filled': False,\n",
       " 'gsrank': 1,\n",
       " 'pub_url': 'https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html',\n",
       " 'author_id': ['RLvsC94AAAAJ', 'McBoXK0AAAAJ', 'rLp0oucAAAAJ'],\n",
       " 'url_scholarbib': '/scholar?hl=en&q=info:IvIxX0MZZ90J:scholar.google.com/&output=cite&scirp=0&hl=en',\n",
       " 'url_add_sclib': '/citations?hl=en&xsrf=&continue=/scholar%3Fq%3DLanguage%2Bmodels%2Bare%2Bfew-shot%2Blearners%26hl%3Den%26as_sdt%3D0,33&citilm=1&update_op=library_add&info=IvIxX0MZZ90J&ei=rkuPZ-D1DoC96rQPt_-H0Q8&json=',\n",
       " 'num_citations': 38863,\n",
       " 'citedby_url': '/scholar?cites=15953747982133883426&as_sdt=5,33&sciodt=0,33&hl=en',\n",
       " 'url_related_articles': '/scholar?q=related:IvIxX0MZZ90J:scholar.google.com/&scioq=Language+models+are+few-shot+learners&hl=en&as_sdt=0,33',\n",
       " 'eprint_url': 'https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf'}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77d2c164-ada3-4948-b1ef-e3cc00f3d668",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b_paper_title' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mb_paper_title\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'b_paper_title' is not defined"
     ]
    }
   ],
   "source": [
    "b_paper_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3817aa2a-be19-43b2-95ed-f1277d9b4981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T Brown, B Mann, N Ryder'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_paper_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3d5d853c-a644-4e55-8b96-0b5d3a7f4f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Language models are few-shot learners'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_paper_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7569f18d-e37a-4d1c-a38c-bad7bbfc9b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_paper_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c4670bbc-43f5-4076-98e2-97f988bae773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'YES'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_compare(a_paper_title, a_paper_authors, b_paper_title, b_paper_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42350c2f-df9e-457b-ada4-a246c2e02137",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for result in search_query:\n",
    "    cnt += 1\n",
    "    b_paper_title = result['bib']['title']\n",
    "    b_paper_authors = ', '.join(result['bib']['author'])\n",
    "    if paper_compare(a_paper_title, a_paper_authors, b_paper_title, b_paper_authors) == 'YES':\n",
    "        citation_count = result.get('num_citations', 0)  # 인용수 가져오기\n",
    "\n",
    "    print(f\"cnt : {cnt}\")\n",
    "    if cnt >= 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "78645f73-5378-4a98-833a-cbd6cbf04291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_paper_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "babc8a4b-3ac0-47d0-8e43-8ed1d69d72bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, et al'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_paper_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4323a284-d9a8-4349-8589-c756f0023995",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scholarly import ProxyGenerator, scholarly\n",
    "\n",
    "# ProxyGenerator 설정\n",
    "pg = ProxyGenerator()\n",
    "pg.proxies = {\n",
    "    'http': 'http://43.202.154.212:80',  # 프록시 주소\n",
    "    'https': 'http://43.202.154.212:80',\n",
    "}\n",
    "scholarly.use_proxy(pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77aaf208-1360-4286-ad47-55e8bfd504d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m search_query \u001b[38;5;241m=\u001b[39m \u001b[43mscholarly\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_pubs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPerception of physical stability and center of mass of 3D objects\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_scholarly.py:160\u001b[0m, in \u001b[0;36m_Scholarly.search_pubs\u001b[0;34m(self, query, patents, citations, year_low, year_high, sort_by, include_last_year, start_index)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Searches by query and returns a generator of Publication objects\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m:param query: terms to be searched\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_url(_PUBSEARCH\u001b[38;5;241m.\u001b[39mformat(requests\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mquote(query)), patents\u001b[38;5;241m=\u001b[39mpatents,\n\u001b[1;32m    158\u001b[0m                           citations\u001b[38;5;241m=\u001b[39mcitations, year_low\u001b[38;5;241m=\u001b[39myear_low, year_high\u001b[38;5;241m=\u001b[39myear_high,\n\u001b[1;32m    159\u001b[0m                           sort_by\u001b[38;5;241m=\u001b[39msort_by, include_last_year\u001b[38;5;241m=\u001b[39minclude_last_year, start_index\u001b[38;5;241m=\u001b[39mstart_index)\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__nav\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_publications\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:296\u001b[0m, in \u001b[0;36mNavigator.search_publications\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msearch_publications\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _SearchScholarIterator:\n\u001b[1;32m    289\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a Publication Generator given a url\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    :param url: the url where publications can be found.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    :rtype: {_SearchScholarIterator}\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_SearchScholarIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/publication_parser.py:53\u001b[0m, in \u001b[0;36m_SearchScholarIterator.__init__\u001b[0;34m(self, nav, url)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pubtype \u001b[38;5;241m=\u001b[39m PublicationSource\u001b[38;5;241m.\u001b[39mPUBLICATION_SEARCH_SNIPPET \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/scholar?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m url \u001b[38;5;28;01melse\u001b[39;00m PublicationSource\u001b[38;5;241m.\u001b[39mJOURNAL_CITATION_LIST\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nav \u001b[38;5;241m=\u001b[39m nav\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_total_results()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_parser \u001b[38;5;241m=\u001b[39m PublicationParser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nav)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/publication_parser.py:59\u001b[0m, in \u001b[0;36m_SearchScholarIterator._load_url\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_load_url\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# this is temporary until setup json file\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nav\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_soup\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgs_r gs_or gs_scl\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsc_mpat_ttl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:239\u001b[0m, in \u001b[0;36mNavigator._get_soup\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_soup\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BeautifulSoup:\n\u001b[1;32m    238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the BeautifulSoup for a page on scholar.google.com\"\"\"\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://scholar.google.com\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     html \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    241\u001b[0m     res \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:132\u001b[0m, in \u001b[0;36mNavigator._get_page\u001b[0;34m(self, pagerequest, premium)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m has_captcha:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot a captcha request.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 132\u001b[0m     session \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_captcha2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpagerequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Retry request within same session\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_proxy_generator.py:422\u001b[0m, in \u001b[0;36mProxyGenerator._handle_captcha2\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    421\u001b[0m     cur \u001b[38;5;241m=\u001b[39m cur \u001b[38;5;241m+\u001b[39m log_interval \u001b[38;5;66;03m# Update before exceptions can happen\u001b[39;00m\n\u001b[0;32m--> 422\u001b[0m     \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_webdriver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil_not\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdrv\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_webdriver_has_captcha\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutException:\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/selenium/webdriver/support/wait.py:127\u001b[0m, in \u001b[0;36mWebDriverWait.until_not\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "search_query = scholarly.search_pubs('Perception of physical stability and center of mass of 3D objects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e739ca2a-33bc-4a46-9eb7-3516105d0542",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Scholarly 테스트\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     search_query \u001b[38;5;241m=\u001b[39m \u001b[43mscholarly\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_pubs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPerception of physical stability and center of mass of 3D objects\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(search_query)\n\u001b[1;32m      5\u001b[0m     scholarly\u001b[38;5;241m.\u001b[39mpprint(result)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_scholarly.py:160\u001b[0m, in \u001b[0;36m_Scholarly.search_pubs\u001b[0;34m(self, query, patents, citations, year_low, year_high, sort_by, include_last_year, start_index)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Searches by query and returns a generator of Publication objects\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m:param query: terms to be searched\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_url(_PUBSEARCH\u001b[38;5;241m.\u001b[39mformat(requests\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mquote(query)), patents\u001b[38;5;241m=\u001b[39mpatents,\n\u001b[1;32m    158\u001b[0m                           citations\u001b[38;5;241m=\u001b[39mcitations, year_low\u001b[38;5;241m=\u001b[39myear_low, year_high\u001b[38;5;241m=\u001b[39myear_high,\n\u001b[1;32m    159\u001b[0m                           sort_by\u001b[38;5;241m=\u001b[39msort_by, include_last_year\u001b[38;5;241m=\u001b[39minclude_last_year, start_index\u001b[38;5;241m=\u001b[39mstart_index)\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__nav\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_publications\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:296\u001b[0m, in \u001b[0;36mNavigator.search_publications\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msearch_publications\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _SearchScholarIterator:\n\u001b[1;32m    289\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a Publication Generator given a url\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    :param url: the url where publications can be found.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    :rtype: {_SearchScholarIterator}\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_SearchScholarIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/publication_parser.py:53\u001b[0m, in \u001b[0;36m_SearchScholarIterator.__init__\u001b[0;34m(self, nav, url)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pubtype \u001b[38;5;241m=\u001b[39m PublicationSource\u001b[38;5;241m.\u001b[39mPUBLICATION_SEARCH_SNIPPET \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/scholar?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m url \u001b[38;5;28;01melse\u001b[39;00m PublicationSource\u001b[38;5;241m.\u001b[39mJOURNAL_CITATION_LIST\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nav \u001b[38;5;241m=\u001b[39m nav\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_total_results()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_parser \u001b[38;5;241m=\u001b[39m PublicationParser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nav)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/publication_parser.py:59\u001b[0m, in \u001b[0;36m_SearchScholarIterator._load_url\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_load_url\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# this is temporary until setup json file\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nav\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_soup\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgs_r gs_or gs_scl\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsc_mpat_ttl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:239\u001b[0m, in \u001b[0;36mNavigator._get_soup\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_soup\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BeautifulSoup:\n\u001b[1;32m    238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the BeautifulSoup for a page on scholar.google.com\"\"\"\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://scholar.google.com\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     html \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    241\u001b[0m     res \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:132\u001b[0m, in \u001b[0;36mNavigator._get_page\u001b[0;34m(self, pagerequest, premium)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m has_captcha:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot a captcha request.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 132\u001b[0m     session \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_captcha2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpagerequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Retry request within same session\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_proxy_generator.py:422\u001b[0m, in \u001b[0;36mProxyGenerator._handle_captcha2\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    421\u001b[0m     cur \u001b[38;5;241m=\u001b[39m cur \u001b[38;5;241m+\u001b[39m log_interval \u001b[38;5;66;03m# Update before exceptions can happen\u001b[39;00m\n\u001b[0;32m--> 422\u001b[0m     \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_webdriver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil_not\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdrv\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_webdriver_has_captcha\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutException:\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/selenium/webdriver/support/wait.py:127\u001b[0m, in \u001b[0;36mWebDriverWait.until_not\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Scholarly 테스트\n",
    "try:\n",
    "    search_query = scholarly.search_pubs('Perception of physical stability and center of mass of 3D objects')\n",
    "    result = next(search_query)\n",
    "    scholarly.pprint(result)\n",
    "except Exception as e:\n",
    "    print(f\"Scholarly error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dbf2e00-a7e5-4ec6-a9a8-5af29f5aece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scholarly import scholarly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe587aad-7963-4a5e-989c-d65ce43bf175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scholarly import scholarly, ProxyGenerator\n",
    "pg = ProxyGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c865e808-ed2f-49f6-957d-ec173182df1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "success = pg.FreeProxies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e8590f8-7a36-4243-af00-013f9c414476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e677a5aa-3e36-45d3-a6a8-32c241137066",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scholarly.use_proxy(pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eec2f2e0-6b1b-4dc9-a162-a4364f7afc02",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m author \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscholarly\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_author\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSteven A Cholewiak\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:250\u001b[0m, in \u001b[0;36mNavigator.search_authors\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msearch_authors\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39mAuthor:\n\u001b[1;32m    249\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generator that returns Author objects from the author search page\"\"\"\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m     soup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_soup\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m     author_parser \u001b[38;5;241m=\u001b[39m AuthorParser(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:239\u001b[0m, in \u001b[0;36mNavigator._get_soup\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_soup\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BeautifulSoup:\n\u001b[1;32m    238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the BeautifulSoup for a page on scholar.google.com\"\"\"\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://scholar.google.com\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     html \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    241\u001b[0m     res \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:180\u001b[0m, in \u001b[0;36mNavigator._get_page\u001b[0;34m(self, pagerequest, premium)\u001b[0m\n\u001b[1;32m    178\u001b[0m tries \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 180\u001b[0m     session, timeout \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next_proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_tries\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_proxies\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo other secondary connections possible. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    183\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the primary proxy for all requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_proxy_generator.py:661\u001b[0m, in \u001b[0;36mProxyGenerator.get_next_proxy\u001b[0;34m(self, num_tries, old_timeout, old_proxy)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;66;03m# Try to get another proxy\u001b[39;00m\n\u001b[1;32m    660\u001b[0m new_proxy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proxy_gen(old_proxy)\n\u001b[0;32m--> 661\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_use_proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_proxy\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    662\u001b[0m     new_proxy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proxy_gen(new_proxy)\n\u001b[1;32m    663\u001b[0m new_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_TIMEOUT \u001b[38;5;66;03m# Reset timeout to default\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_proxy_generator.py:210\u001b[0m, in \u001b[0;36mProxyGenerator._use_proxy\u001b[0;34m(self, http, https)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessful ScraperAPI requests \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    208\u001b[0m                          r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequestCount\u001b[39m\u001b[38;5;124m\"\u001b[39m], r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequestLimit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proxy_works \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proxy_works:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proxies \u001b[38;5;241m=\u001b[39m proxies\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_proxy_generator.py:141\u001b[0m, in \u001b[0;36mProxyGenerator._check_proxy\u001b[0;34m(self, proxies)\u001b[0m\n\u001b[1;32m    139\u001b[0m session\u001b[38;5;241m.\u001b[39mproxies \u001b[38;5;241m=\u001b[39m proxies\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 141\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp://httpbin.org/ip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_TIMEOUT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProxy works! IP address: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    144\u001b[0m                          resp\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morigin\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/requests/sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/urllib3/connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.16/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.16/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.16/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.16/lib/python3.10/socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "author = next(scholarly.search_author('Steven A Cholewiak'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca0c85a8-3dd2-4347-a946-c9d1f094765b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MaxTriesExceededException",
     "evalue": "Cannot Fetch from Google Scholar.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMaxTriesExceededException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m author \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscholarly\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_author\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSteven A Cholewiak\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m scholarly\u001b[38;5;241m.\u001b[39mpprint(author)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:250\u001b[0m, in \u001b[0;36mNavigator.search_authors\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msearch_authors\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39mAuthor:\n\u001b[1;32m    249\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generator that returns Author objects from the author search page\"\"\"\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m     soup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_soup\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m     author_parser \u001b[38;5;241m=\u001b[39m AuthorParser(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:239\u001b[0m, in \u001b[0;36mNavigator._get_soup\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_soup\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BeautifulSoup:\n\u001b[1;32m    238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the BeautifulSoup for a page on scholar.google.com\"\"\"\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://scholar.google.com\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     html \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    241\u001b[0m     res \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:188\u001b[0m, in \u001b[0;36mNavigator._get_page\u001b[0;34m(self, pagerequest, premium)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# If secondary proxy does not work, try again primary proxy.\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m premium:\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpagerequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxTriesExceededException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot Fetch from Google Scholar.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:190\u001b[0m, in \u001b[0;36mNavigator._get_page\u001b[0;34m(self, pagerequest, premium)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_page(pagerequest, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxTriesExceededException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot Fetch from Google Scholar.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mMaxTriesExceededException\u001b[0m: Cannot Fetch from Google Scholar."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "author = next(scholarly.search_author('Steven A Cholewiak'))\n",
    "scholarly.pprint(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f1e6715-5494-4516-a2da-7f1f861e12eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scholarly import ProxyGenerator\n",
    "\n",
    "# Set up a ProxyGenerator object to use free proxies\n",
    "# This needs to be done only once per session\n",
    "pg = ProxyGenerator()\n",
    "pg.FreeProxies()\n",
    "scholarly.use_proxy(pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe8c1e7-6177-4b42-9503-6f7a4c728115",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MaxTriesExceededException",
     "evalue": "Cannot Fetch from Google Scholar.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMaxTriesExceededException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m search_query \u001b[38;5;241m=\u001b[39m \u001b[43mscholarly\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_pubs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPerception of physical stability and center of mass of 3D objects\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_scholarly.py:160\u001b[0m, in \u001b[0;36m_Scholarly.search_pubs\u001b[0;34m(self, query, patents, citations, year_low, year_high, sort_by, include_last_year, start_index)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Searches by query and returns a generator of Publication objects\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m:param query: terms to be searched\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_url(_PUBSEARCH\u001b[38;5;241m.\u001b[39mformat(requests\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mquote(query)), patents\u001b[38;5;241m=\u001b[39mpatents,\n\u001b[1;32m    158\u001b[0m                           citations\u001b[38;5;241m=\u001b[39mcitations, year_low\u001b[38;5;241m=\u001b[39myear_low, year_high\u001b[38;5;241m=\u001b[39myear_high,\n\u001b[1;32m    159\u001b[0m                           sort_by\u001b[38;5;241m=\u001b[39msort_by, include_last_year\u001b[38;5;241m=\u001b[39minclude_last_year, start_index\u001b[38;5;241m=\u001b[39mstart_index)\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__nav\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_publications\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:296\u001b[0m, in \u001b[0;36mNavigator.search_publications\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msearch_publications\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _SearchScholarIterator:\n\u001b[1;32m    289\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a Publication Generator given a url\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    :param url: the url where publications can be found.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    :rtype: {_SearchScholarIterator}\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_SearchScholarIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/publication_parser.py:53\u001b[0m, in \u001b[0;36m_SearchScholarIterator.__init__\u001b[0;34m(self, nav, url)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pubtype \u001b[38;5;241m=\u001b[39m PublicationSource\u001b[38;5;241m.\u001b[39mPUBLICATION_SEARCH_SNIPPET \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/scholar?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m url \u001b[38;5;28;01melse\u001b[39;00m PublicationSource\u001b[38;5;241m.\u001b[39mJOURNAL_CITATION_LIST\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nav \u001b[38;5;241m=\u001b[39m nav\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_total_results()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_parser \u001b[38;5;241m=\u001b[39m PublicationParser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nav)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/publication_parser.py:59\u001b[0m, in \u001b[0;36m_SearchScholarIterator._load_url\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_load_url\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# this is temporary until setup json file\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nav\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_soup\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgs_r gs_or gs_scl\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsc_mpat_ttl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:239\u001b[0m, in \u001b[0;36mNavigator._get_soup\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_soup\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BeautifulSoup:\n\u001b[1;32m    238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the BeautifulSoup for a page on scholar.google.com\"\"\"\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://scholar.google.com\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     html \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    241\u001b[0m     res \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:190\u001b[0m, in \u001b[0;36mNavigator._get_page\u001b[0;34m(self, pagerequest, premium)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_page(pagerequest, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxTriesExceededException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot Fetch from Google Scholar.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mMaxTriesExceededException\u001b[0m: Cannot Fetch from Google Scholar."
     ]
    }
   ],
   "source": [
    "search_query = scholarly.search_pubs('Perception of physical stability and center of mass of 3D objects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4b582c3-885d-49e7-9423-75c24f3173c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "MaxTriesExceededException",
     "evalue": "Cannot Fetch from Google Scholar.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMaxTriesExceededException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m scholarly\u001b[38;5;241m.\u001b[39muse_proxy(pg)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Now search Google Scholar from behind a proxy\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m search_query \u001b[38;5;241m=\u001b[39m \u001b[43mscholarly\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_pubs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPerception of physical stability and center of mass of 3D objects\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m scholarly\u001b[38;5;241m.\u001b[39mpprint(\u001b[38;5;28mnext\u001b[39m(search_query))\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_scholarly.py:160\u001b[0m, in \u001b[0;36m_Scholarly.search_pubs\u001b[0;34m(self, query, patents, citations, year_low, year_high, sort_by, include_last_year, start_index)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Searches by query and returns a generator of Publication objects\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m:param query: terms to be searched\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_url(_PUBSEARCH\u001b[38;5;241m.\u001b[39mformat(requests\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mquote(query)), patents\u001b[38;5;241m=\u001b[39mpatents,\n\u001b[1;32m    158\u001b[0m                           citations\u001b[38;5;241m=\u001b[39mcitations, year_low\u001b[38;5;241m=\u001b[39myear_low, year_high\u001b[38;5;241m=\u001b[39myear_high,\n\u001b[1;32m    159\u001b[0m                           sort_by\u001b[38;5;241m=\u001b[39msort_by, include_last_year\u001b[38;5;241m=\u001b[39minclude_last_year, start_index\u001b[38;5;241m=\u001b[39mstart_index)\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__nav\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_publications\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:296\u001b[0m, in \u001b[0;36mNavigator.search_publications\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msearch_publications\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _SearchScholarIterator:\n\u001b[1;32m    289\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a Publication Generator given a url\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    :param url: the url where publications can be found.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    :rtype: {_SearchScholarIterator}\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_SearchScholarIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/publication_parser.py:53\u001b[0m, in \u001b[0;36m_SearchScholarIterator.__init__\u001b[0;34m(self, nav, url)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pubtype \u001b[38;5;241m=\u001b[39m PublicationSource\u001b[38;5;241m.\u001b[39mPUBLICATION_SEARCH_SNIPPET \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/scholar?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m url \u001b[38;5;28;01melse\u001b[39;00m PublicationSource\u001b[38;5;241m.\u001b[39mJOURNAL_CITATION_LIST\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nav \u001b[38;5;241m=\u001b[39m nav\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_total_results()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_parser \u001b[38;5;241m=\u001b[39m PublicationParser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nav)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/publication_parser.py:59\u001b[0m, in \u001b[0;36m_SearchScholarIterator._load_url\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_load_url\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# this is temporary until setup json file\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nav\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_soup\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgs_r gs_or gs_scl\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsc_mpat_ttl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:239\u001b[0m, in \u001b[0;36mNavigator._get_soup\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_soup\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BeautifulSoup:\n\u001b[1;32m    238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the BeautifulSoup for a page on scholar.google.com\"\"\"\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://scholar.google.com\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     html \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    241\u001b[0m     res \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:190\u001b[0m, in \u001b[0;36mNavigator._get_page\u001b[0;34m(self, pagerequest, premium)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_page(pagerequest, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxTriesExceededException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot Fetch from Google Scholar.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mMaxTriesExceededException\u001b[0m: Cannot Fetch from Google Scholar."
     ]
    }
   ],
   "source": [
    "from scholarly import ProxyGenerator\n",
    "\n",
    "# Set up a ProxyGenerator object to use free proxies\n",
    "# This needs to be done only once per session\n",
    "pg = ProxyGenerator()\n",
    "pg.FreeProxies()\n",
    "scholarly.use_proxy(pg)\n",
    "\n",
    "# Now search Google Scholar from behind a proxy\n",
    "search_query = scholarly.search_pubs('Perception of physical stability and center of mass of 3D objects')\n",
    "scholarly.pprint(next(search_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "4b97f0dc-7a04-4503-aa69-db3009749fba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MaxTriesExceededException",
     "evalue": "Cannot Fetch from Google Scholar.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMaxTriesExceededException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[236], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m ref_paper_title \u001b[38;5;241m=\u001b[39m one_ref_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m ref_paper_authors \u001b[38;5;241m=\u001b[39m one_ref_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAuthor(s)\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m citation_cnt \u001b[38;5;241m=\u001b[39m \u001b[43mget_citation_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_paper_title\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_paper_authors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcitation_cnt\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m10,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_paper_title\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[234], line 5\u001b[0m, in \u001b[0;36mget_citation_count\u001b[0;34m(a_paper_title, a_paper_authors, author)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_citation_count\u001b[39m(a_paper_title, a_paper_authors, author\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Google Scholar에서 논문 검색\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     search_query \u001b[38;5;241m=\u001b[39m \u001b[43mscholarly\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_pubs\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_paper_title\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m search_query:\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_scholarly.py:160\u001b[0m, in \u001b[0;36m_Scholarly.search_pubs\u001b[0;34m(self, query, patents, citations, year_low, year_high, sort_by, include_last_year, start_index)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Searches by query and returns a generator of Publication objects\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m:param query: terms to be searched\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_url(_PUBSEARCH\u001b[38;5;241m.\u001b[39mformat(requests\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mquote(query)), patents\u001b[38;5;241m=\u001b[39mpatents,\n\u001b[1;32m    158\u001b[0m                           citations\u001b[38;5;241m=\u001b[39mcitations, year_low\u001b[38;5;241m=\u001b[39myear_low, year_high\u001b[38;5;241m=\u001b[39myear_high,\n\u001b[1;32m    159\u001b[0m                           sort_by\u001b[38;5;241m=\u001b[39msort_by, include_last_year\u001b[38;5;241m=\u001b[39minclude_last_year, start_index\u001b[38;5;241m=\u001b[39mstart_index)\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__nav\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_publications\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:296\u001b[0m, in \u001b[0;36mNavigator.search_publications\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msearch_publications\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _SearchScholarIterator:\n\u001b[1;32m    289\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a Publication Generator given a url\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    :param url: the url where publications can be found.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    :rtype: {_SearchScholarIterator}\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_SearchScholarIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/publication_parser.py:53\u001b[0m, in \u001b[0;36m_SearchScholarIterator.__init__\u001b[0;34m(self, nav, url)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pubtype \u001b[38;5;241m=\u001b[39m PublicationSource\u001b[38;5;241m.\u001b[39mPUBLICATION_SEARCH_SNIPPET \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/scholar?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m url \u001b[38;5;28;01melse\u001b[39;00m PublicationSource\u001b[38;5;241m.\u001b[39mJOURNAL_CITATION_LIST\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nav \u001b[38;5;241m=\u001b[39m nav\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_total_results()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_parser \u001b[38;5;241m=\u001b[39m PublicationParser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nav)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/publication_parser.py:59\u001b[0m, in \u001b[0;36m_SearchScholarIterator._load_url\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_load_url\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# this is temporary until setup json file\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nav\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_soup\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgs_r gs_or gs_scl\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsc_mpat_ttl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:239\u001b[0m, in \u001b[0;36mNavigator._get_soup\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_soup\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BeautifulSoup:\n\u001b[1;32m    238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the BeautifulSoup for a page on scholar.google.com\"\"\"\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://scholar.google.com\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     html \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    241\u001b[0m     res \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:190\u001b[0m, in \u001b[0;36mNavigator._get_page\u001b[0;34m(self, pagerequest, premium)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_page(pagerequest, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxTriesExceededException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot Fetch from Google Scholar.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mMaxTriesExceededException\u001b[0m: Cannot Fetch from Google Scholar."
     ]
    }
   ],
   "source": [
    "for i, one_ref_info in ref_dict.items():\n",
    "    ref_paper_title = one_ref_info['Title']\n",
    "    ref_paper_authors = one_ref_info['Author(s)']\n",
    "    citation_cnt = get_citation_count(ref_paper_title, ref_paper_authors)\n",
    "    print(f\"[{citation_cnt:10,}] [{i}] {ref_paper_title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "1fc202f0-bae8-4581-83a1-049b077b563e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Recommender ai agent: Integrating large language models for interactive recommendations'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_paper_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0b8f8fd5-bde0-413f-a9d4-ae3a673a2111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Xu Huang, Jianxun Lian, Yuxuan Lei, Jing Yao, Defu Lian, and Xing Xie'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_paper_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ff340451-3950-4b80-a250-de6b795a727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = scholarly.search_pubs(a_paper_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f981bfe4-19a5-4ddd-91c5-56c57f40960d",
   "metadata": {},
   "source": [
    "# get_citation_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "39eae8b7-8133-44ae-a02b-15855713fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PAPER_COMPARE_PROMPT.format(\n",
    "                a_paper_title=a_paper_title,\n",
    "                a_paper_authors=a_paper_authors,\n",
    "                b_paper_title=b_paper_title,  # 오타 수정\n",
    "                b_paper_authors=b_paper_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ef4b0a9e-23ae-4ca6-85ca-ad70f2f99014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare the titles and authors of the two papers, and if they are the same, respond with YES; otherwise, respond with NO.\n",
      "          \n",
      "          A paper title : Language models are few-shot learners,\n",
      "          A paper authors : Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al\n",
      "          \n",
      "          B paper title : Language models are few-shot learners,\n",
      "          B paper authors : T Brown, B Mann, N Ryder\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "583d2842-8c28-4848-bba4-54729bab962f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scholarly import scholarly\n",
    "\n",
    "def get_citation_count(a_paper_title, a_paper_authors, author=None):\n",
    "    # Google Scholar에서 논문 검색\n",
    "    search_query = scholarly.search_pubs(a_paper_title)\n",
    "    cnt = 0\n",
    "    for result in search_query:\n",
    "        cnt += 1\n",
    "        b_paper_title = result['bib']['title']\n",
    "        b_paper_authors = ', '.join(result['bib']['author'])\n",
    "        if paper_compare(a_paper_title, a_paper_authors, b_paper_title, b_paper_authors) == 'YES':\n",
    "            citation_count = result.get('num_citations', 0)  # 인용수 가져오기\n",
    "            return citation_count\n",
    "        if cnt >= 20:\n",
    "            return None\n",
    "\n",
    "PAPER_COMPARE_PROMPT = \"\"\"Compare the titles and authors of the two papers, and if they are the same, respond with YES; otherwise, respond with NO. Take into account that the authors' names might be abbreviated.\n",
    "          \n",
    "          A paper title : {a_paper_title}\n",
    "          A paper authors : {a_paper_authors}\n",
    "          \n",
    "          B paper title : {b_paper_title}\n",
    "          B paper authors : {b_paper_authors}\"\"\"\n",
    "\n",
    "def paper_compare(a_paper_title, a_paper_authors, b_paper_title, b_paper_authors):\n",
    "    print(f\"\\ta_paper_title : {a_paper_title}\\n\\tb_paper_title : {b_paper_title}\")\n",
    "    prompt = PAPER_COMPARE_PROMPT.format(\n",
    "                    a_paper_title=a_paper_title,\n",
    "                    a_paper_authors=a_paper_authors,\n",
    "                    b_paper_title=b_paper_title,  # 오타 수정\n",
    "                    b_paper_authors=b_paper_authors\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61e0017-fc4d-4294-a3a0-eb7bdb838545",
   "metadata": {},
   "source": [
    "# Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ae6e4cc-8db0-4b09-812a-adfd4671acdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Google Scholar 검색 URL\n",
    "query = \"recommendation\"\n",
    "url = f\"https://scholar.google.com/scholar?q={query}\"\n",
    "\n",
    "# 요청 헤더 설정 (실제 브라우저에서의 요청처럼 위장)\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# GET 요청 보내기\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# 상태 코드 확인\n",
    "if response.status_code == 200:\n",
    "    # HTML 파싱\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # 논문 제목과 관련 정보 추출\n",
    "    results = soup.select(\".gs_ri\")\n",
    "    for i, result in enumerate(results):\n",
    "        title = result.select_one(\".gs_rt\").text\n",
    "        authors_and_year = result.select_one(\".gs_a\").text\n",
    "        snippet = result.select_one(\".gs_rs\").text if result.select_one(\".gs_rs\") else \"No snippet available\"\n",
    "        link = result.select_one(\".gs_rt a\")[\"href\"] if result.select_one(\".gs_rt a\") else \"No link available\"\n",
    "\n",
    "        print(f\"Result {i+1}:\")\n",
    "        print(f\"Title: {title}\")\n",
    "        print(f\"Authors and Year: {authors_and_year}\")\n",
    "        print(f\"Snippet: {snippet}\")\n",
    "        print(f\"Link: {link}\")\n",
    "        print(\"-\" * 80)\n",
    "else:\n",
    "    print(f\"Failed to fetch the page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "331fcc6e-afaa-4de8-913b-d7bcb8bef5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response saved to response.html. Open it in a browser to check if it's a Captcha page.\n"
     ]
    }
   ],
   "source": [
    "# 응답 HTML 저장 및 확인\n",
    "with open(\"response.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "print(\"Response saved to response.html. Open it in a browser to check if it's a Captcha page.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recom_paper_crawling",
   "language": "python",
   "name": "recom_paper_crawling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
