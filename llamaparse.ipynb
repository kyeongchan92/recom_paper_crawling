{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "3e8e19a8-e328-46a7-8c15-d0c3746c544e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.vector_stores.kdbai import KDBAIVectorStore\n",
    "from getpass import getpass\n",
    "import kdbai_client as kdbai\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "bc341bf4-fc1e-45db-92d9-b16b234968c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KDBAIException",
     "evalue": "Your KDB.AI server is not compatible with this client (kdbai_client==1.5.0).\nPlease use kdbai_client >=1.6.0 and <=latest.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKDBAIException\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[297], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m KDBAI_API_KEY \u001b[38;5;241m=\u001b[39m (os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKDBAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKDBAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron \u001b[38;5;28;01melse\u001b[39;00m getpass(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKDB.AI API key: \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#connect to KDB.AI\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m session \u001b[38;5;241m=\u001b[39m \u001b[43mkdbai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSession\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mKDBAI_API_KEY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mKDBAI_ENDPOINT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/kdbai_client/api.py:70\u001b[0m, in \u001b[0;36mSession.__init__\u001b[0;34m(self, api_key, endpoint, host, port, mode, options)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m endpoint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m         endpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://localhost:8081\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session \u001b[38;5;241m=\u001b[39m \u001b[43mSessionRest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m MODE_QIPC:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m endpoint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/kdbai_client/session_rest.py:51\u001b[0m, in \u001b[0;36mSessionRest.__init__\u001b[0;34m(self, api_key, endpoint)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_endpoint()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readiness()\n\u001b[0;32m---> 51\u001b[0m \u001b[43mcheck_version\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/kdbai_client/version.py:31\u001b[0m, in \u001b[0;36mcheck_version\u001b[0;34m(versions)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (version\u001b[38;5;241m.\u001b[39mparse(__version__) \u001b[38;5;241m<\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(versions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclientMinVersion\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (versions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclientMaxVersion\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatest\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(__version__) \u001b[38;5;241m>\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(versions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclientMaxVersion\u001b[39m\u001b[38;5;124m'\u001b[39m]))):\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m KDBAIException(\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYour KDB.AI server is not compatible with this client (kdbai_client==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use kdbai_client >=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclientMinVersion\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and <=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclientMaxVersion\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m     )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(versions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserverVersion\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m<\u001b[39m version\u001b[38;5;241m.\u001b[39mVersion(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.4.0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mKDBAIException\u001b[0m: Your KDB.AI server is not compatible with this client (kdbai_client==1.5.0).\nPlease use kdbai_client >=1.6.0 and <=latest."
     ]
    }
   ],
   "source": [
    "# llama-parse is async-first, running the async code in a notebook requires the use of nest_asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "# API access to llama-cloud\n",
    "# os.environ[\"LLAMA_CLOUD_API_KEY\"] = os.getenv('LLAMA_CLOUD_API_KEY')\n",
    "\n",
    "KDBAI_ENDPOINT = (os.environ[\"KDBAI_ENDPOINT\"] if \"KDBAI_ENDPOINT\" in os.environ else input(\"KDB.AI endpoint: \"))\n",
    "KDBAI_API_KEY = (os.environ[\"KDBAI_API_KEY\"] if \"KDBAI_API_KEY\" in os.environ else getpass(\"KDB.AI API key: \"))\n",
    "\n",
    "#connect to KDB.AI\n",
    "session = kdbai.Session(api_key=KDBAI_API_KEY, endpoint=KDBAI_ENDPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7665c95-00d5-4b28-ab74-9f652f72e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect with kdbai database\n",
    "db = session.database(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2323dfcb-70fc-4275-89fb-71c4fabf4b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The schema contains two metadata columns (document_id, text) and one embeddings column\n",
    "schema = [\n",
    "        dict(name=\"document_id\", type=\"str\"),\n",
    "        dict(name=\"text\", type=\"str\"),\n",
    "        dict(name=\"embeddings\", type=\"float32s\"),\n",
    "    ]\n",
    "\n",
    "# indexflat, define the index name, type, column to apply the index to (embeddings)\n",
    "# and params which include thesearch metric (Euclidean distance), and dims\n",
    "indexFlat = {\n",
    "        \"name\": \"flat\",\n",
    "        \"type\": \"flat\",\n",
    "        \"column\": \"embeddings\",\n",
    "        \"params\": {'dims': 1536, 'metric': 'L2'},\n",
    "    }\n",
    "\n",
    "KDBAI_TABLE_NAME = \"LlamaParse_Table\"\n",
    "\n",
    "# First ensure the table does not already exist\n",
    "try:\n",
    "    db.table(KDBAI_TABLE_NAME).drop()\n",
    "except kdbai.KDBAIException:\n",
    "    pass\n",
    "\n",
    "#Create the table\n",
    "table = db.create_table(table=KDBAI_TABLE_NAME, schema=schema, indexes=[indexFlat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04bae3a7-f981-4e1c-9ba7-533dfb7aed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL  = \"text-embedding-3-small\"\n",
    "GENERATION_MODEL = \"gpt-4o\"\n",
    "\n",
    "llm = OpenAI(model=GENERATION_MODEL)\n",
    "embed_model = OpenAIEmbedding(model=EMBEDDING_MODEL)\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "pdf_file_name = './MACRec.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b900c37-275e-419c-b6a9-29c901983541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id aa583c54-abd1-4eee-947a-f13adbfc51c2\n",
      ".."
     ]
    }
   ],
   "source": [
    "# parsing_instructions = '''The document titled \"LLM In-Context Recall is Prompt Dependent\" is an academic preprint from April 2024, authored by Daniel Machlab and Rick Battle from the VMware NLP Lab. It explores the in-context recall capabilities of Large Language Models (LLMs) using a method called \"needle-in-a-haystack,\" where a specific factoid is embedded in a block of unrelated text. The study investigates how the recall performance of various LLMs is influenced by the content of prompts and the biases in their training data. The research involves testing multiple LLMs with varying context window sizes to assess their ability to recall information accurately when prompted differently. The paper includes detailed methodologies, results from numerous tests, discussions on the impact of prompt variations and training data, and conclusions on improving LLM utility in practical applications. It contains many tables. Answer questions using the information in this article and be precise.'''\n",
    "# print(parsing_instructions)\n",
    "\n",
    "documents = LlamaParse(\n",
    "    result_type=\"markdown\", \n",
    "    # parsing_instructions=parsing_instructions\n",
    ").load_data(pdf_file_name)\n",
    "# print(documents[0].text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adc4634d-1439-40b1-b19e-13e567dffb21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1---------------------------------------------------------------------------------------------------\n",
      "# MACRec: a Multi-Agent Collaboration Framework for Recommendation\n",
      "\n",
      "Zhefan Wang∗\n",
      "\n",
      "DCST, Tsinghua University\n",
      "\n",
      "Beijing 100084, China\n",
      "\n",
      "wzf23@mails.tsinghua.edu.cn\n",
      "\n",
      "Yuanqing Yu∗\n",
      "\n",
      "DCST, Tsinghua University\n",
      "\n",
      "Beijing 100084, China\n",
      "\n",
      "yyq23@mails.tsinghua.edu.cn\n",
      "\n",
      "Wendi Zheng\n",
      "\n",
      "DCST, Tsinghua University\n",
      "\n",
      "Beijing 100084, China\n",
      "\n",
      "zhengwd23@mails.tsinghua.edu.cn\n",
      "\n",
      "Weizhi Ma†\n",
      "\n",
      "AIR, Tsinghua University\n",
      "\n",
      "Beijing 100084, China\n",
      "\n",
      "mawz@tsinghua.edu.cn\n",
      "\n",
      "Min Zhang†\n",
      "\n",
      "DCST, Tsinghua University\n",
      "\n",
      "Beijing 100084, China\n",
      "\n",
      "z-m@tsinghua.edu.cn\n",
      "\n",
      "arXiv:2402.15235v3 [cs.IR] 1 Nov 2024\n",
      "\n",
      "# ABSTRACT\n",
      "\n",
      "LLM-based agents have gained considerable attention for their decision-making skills and ability to handle complex tasks. Recognizing the current gap in leveraging agent capabilities for multi-agent collaboration in recommendation systems, we introduce MACRec, a novel framework designed to enhance recommendation systems through multi-agent collaboration. Unlike existing work on using agents for user/item simulation, we aim to deploy multi-agents to tackle recommendation tasks directly. In our framework, recommendation tasks are addressed through the collaborative efforts of various specialized agents, including Manager, User/Item Analyst, Reflector, Searcher, and Task Interpreter, with different working flows. Furthermore, we provide application examples of how developers can easily use MACRec on various recommendation tasks, including rating prediction, sequential recommendation, conversational recommendation, and explanation generation of recommendation results. The framework and demonstration video are publicly available at https://github.com/wzf2000/MACRec.\n",
      "\n",
      "# 1 INTRODUCTION\n",
      "\n",
      "Recommender systems (RSs) play a vital role in improving user experience and platform economic benefits, which have become an essential part of various domains, such as e-commerce, social media, and so on. Currently, the advancement of Large Language Models (LLMs) [1, 9, 15, 22] has introduced LLM-based agents [7, 10, 21] capable of completing complex tasks. These agents’ semantic understanding, planning, and decision-making skills unlock new potentials for more nuanced and context-aware recommendations. Researchers have started to utilize the capabilities of agents to solve recommendation tasks. Existing work like [17, 23, 25] primarily focuses on employing agents for simulating user or item behaviors, providing insights into user preferences but falling short of integration into RSs. On the other hand, some studies [5, 18] attempt to leverage the capabilities of agents to directly build a recommender, primarily using one single agent with planning and memory components and auxiliary tools (e.g., search engine). However, there are various complex decision-making tasks in recommendation scenarios [13, 14], on which single-agent instances are unable to perform well. Multi-agent collaboration, which is near to human workflows, is believed to accomplish complex tasks better with collective intelligence. Although work [11] proposes a multi-agent recommendation framework, it only has limited agent types and a fixed collaboration mode.\n",
      "\n",
      "# CCS CONCEPTS\n",
      "\n",
      "• Information systems → Recommender systems.\n",
      "\n",
      "# KEYWORDS\n",
      "\n",
      "Multi-agents; Large Language Models; Recommender Systems\n",
      "\n",
      "# ACM Reference Format:\n",
      "\n",
      "Zhefan Wang, Yuanqing Yu, Wendi Zheng, Weizhi Ma, and Min Zhang. 2024. MACRec: a Multi-Agent Collaboration Framework for Recommendation. In Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ’24), July 14–18, 2024, Washington, DC, USA. ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/3626772.3657669\n",
      "\n",
      "∗Both authors contributed equally to this research.\n",
      "\n",
      "†Corresponding author. This work is supported by the Natural Science Foundation of China (Grant No. U21B2026, 62372260).\n",
      "\n",
      "Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s).\n",
      "\n",
      "SIGIR ’24, July 14–18, 2024, Washington, DC, USA\n",
      "\n",
      "© 2024 Copyright held by the owner/author(s).\n",
      "\n",
      "ACM ISBN 979-8-4007-0431-4/24/07.\n",
      "\n",
      "https://doi.org/10.1145/3626772.3657669\n",
      "2---------------------------------------------------------------------------------------------------\n",
      "# SIGIR ’24, July 14–18, 2024, Washington, DC, USA\n",
      "\n",
      "Zhefan Wang, Yuanqing Yu, Wendi Zheng, Weizhi Ma, & Min Zhang\n",
      "\n",
      "# Table 1: Comparison between previous work and our MACRec\n",
      "\n",
      "Note that Single-type Agents indicate all agents serve the same role (e.g., users), while Multi-type Agents refer to agents having multiple roles and capabilities (e.g., managers, reflectors).\n",
      "\n",
      "|Model|Objectives|Single-type Agents|Multi-type Agents|Diverse Rec. Scenarios|Open-source|\n",
      "|---|---|---|---|---|---|\n",
      "|RecAgent [17]|User Simulation|!| | |!|\n",
      "|Agent4Rec [23]|User Simulation|!| | |!|\n",
      "|AgentCF [25]|U-I Inter Simulation| |!| | |\n",
      "|RAH [11]|Recommender| |!| | |\n",
      "|RecMind [18]|Recommender|!| | |!|\n",
      "|InteRecAgent [5]|Recommender|!| | | |\n",
      "|MACRec|Recommender|!|!|!| |\n",
      "\n",
      "Varying requirements for agents in different scenarios, we show case examples of selecting and customizing agents to collaborate on diverse recommendation tasks. Furthermore, we developed an online web interface for our MACRec, providing a user-friendly visualization of the agents’ collaboration process. The main strengths of this work can be summarized as follows:\n",
      "\n",
      "- A New Multi-agent Collaboration Framework for Recommendation. Unlike previous studies focused on user/item simulation with agents, we propose a new multi-agent collaboration framework for recommendation MACRec. In this framework, agents with different abilities work collaboratively to tackle specific recommendation tasks.\n",
      "- Diverse Applications on Recommendation Scenarios. We present application examples on various recommendation scenarios, including rating prediction, sequential recommendation, explanation generation, and conversational recommendation.\n",
      "- A User-friendly Online Web Interface. We developed an online web interface for MACRec, visualizing how agents collaboratively tackle tasks.\n",
      "\n",
      "# 2.2 Multi-agent Collaboration\n",
      "\n",
      "Multi-agent systems, initially grounded in DAI [2] and MAS [12], evolved with foundational concepts of agent coordination and communication by Wooldridge and Jennings [19]. The advent of powerful LLMs [1, 9, 15, 22] has shifted focus towards their application in multi-agent collaboration. Brown et al. [1] demonstrated LLMs’ potential in human-like dialogues, applicable to agent-agent communication. Nascimento et al. [8], Vinyals et al. [16] illustrate how LLM agents can collaborate for shared objectives, achieving specific and complex task solutions. Recent work [3, 4, 24] leverage multi-agent collaboration to achieve better performance on complex tasks. CAMEL [6] and AutoGen [20] focus on communicative agent systems for complex task solutions through inter-agent dialogue. However, existing research on multi-agent collaboration has not investigated its potential in recommendation scenarios.\n",
      "\n",
      "# 2.1 Agents-based Recommendation\n",
      "\n",
      "Currently, research on integrating LLM-based agents for recommendation can be categorized into two primary orientations: simulation-oriented and recommender-oriented approaches. Table 1 compares our MACRec and previous agents-based work.\n",
      "\n",
      "The simulation-oriented work focuses on using agents to simulate user behaviors and item characteristics in RSs. RecAgent [23] and Agent4Rec [17] both propose to use agents as user simulators to empower the evaluation of RSs, which feature single-type agents (as users). AgentCF [25] explores the simulation of user-item interactions through user-agents and item-agents. It belongs to a multi-type agent system, with only two types and simple interactions. This line of research aims to provide a deeper understanding of user preferences but falls short of integration into RSs.\n",
      "\n",
      "The goal of recommender-oriented studies is to build a \"recommender agent\" with planning and memory components to tackle recommendation tasks. InteRecAgent [5] and RecMind [18] primarily focus on improving a single recommender agent’s planning and reflection ability. RAH [11] proposes a human-centered framework using LLM Agents as assistants. It supports collaboration.\n",
      "\n",
      "# 3 THE MACREC FRAMEWORK\n",
      "\n",
      "# 3.1 Framework Overview\n",
      "\n",
      "Figure 1 illustrates our proposed multi-agent collaboration recommendation framework. A sequential recommendation task is given as an example.\n",
      "\n",
      "As shown in the example in Figure 1, the Task Interpreter first translates the task in a better way to understand. Then, as the central component of the entire system, the Manager starts calling other agents to obtain detailed analyses of the user and items. These agents, including the Searcher and the User/Item Analyst, support the call of some tools, e.g., the Searcher has access to the search engine and the User/Item Analyst can access detailed information about users and items. After receiving responses from the Searcher and Analyst, the Manager will attempt to provide an answer, i.e., give a ranking order of the candidate sets. The Reflector will be responsible for analyzing and reflecting on the Manager’s answer in the last trial and giving suggestions, e.g., modifying the answer format to follow the task requirements. Eventually, the Manager.\n",
      "3---------------------------------------------------------------------------------------------------\n",
      "# MACRec: a Multi-Agent Collaboration Framework for Recommendation\n",
      "\n",
      "# SIGIR ’24, July 14–18, 2024, Washington, DC, USA\n",
      "\n",
      "# Task: Sequential Recommendation\n",
      "\n",
      "User ID: 46\n",
      "\n",
      "Candidate Item ID: [849, 376, 291, 125, 151, 132, 16, 814]\n",
      "\n",
      "Rank the above candidates for the user:\n",
      "\n",
      "UserInfo [UserID: 46]\n",
      "\n",
      "Finish:\n",
      "\n",
      "The user 46 is a 27-year-old female marketing professional who has interacted with a variety of movie genres including Drama, Sci-Fi, Adventure, Childrens, and Comedy:\n",
      "\n",
      "ItemInfo [ItemID: 849]\n",
      "\n",
      "Finish:\n",
      "\n",
      "The movie 'Days of Thunder' (1990) has been interacted with by users of various ages and genders, indicating a broad appeal across different demographics.\n",
      "\n",
      "ItemAnalyst\n",
      "\n",
      "Output: [151, 125, 814, 291, 376, 132, 849, 16]\n",
      "\n",
      "Figure 1: The Framework of MACRec. We take a sequential recommendation task as an example to show how these agents work collaboratively.\n",
      "\n",
      "According to user_46's preference, give a rank order of the following will reattempt to solve the task based on the reflections and provide a more reasonable answer, e.g., adding the missed item ID.\n",
      "\n",
      "The following sections will detail each agent’s specific characteristics and functions.\n",
      "\n",
      "# 3.2 Agent Roles\n",
      "\n",
      "# 3.2.1 Manager\n",
      "\n",
      "For the given task, the Manager would assign sub-tasks to other agents and complete the main execution process. It oversees the collaboration among all other agents.\n",
      "\n",
      "The Manager always performs the three steps of Thought, Action, and Observation alternately. In the Thought phase, the Manager reasons about the current situation of the task (e.g., whether the analysis is sufficient, whether additional information is needed, etc.). During the Action phase, the Manager can choose to give an answer to end the task or seek help from other agents (under a particular interface format). Responses given by other agents will be given in the Observation phase of the Manager.\n",
      "\n",
      "# 3.2.2 Reflector\n",
      "\n",
      "The Reflector is responsible for judging the correctness of the answer given by the Manager. A further reflection will be given if the Reflector determines the answer is correct. The Reflector will step in when the Manager is about to perform the second or more runs on the same task input. If the Reflector judges that the answer given by the Manager has no room for improvement, the Manager will no longer perform the current run. Otherwise, the Reflector will further summarize where the Manager can be improved, e.g., not considering the few highly rated items/movies in the user’s historical interactions.\n",
      "\n",
      "# 3.2.3 User/Item Analyst\n",
      "\n",
      "User/Item Analyst specializes in examining and understanding the characteristics and preferences of users, as well as the attributes of items. The Analyst will be given access to two tools to assist in the analysis, including info database and interaction retriever. The Analyst can get the user profile of each user and the attributes of each item through the info database. Through the interaction retriever, the Analyst can get the user/item interaction history before the current time. With the combination of these two tools, the Analyst can have an in-depth analysis of the user or the item.\n",
      "\n",
      "# 3.2.4 Searcher\n",
      "\n",
      "The Searcher is responsible for searching under the requirements given by the Manager with the search tool, and finally summarizing the text reply to the Manager. Take Wikipedia as an example of a search tool. The Searcher can give a search query to get the most relevant entry in Wikipedia. The Searcher can further retrieve passages in a specific entry where the given keywords exist. Eventually, the Searcher is asked to summarize the paragraph to respond to the Manager’s query.\n",
      "\n",
      "# 3.2.5 Task Interpreter\n",
      "\n",
      "The Task Interpreter translates the dialogs into executable recommendation tasks. The Task Interpreter will get the conversation history when starts running. Since conversation histories can be long, the Task Interpreter will only get the last part of the history. The Task Interpreter also has access to call the text summarization tool to get a more concise overview of the history. Eventually, the Task Interpreter will give a specific description of the task requirements that will be used to guide the subsequent runs of the Manager.\n",
      "\n",
      "# 4 APPLICATIONS ON RECOMMENDATION SCENARIOS\n",
      "\n",
      "Here, we present the applications of MACRec on four recommendation scenarios. Table 2 summarizes the agents’ selection for each scenario.\n",
      "\n",
      "|Task|U.Analy.|I.Analy.|Reflector|Searcher|Interpreter|\n",
      "|---|---|---|---|---|---|\n",
      "|RP| | | | | |\n",
      "|SR| | | | | |\n",
      "|EG| | | | | |\n",
      "|CR| | | | | |\n",
      "\n",
      "Code is available at https://github.com/wzf2000/MACRec.\n",
      "\n",
      "Table 2: The agents’ selection for four applications supported by MACRec. means required and means optional.\n",
      "4---------------------------------------------------------------------------------------------------\n",
      "# SIGIR ’24, July 14–18, 2024, Washington, DC, USA\n",
      "\n",
      "# Zhefan Wang, Yuanqing Yu, Wendi Zheng, Weizhi Ma, & Min Zhang\n",
      "\n",
      "# ChatSystem for Conversational Recommendation\n",
      "\n",
      "# Tasks\n",
      "\n",
      "Manager: Calling Searcher with movies about history.\n",
      "\n",
      "Manager: Calling Searcher with historical movies similar to Schindler's List.\n",
      "\n",
      "Searcher: Search for movies about history.\n",
      "\n",
      "Searcher: Search for historical movies similar to Schindler's List.\n",
      "\n",
      "Choose a task\n",
      "\n",
      "I have watched the movie Schindler's List recently: Found 3 documents. Their titles: Skin: A History of Nudity in the Movies, List of ghost films, List of drug films.\n",
      "\n",
      "(summary: Schindler's List (Schindler's List is a 1993 American epic historical drama film directed and produced by Steven Spielberg and written by Steven Spielberg).\n",
      "\n",
      "Amistad (film) (Amistad is a 1997 American historical drama film directed by Steven Spielberg, based on the events in 1839 aboard the...\n",
      "\n",
      "System is running...\n",
      "\n",
      "Skin: A History of Nudity in the Movies is a 2020 documentary film about the history of nudity in film. It was directed by Danny Wolf and executive produced by Jim 'Mr: Skin' McBride, who is also interviewed in the film.\n",
      "\n",
      "Interpreter: Summarize input.\n",
      "\n",
      "Searcher: Finish with results:\n",
      "\n",
      "Summarized text: user: I am very touched by the movie Schindler's List.\n",
      "\n",
      "Skin: A History of Nudity in the Movies is a 2020 documentary film about the history of nudity in film.\n",
      "\n",
      "Manager: Response from Searcher with historical movies similar to Schindler's List:\n",
      "\n",
      "Manager: Response from Searcher with movies about history:\n",
      "\n",
      "Can you recommend other movies that can teach me about history like Schindler's List?\n",
      "\n",
      "Search result: Skin: A History of Nudity in the Movies is a 2020 documentary film about the history of nudity in film.\n",
      "\n",
      "Manager: Thought 3: Amistad is a historical movie that can teach about the history of slavery and the fight for freedom: should recommend this movie to the user.\n",
      "\n",
      "Manager: Thought 1: There are many movies that can teach about history, but need to consider the specific themes and time periods that the user is interested in.\n",
      "\n",
      "Manager: Thought 2: Skin: A History of Nudity in the Movies is not relevant to the user's request: need to refine the search to find movies that specifically teach about historical events and themes.\n",
      "\n",
      "a) Interpret the dialog into a task (b) Search for movies about history: Search for movies similar to Schindler's List.\n",
      "\n",
      "# Figure 2:\n",
      "\n",
      "The web interfaces of our MACRec, along with a case of how three agents collaboratively address a conversational recommendation task. The interface is composed by the leftmost configuration panel and the main interaction panel.\n",
      "\n",
      "# 4.1 Rating Prediction (RP)\n",
      "\n",
      "Rating prediction task involves predicting the numerical rating a user might give to an item, such as a movie or a product, based on their preferences and historical interactions.\n",
      "\n",
      "In the rating prediction task, each user will have different rating preferences. The User Analyst can provide a detailed analysis of the user’s historical interactions and preferences. Meanwhile, the Manager also needs characteristic analysis of the target item, which can be provided by the Item Analyst. With the help of two types of Analysts, the Manager can know the user’s tendency to rate and the item’s recent ratings before giving a prediction.\n",
      "\n",
      "# 4.2 Sequential Recommendation (SR)\n",
      "\n",
      "Sequential recommendation systems analyze the sequence of items a user has interacted with to predict their next likely interest.\n",
      "\n",
      "Modeling of user’s long-term and short-term interests is important in sequential recommendation tasks. Hence, the User Analyst’s role is self-evident. The number of relevant items in the sequence is significantly higher than the rating prediction task. It is hard to ask the Item Analyst to analyze every item that appeared in either the history or the candidate set. Moreover, given that the answers to the sequential recommendation task are much more complex (i.e., a ranking order of the candidate set), the Reflector can help to avoid the Manager getting into formatting troubles. A single round of behavioral analysis may omit consideration of long-term user behavior, and reflection on this is something the Reflector can do.\n",
      "\n",
      "# 4.3 Explanation Generation (EG)\n",
      "\n",
      "This task involves generating understandable and relevant explanations for the recommendations provided to users.\n",
      "\n",
      "The explanation generation task also requires a detailed analysis of both the user and the item. In addition, more information about the item may also help the Manager understand the user’s behavior towards it. For example, a user may have similar preferences for multiple movies by the same director. The information about the director may not be contained in the dataset. Retrieving these extra pieces of information is suitable for the Searcher to perform.\n",
      "\n",
      "Figure 2 presents the web interfaces of our framework, along with a detailed case study demonstrating the collaborative efforts of three agents in addressing a conversational recommendation task.\n",
      "\n",
      "The interface can be divided into two main panels. 1) Configuration panel, where users can select different tasks to tackle, such as \"Rating Prediction.\" Users can also customize different systems and configuration files for the task execution. 2) Interaction panel, where the whole collaboration process takes place. Agents with different abilities would complete the task collaboratively.\n",
      "\n",
      "In Figure 2, the user has expressed a preference for the movie \"Schindler’s List\" and seeks recommendations for similar historical movies. The Interpreter summarizes this input and translates it into a clearer task. Then, the Manager calls for the help of the Searcher for two rounds, searching for movies about history and movies similar to \"Schindler’s List\". According to all the information, the Manager gives the final recommendation movie \"Amistad\".\n",
      "\n",
      "# 6 CONCLUSION\n",
      "\n",
      "In this work, we propose a novel LLM-based multi-agent collaboration framework for recommendation, called MACRec. Unlike existing studies on using agents for user/item simulation, we directly tackle recommendation tasks through the collaboration of various agents. We present applications of MACRec on four different recommendation tasks. Moreover, we developed an online web interface for MACRec, visualizing how agents work collaboratively.\n",
      "5---------------------------------------------------------------------------------------------------\n",
      "# MACRec: a Multi-Agent Collaboration Framework for Recommendation\n",
      "\n",
      "# SIGIR ’24, July 14–18, 2024, Washington, DC, USA\n",
      "\n",
      "# REFERENCES\n",
      "\n",
      "1. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877–1901.\n",
      "2. Brahim Chaib-Draa, Bernard Moulin, René Mandiau, and Patrick Millot. 1992. Trends in distributed artificial intelligence. Artificial Intelligence Review 6 (1992), 35–66.\n",
      "3. Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, et al. 2023. Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents. arXiv preprint arXiv:2308.10848 (2023).\n",
      "4. Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch. 2023. Improving Factuality and Reasoning in Language Models through Multiagent Debate. arXiv preprint arXiv:2305.14325 (2023).\n",
      "5. Xu Huang, Jianxun Lian, Yuxuan Lei, Jing Yao, Defu Lian, and Xing Xie. 2023. Recommender ai agent: Integrating large language models for interactive recommendations. arXiv preprint arXiv:2308.16505 (2023).\n",
      "6. Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. 2023. Camel: Communicative agents for \"mind\" exploration of large scale language model society. arXiv preprint arXiv:2303.17760 (2023).\n",
      "7. Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al. 2021. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332 (2021).\n",
      "8. Nathalia Nascimento, Paulo Alencar, and Donald Cowan. 2023. GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems. arXiv preprint arXiv:2308.10435 (2023).\n",
      "9. OpenAI. 2023. GPT-4 Technical Report. arXiv preprint arXiv:2303.08774 (2023).\n",
      "10. Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. 2023. Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface. arXiv preprint arXiv:2303.17580 (2023).\n",
      "11. Yubo Shu, Hansu Gu, Peng Zhang, Haonan Zhang, Tun Lu, Dongsheng Li, and Ning Gu. 2023. RAH! RecSys-Assistant-Human: A Human-Central Recommendation Framework with Large Language Models. arXiv preprint arXiv:2308.09904 (2023).\n",
      "12. Peter Stone and Manuela Veloso. 2000. Multiagent systems: A survey from a machine learning perspective. Autonomous Robots 8 (2000), 345–383.\n",
      "13. Peijie Sun, Yifan Wang, Min Zhang, Chuhan Wu, Yan Fang, Hong Zhu, Yuan Fang, and Meng Wang. 2024. Collaborative-Enhanced Prediction of Spending on Newly Downloaded Mobile Games under Consumption Uncertainty. WWW2024, Industry Track (2024).\n",
      "14. Peijie Sun, Le Wu, Kun Zhang, Xiangzhi Chen, and Meng Wang. 2023. Neighborhood-Enhanced Supervised Contrastive Learning for Collaborative Filtering. IEEE Transactions on Knowledge and Data Engineering (2023).\n",
      "15. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971 (2023).\n",
      "16. Oriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung, David H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, et al. 2019. Grandmaster level in StarCraft II using multi-agent reinforcement learning. Nature 575, 7782 (2019), 350–354.\n",
      "17. Lei Wang, Jingsen Zhang, Hao Yang, Zhiyuan Chen, Jiakai Tang, Zeyu Zhang, Xu Chen, Yankai Lin, Ruihua Song, Wayne Xin Zhao, et al. 2023. When Large Language Model based Agent Meets User Behavior Analysis: A Novel User Simulation Paradigm. arXiv preprint ArXiv:2306.02552 (2023).\n",
      "18. Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah Cho, Xing Fan, Xiaojiang Huang, Yanbin Lu, and Yingzhen Yang. 2023. Rec-mind: Large language model powered agent for recommendation. arXiv preprint arXiv:2308.14296 (2023).\n",
      "19. Michael Wooldridge and Nicholas R Jennings. 1995. Intelligent agents: Theory and practice. The knowledge engineering review 10, 2 (1995), 115–152.\n",
      "20. Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. 2023. Autogen: Enabling next-gen llm applications via multi-agent conversation framework. arXiv preprint arXiv:2308.08155 (2023).\n",
      "21. Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2022. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629 (2022).\n",
      "22. Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al. 2022. Glm-130b: An open bilingual pre-trained model. arXiv preprint arXiv:2210.02414 (2022).\n",
      "23. An Zhang, Leheng Sheng, Yuxin Chen, Hao Li, Yang Deng, Xiang Wang, and Tat-Seng Chua. 2023. On generative agents in recommendation. arXiv preprint arXiv:2310.10108 (2023).\n",
      "24. Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B Tenenbaum, Tianmin Shu, and Chuang Gan. 2023. Building cooperative embodied agents modularly with large language models. arXiv preprint arXiv:2307.02485 (2023).\n",
      "25. Junjie Zhang, Yupeng Hou, Ruobing Xie, Wenqi Sun, Julian McAuley, Wayne Xin Zhao, Leyu Lin, and Ji-Rong Wen. 2023. Agentcf: Collaborative learning with autonomous language agents for recommender systems. arXiv preprint arXiv:2310.09233 (2023).\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(documents, start=1):\n",
    "    print(f\"{i}\".ljust(100, '-'))\n",
    "    print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66f86e59-e556-46cf-804f-8c2ed540741d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 18558.87it/s]\n",
      "1it [00:00, 15650.39it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Parse the documents using MarkdownElementNodeParser\n",
    "node_parser = MarkdownElementNodeParser(llm=llm, num_workers=8).from_defaults()\n",
    "\n",
    "# Retrieve nodes (text) and objects (table)\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "\n",
    "base_nodes, objects = node_parser.get_nodes_and_objects(nodes)\n",
    "\n",
    "# insert the table markdown into the text of each table object\n",
    "for i in range(len(objects)):\n",
    "  objects[i].text = objects[i].obj.text[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13911fe1-e63d-49fd-b52e-3c75aad09b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2b516ba5-4f80-4723-85bd-1210fc2131e4</td>\n",
       "      <td>MACRec: a Multi-Agent Collaboration Framework ...</td>\n",
       "      <td>[-0.0010586621, 0.041707043, 0.02925757, 0.029...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a6c378f2-ab9d-46fd-89cb-25f4cf62b35e</td>\n",
       "      <td>SIGIR ’24, July 14–18, 2024, Washington, DC, U...</td>\n",
       "      <td>[-0.0015073667, 0.03517134, 0.057041712, 0.030...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b1dd3c00-1b68-47fc-917d-d2543f7c36a9</td>\n",
       "      <td>Varying requirements for agents in different s...</td>\n",
       "      <td>[-0.004967418, 0.037573203, 0.04944687, 0.0059...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6a286a2e-717a-4419-a3e3-fd5c173631a3</td>\n",
       "      <td>MACRec: a Multi-Agent Collaboration Framework ...</td>\n",
       "      <td>[-0.0118856495, 0.06537797, 0.021507366, 0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2ad81017-66f8-4e74-8598-c902244f810c</td>\n",
       "      <td>Code is available at https://github.com/wzf200...</td>\n",
       "      <td>[-0.018466502, 0.047101013, 0.060254864, 0.020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dfda5935-52df-4254-98a0-58761eb9b69a</td>\n",
       "      <td>SIGIR ’24, July 14–18, 2024, Washington, DC, U...</td>\n",
       "      <td>[-0.027369712, 0.04296594, -0.007082258, 0.006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>224ab1d8-a8f7-4fe9-bdb7-e1a7fa37e50b</td>\n",
       "      <td>Moreover, given that the answers to the sequen...</td>\n",
       "      <td>[-0.013393156, 0.05124579, 0.016177049, 0.0100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>79c2c0d4-1557-43c8-9d29-5fce9c418069</td>\n",
       "      <td>MACRec: a Multi-Agent Collaboration Framework ...</td>\n",
       "      <td>[-0.02555791, 0.009939187, 0.06459412, 0.02189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19d54e30-e5e8-40c1-b1c2-7642ac3adb95</td>\n",
       "      <td>arXiv preprint arXiv:2308.09904 (2023).\\n12. P...</td>\n",
       "      <td>[-0.0062998543, 0.022451159, 0.04597343, 0.013...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5e1b00ab-6c49-417f-80ac-d812d56e0501</td>\n",
       "      <td>2022. Glm-130b: An open bilingual pre-trained ...</td>\n",
       "      <td>[-0.0017179978, -0.0010304812, 0.04113033, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0fceed1d-7f0e-4190-aeb0-4cd188b3f0b8</td>\n",
       "      <td>The table compares different models based on t...</td>\n",
       "      <td>[-0.04988417, 0.02925188, 0.050212536, -0.0178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0e2e8a7f-43dd-46dc-8172-9b0cef171d57</td>\n",
       "      <td>The table lists various tasks (RP, SR, EG, CR)...</td>\n",
       "      <td>[-0.04078693, 0.080757536, 0.07323572, -0.0346...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             document_id  \\\n",
       "0   2b516ba5-4f80-4723-85bd-1210fc2131e4   \n",
       "1   a6c378f2-ab9d-46fd-89cb-25f4cf62b35e   \n",
       "2   b1dd3c00-1b68-47fc-917d-d2543f7c36a9   \n",
       "3   6a286a2e-717a-4419-a3e3-fd5c173631a3   \n",
       "4   2ad81017-66f8-4e74-8598-c902244f810c   \n",
       "5   dfda5935-52df-4254-98a0-58761eb9b69a   \n",
       "6   224ab1d8-a8f7-4fe9-bdb7-e1a7fa37e50b   \n",
       "7   79c2c0d4-1557-43c8-9d29-5fce9c418069   \n",
       "8   19d54e30-e5e8-40c1-b1c2-7642ac3adb95   \n",
       "9   5e1b00ab-6c49-417f-80ac-d812d56e0501   \n",
       "10  0fceed1d-7f0e-4190-aeb0-4cd188b3f0b8   \n",
       "11  0e2e8a7f-43dd-46dc-8172-9b0cef171d57   \n",
       "\n",
       "                                                 text  \\\n",
       "0   MACRec: a Multi-Agent Collaboration Framework ...   \n",
       "1   SIGIR ’24, July 14–18, 2024, Washington, DC, U...   \n",
       "2   Varying requirements for agents in different s...   \n",
       "3   MACRec: a Multi-Agent Collaboration Framework ...   \n",
       "4   Code is available at https://github.com/wzf200...   \n",
       "5   SIGIR ’24, July 14–18, 2024, Washington, DC, U...   \n",
       "6   Moreover, given that the answers to the sequen...   \n",
       "7   MACRec: a Multi-Agent Collaboration Framework ...   \n",
       "8   arXiv preprint arXiv:2308.09904 (2023).\\n12. P...   \n",
       "9   2022. Glm-130b: An open bilingual pre-trained ...   \n",
       "10  The table compares different models based on t...   \n",
       "11  The table lists various tasks (RP, SR, EG, CR)...   \n",
       "\n",
       "                                           embeddings  \n",
       "0   [-0.0010586621, 0.041707043, 0.02925757, 0.029...  \n",
       "1   [-0.0015073667, 0.03517134, 0.057041712, 0.030...  \n",
       "2   [-0.004967418, 0.037573203, 0.04944687, 0.0059...  \n",
       "3   [-0.0118856495, 0.06537797, 0.021507366, 0.003...  \n",
       "4   [-0.018466502, 0.047101013, 0.060254864, 0.020...  \n",
       "5   [-0.027369712, 0.04296594, -0.007082258, 0.006...  \n",
       "6   [-0.013393156, 0.05124579, 0.016177049, 0.0100...  \n",
       "7   [-0.02555791, 0.009939187, 0.06459412, 0.02189...  \n",
       "8   [-0.0062998543, 0.022451159, 0.04597343, 0.013...  \n",
       "9   [-0.0017179978, -0.0010304812, 0.04113033, 0.0...  \n",
       "10  [-0.04988417, 0.02925188, 0.050212536, -0.0178...  \n",
       "11  [-0.04078693, 0.080757536, 0.07323572, -0.0346...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store = KDBAIVectorStore(table)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "#Create the index, inserts base_nodes and objects into KDB.AI\n",
    "recursive_index = VectorStoreIndex(\n",
    "    nodes= base_nodes + objects, storage_context=storage_context\n",
    ")\n",
    "\n",
    "# Query KDB.AI to ensure the nodes were inserted\n",
    "table.query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c20dd18-5cdd-466b-867f-7b9b710dae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def embed_query(query):\n",
    "    query_embedding = client.embeddings.create(\n",
    "            input=query,\n",
    "            model=\"text-embedding-3-small\"\n",
    "        )\n",
    "    return query_embedding.data[0].embedding\n",
    "\n",
    "def retrieve_data(query):\n",
    "    query_embedding = embed_query(query)\n",
    "    results = table.search(vectors={'flat':[query_embedding]},n=5,filter=[('<>','document_id','4a9551df-5dec-4410-90bb-43d17d722918')])\n",
    "    retrieved_data_for_RAG = []\n",
    "    for index, row in results[0].iterrows():\n",
    "      retrieved_data_for_RAG.append(row['text'])\n",
    "    return retrieved_data_for_RAG\n",
    "\n",
    "def RAG(query):\n",
    "  question = \"You will answer this question based on the provided reference material: \" + query\n",
    "  messages = \"Here is the provided context: \" + \"\\n\"\n",
    "  results = retrieve_data(query)\n",
    "  if results:\n",
    "    for data in results:\n",
    "      messages += data + \"\\n\"\n",
    "  response = client.chat.completions.create(\n",
    "      model=\"gpt-4o\",\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": question},\n",
    "          {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "              {\"type\": \"text\", \"text\": messages},\n",
    "          ],\n",
    "          }\n",
    "      ],\n",
    "      # max_tokens=300,\n",
    "  )\n",
    "  content = response.choices[0].message.content\n",
    "  return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9646799a-5734-40b1-96e8-9229cc19bb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 논문의 핵심은 MACRec이라는 새로운 프레임워크를 소개하는 것입니다. MACRec는 LLM 기반의 다중 에이전트 협업 프레임워크로, 추천 시스템에서의 멀티 에이전트 협업을 통해 추천 작업을 직접적으로 해결하는 것을 목표로 합니다. 이 프레임워크는 매니저, 사용자/아이템 분석가, 반성자, 탐색자, 작업 해석자와 같은 여러 전문화된 에이전트들의 협력을 통해 추천 작업을 수행합니다. MACRec는 평가 예측, 순차적 추천, 대화형 추천, 추천 결과 설명 생성과 같은 다양한 추천 작업에 쉽게 활용할 수 있습니다. 이 프레임워크는 특히 단일 에이전트가 수행하기 어려운 복잡한 의사결정 작업에서 유용하며, 인간의 작업 흐름에 가까운 다중 에이전트 협업이 이를 보다 효과적으로 수행할 수 있다고 설명합니다. \"In this work, we propose a novel LLM-based multi-agent collaboration framework for recommendation, called MACRec. Unlike existing studies on using agents for user/item simulation, we directly tackle recommendation tasks through the collaboration of various agents.\"(본문에서 발췌)\n"
     ]
    }
   ],
   "source": [
    "print(RAG(\"이 논문의 핵심은 뭐야? 본문의 내용을 인용/발췌해서 설명해줘. 한글로 대답해.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f672d5-eb16-49af-a473-d5cf426f1744",
   "metadata": {},
   "source": [
    "# Reference 파싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "d1f5a8cd-8010-498f-9d02-949eed682c8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "answer = RAG(f\"\"\"Find this paper's References. Give me that References with the given json form. Don't return any other comments except that References\n",
    "\n",
    "EXAMPLE : \n",
    "{{\n",
    "    1 : {{\n",
    "            \"from_paper : \n",
    "                            {{\n",
    "                                \"title\" : \"Language models are few-shot learners\",\n",
    "                                \"authors\" : \"Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al\",\n",
    "                                \"source\" : \"Advances in neural information processing systems 33 (2020), 1877–1901\",\n",
    "                                \"year\" : 2020\n",
    "                            }}\n",
    "    }},\n",
    "    2 : {{\n",
    "        ...\n",
    "    }},\n",
    "    ...\n",
    "}}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "125bf082-3b17-405c-8ab1-6072b9c97573",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_dict = eval(answer.replace(\"```json\\n\", \"\").replace(\"```\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "83fc0c1c-1525-41db-b162-03774710adbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'from_paper': {'title': 'Language models are few-shot learners',\n",
       "   'authors': 'Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al',\n",
       "   'source': 'Advances in neural information processing systems 33 (2020), 1877–1901',\n",
       "   'year': 2020}},\n",
       " 2: {'from_paper': {'title': 'Trends in distributed artificial intelligence',\n",
       "   'authors': 'Brahim Chaib-Draa, Bernard Moulin, René Mandiau, and Patrick Millot',\n",
       "   'source': 'Artificial Intelligence Review 6 (1992), 35–66',\n",
       "   'year': 1992}},\n",
       " 3: {'from_paper': {'title': 'Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents',\n",
       "   'authors': 'Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, et al',\n",
       "   'source': 'arXiv preprint arXiv:2308.10848 (2023)',\n",
       "   'year': 2023}},\n",
       " 4: {'from_paper': {'title': 'Improving Factuality and Reasoning in Language Models through Multiagent Debate',\n",
       "   'authors': 'Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch',\n",
       "   'source': 'arXiv preprint arXiv:2305.14325 (2023)',\n",
       "   'year': 2023}},\n",
       " 5: {'from_paper': {'title': 'Recommender ai agent: Integrating large language models for interactive recommendations',\n",
       "   'authors': 'Xu Huang, Jianxun Lian, Yuxuan Lei, Jing Yao, Defu Lian, and Xing Xie',\n",
       "   'source': 'arXiv preprint arXiv:2308.16505 (2023)',\n",
       "   'year': 2023}},\n",
       " 6: {'from_paper': {'title': \"Camel: Communicative agents for 'mind' exploration of large scale language model society\",\n",
       "   'authors': 'Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem',\n",
       "   'source': 'arXiv preprint arXiv:2303.17760 (2023)',\n",
       "   'year': 2023}},\n",
       " 7: {'from_paper': {'title': 'Webgpt: Browser-assisted question-answering with human feedback',\n",
       "   'authors': 'Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al',\n",
       "   'source': 'arXiv preprint arXiv:2112.09332 (2021)',\n",
       "   'year': 2021}},\n",
       " 8: {'from_paper': {'title': 'GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems',\n",
       "   'authors': 'Nathalia Nascimento, Paulo Alencar, and Donald Cowan',\n",
       "   'source': 'arXiv preprint arXiv:2308.10435 (2023)',\n",
       "   'year': 2023}},\n",
       " 9: {'from_paper': {'title': 'GPT-4 Technical Report',\n",
       "   'authors': 'OpenAI',\n",
       "   'source': 'arXiv preprint arXiv:2303.08774 (2023)',\n",
       "   'year': 2023}},\n",
       " 10: {'from_paper': {'title': 'Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface',\n",
       "   'authors': 'Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang',\n",
       "   'source': 'arXiv preprint arXiv:2303.17580 (2023)',\n",
       "   'year': 2023}},\n",
       " 11: {'from_paper': {'title': 'RAH! RecSys-Assistant-Human: A Human-Central Recommendation Framework with Large Language Models',\n",
       "   'authors': 'Yubo Shu, Hansu Gu, Peng Zhang, Haonan Zhang, Tun Lu, Dongsheng Li, and Ning Gu',\n",
       "   'source': 'arXiv preprint arXiv:2308.09904 (2023)',\n",
       "   'year': 2023}},\n",
       " 12: {'from_paper': {'title': 'Multiagent systems: A survey from a machine learning perspective',\n",
       "   'authors': 'Peter Stone and Manuela Veloso',\n",
       "   'source': 'Autonomous Robots 8 (2000), 345–383',\n",
       "   'year': 2000}},\n",
       " 13: {'from_paper': {'title': 'Collaborative-Enhanced Prediction of Spending on Newly Downloaded Mobile Games under Consumption Uncertainty',\n",
       "   'authors': 'Peijie Sun, Yifan Wang, Min Zhang, Chuhan Wu, Yan Fang, Hong Zhu, Yuan Fang, and Meng Wang',\n",
       "   'source': 'WWW2024, Industry Track (2024)',\n",
       "   'year': 2024}},\n",
       " 14: {'from_paper': {'title': 'Neighborhood-Enhanced Supervised Contrastive Learning for Collaborative Filtering',\n",
       "   'authors': 'Peijie Sun, Le Wu, Kun Zhang, Xiangzhi Chen, and Meng Wang',\n",
       "   'source': 'IEEE Transactions on Knowledge and Data Engineering (2023)',\n",
       "   'year': 2023}},\n",
       " 15: {'from_paper': {'title': 'Llama: Open and efficient foundation language models',\n",
       "   'authors': 'Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al',\n",
       "   'source': 'arXiv preprint arXiv:2302.13971 (2023)',\n",
       "   'year': 2023}},\n",
       " 16: {'from_paper': {'title': 'Grandmaster level in StarCraft II using multi-agent reinforcement learning',\n",
       "   'authors': 'Oriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung, David H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, et al',\n",
       "   'source': 'Nature 575, 7782 (2019), 350–354',\n",
       "   'year': 2019}},\n",
       " 17: {'from_paper': {'title': 'When Large Language Model based Agent Meets User Behavior Analysis: A Novel User Simulation Paradigm',\n",
       "   'authors': 'Lei Wang, Jingsen Zhang, Hao Yang, Zhiyuan Chen, Jiakai Tang, Zeyu Zhang, Xu Chen, Yankai Lin, Ruihua Song, Wayne Xin Zhao, et al',\n",
       "   'source': 'arXiv preprint ArXiv:2306.02552 (2023)',\n",
       "   'year': 2023}},\n",
       " 18: {'from_paper': {'title': 'Rec-mind: Large language model powered agent for recommendation',\n",
       "   'authors': 'Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah Cho, Xing Fan, Xiaojiang Huang, Yanbin Lu, and Yingzhen Yang',\n",
       "   'source': 'arXiv preprint arXiv:2308.14296 (2023)',\n",
       "   'year': 2023}},\n",
       " 19: {'from_paper': {'title': 'Intelligent agents: Theory and practice',\n",
       "   'authors': 'Michael Wooldridge and Nicholas R Jennings',\n",
       "   'source': 'The knowledge engineering review 10, 2 (1995), 115–152',\n",
       "   'year': 1995}},\n",
       " 20: {'from_paper': {'title': 'Autogen: Enabling next-gen llm applications via multi-agent conversation framework',\n",
       "   'authors': 'Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang',\n",
       "   'source': 'arXiv preprint arXiv:2308.08155 (2023)',\n",
       "   'year': 2023}},\n",
       " 21: {'from_paper': {'title': 'React: Synergizing reasoning and acting in language models',\n",
       "   'authors': 'Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao',\n",
       "   'source': 'arXiv preprint arXiv:2210.03629 (2022)',\n",
       "   'year': 2022}},\n",
       " 22: {'from_paper': {'title': 'Glm-130b: An open bilingual pre-trained model',\n",
       "   'authors': 'Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al',\n",
       "   'source': 'arXiv preprint arXiv:2210.02414 (2022)',\n",
       "   'year': 2022}},\n",
       " 23: {'from_paper': {'title': 'On generative agents in recommendation',\n",
       "   'authors': 'An Zhang, Leheng Sheng, Yuxin Chen, Hao Li, Yang Deng, Xiang Wang, and Tat-Seng Chua',\n",
       "   'source': 'arXiv preprint arXiv:2310.10108 (2023)',\n",
       "   'year': 2023}},\n",
       " 24: {'from_paper': {'title': 'Building cooperative embodied agents modularly with large language models',\n",
       "   'authors': 'Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B Tenenbaum, Tianmin Shu, and Chuang Gan',\n",
       "   'source': 'arXiv preprint arXiv:2307.02485 (2023)',\n",
       "   'year': 2023}},\n",
       " 25: {'from_paper': {'title': 'Agentcf: Collaborative learning with autonomous language agents for recommender systems',\n",
       "   'authors': 'Junjie Zhang, Yupeng Hou, Ruobing Xie, Wenqi Sun, Julian McAuley, Wayne Xin Zhao, Leyu Lin, and Ji-Rong Wen',\n",
       "   'source': 'arXiv preprint arXiv:2310.09233 (2023)',\n",
       "   'year': 2023}}}"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f981bfe4-19a5-4ddd-91c5-56c57f40960d",
   "metadata": {},
   "source": [
    "# get_citation_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "7800f96f-a78b-4d07-831b-d54571564fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = scholarly.search_pubs(ref_paper_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "8fec6089-f6cb-467c-8921-db1c74d5a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in search_query:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "03026c6d-34ea-4bc2-a443-532792141ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'container_type': 'Publication',\n",
       " 'source': <PublicationSource.PUBLICATION_SEARCH_SNIPPET: 'PUBLICATION_SEARCH_SNIPPET'>,\n",
       " 'bib': {'title': 'Gpt-4 technical report',\n",
       "  'author': ['J Achiam', 'S Adler', 'S Agarwal', 'L Ahmad'],\n",
       "  'pub_year': '2023',\n",
       "  'venue': 'arXiv preprint arXiv …',\n",
       "  'abstract': 'This technical report presents GPT-4, a large multimodal  To test its capabilities in such  scenarios, GPT-4 was evaluated on a  For example, on a simulated bar exam, GPT-4 achieves a'},\n",
       " 'filled': False,\n",
       " 'gsrank': 1,\n",
       " 'pub_url': 'https://arxiv.org/abs/2303.08774',\n",
       " 'author_id': ['', 'K8mpmWAAAAAJ', '8UZIqcoAAAAJ', ''],\n",
       " 'url_scholarbib': '/scholar?hl=en&q=info:yMRuEJga_zIJ:scholar.google.com/&output=cite&scirp=0&hl=en',\n",
       " 'url_add_sclib': '/citations?hl=en&oe=ASCII&xsrf=&continue=/scholar%3Fq%3DGPT-4%2BTechnical%2BReport%26hl%3Den%26oe%3DASCII%26as_sdt%3D0,33&citilm=1&update_op=library_add&info=yMRuEJga_zIJ&ei=nWibZ6KANI2l6rQPhef7qAs&json=',\n",
       " 'num_citations': 7508,\n",
       " 'citedby_url': '/scholar?cites=3674685061370660040&as_sdt=5,33&sciodt=0,33&hl=en&oe=ASCII',\n",
       " 'url_related_articles': '/scholar?q=related:yMRuEJga_zIJ:scholar.google.com/&scioq=GPT-4+Technical+Report&hl=en&oe=ASCII&as_sdt=0,33',\n",
       " 'eprint_url': 'https://arxiv.org/pdf/2303.08774.pdf?fbclid=IwAR2XS6JT2NLIP4MjFn9npot34FhddoqStNbLwIvWETf5ZGlCPsIbuYneo8s&mibextid=Zxz2cZ'}"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "118640a3-e38b-4745-b38e-02d3f5a34936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://arxiv.org/abs/2303.08774'"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['pub_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "7f5db147-9858-424d-9bb1-7b7466a7fd2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'from_paper': {'title': 'Language models are few-shot learners',\n",
       "  'authors': 'Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al',\n",
       "  'source': 'Advances in neural information processing systems 33 (2020), 1877–1901',\n",
       "  'year': 2020}}"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "7de9ff66-7df7-4c1b-adcb-7af4d218663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = scholarly.search_pubs('Language models are few-shot learners')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "16538717-3b9c-45b9-b1bb-13ad78e598af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in search_query:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "889eef3b-bcbf-4e1b-a018-562e05a20725",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_COMPARE_PROMPT = \"\"\"🔹 Task Instruction\n",
    "Determine whether A paper and B paper refer to the same research work. If they do, respond with \"YES\"; otherwise, respond with \"NO\".\n",
    "\n",
    "When making this judgment, apply the following considerations:\n",
    "\n",
    "🔹 Considerations for Matching Papers\n",
    "1. Title Matching (Minor Differences Allowed)\n",
    "✅ Match the papers even if:\n",
    "\n",
    "The capitalization, punctuation, or spacing is slightly different.\n",
    "Example: \"GPT-4 Technical Report\" vs. \"Gpt-4 technical report\" → Match\n",
    "There are minor wording differences that do not change the meaning.\n",
    "Example: \"Large-scale language model society\" vs. \"Large language model society\" → Match\n",
    "🚨 Do NOT match the papers if:\n",
    "\n",
    "The core meaning of the title is different.\n",
    "Example: \"GPT-4 Overview\" vs. \"GPT-3.5 Architecture\" → Not the same paper\n",
    "2. Source Matching (Preprints, Conferences, Journals, DOI, URLs)\n",
    "✅ Match the papers even if:\n",
    "\n",
    "One is an arXiv preprint, and the other is a published conference/journal version of the same research.\n",
    "Example: arXiv preprint arXiv:2303.17760 → NeurIPS 2023 proceedings link → Same research work\n",
    "The URLs are different but point to the same DOI, arXiv ID, or official publisher repository.\n",
    "Example:\n",
    "\"https://arxiv.org/abs/2303.08774\"\n",
    "\"https://proceedings.neurips.cc/.../2303.08774\"\n",
    "→ Same paper\n",
    "The conference/journal version is an extended version of an arXiv paper, unless there is major content divergence.\n",
    "🚨 Do NOT match the papers if:\n",
    "\n",
    "The DOI/arXiv ID is different, and there is no indication that one is a revision of the other.\n",
    "One is from a completely different publisher (e.g., IEEE vs. ACL Anthology) without a clear link between them.\n",
    "3. Author Name Variations (Abbreviations & Institutional Naming Allowed)\n",
    "✅ Match the papers even if:\n",
    "\n",
    "Authors use initials instead of full names.\n",
    "Example: \"Guohao Li\" vs. \"G Li\" → Same author\n",
    "Authors are listed differently between an arXiv preprint and a published paper.\n",
    "Example: \"OpenAI\" vs. \"J Achiam, S Adler, S Agarwal\" → Match if source matches\n",
    "A company name is used instead of individual authors.\n",
    "🚨 Do NOT match the papers if:\n",
    "\n",
    "A completely different research group is listed.\n",
    "The list of authors has no significant overlap.\n",
    "4. Edition or Version Differences (Preprint vs. Published Paper)\n",
    "✅ Match the papers even if:\n",
    "\n",
    "One version is an early preprint and the other is a peer-reviewed conference/journal version.\n",
    "The published version contains minor updates or additional experiments but is still based on the same research.\n",
    "🚨 Do NOT match the papers if:\n",
    "\n",
    "The newer version substantially changes the research (e.g., different methodology, new experiments, different conclusions).\n",
    "The preprint was not accepted by the listed conference/journal.\n",
    "\n",
    "A paper title : {a_paper_title}\n",
    "A paper authors : {a_paper_authors}\n",
    "A paper source : {a_paper_source}\n",
    "\n",
    "B paper title : {b_paper_title}\n",
    "B paper authors : {b_paper_authors}\n",
    "B paper source : {b_paper_source}\"\"\"\n",
    "\n",
    "\n",
    "REQUEST_HTML_PARSING_PROMPT = \"\"\"Parse the given HTML code like the given format. Never answer the other comments but formatted information.\n",
    "\n",
    "HTML : {one_paper_box_html}\n",
    "\n",
    "Format example :\n",
    "{{\n",
    "    \"title\" : \"Language models are few-shot learners\",\n",
    "    \"authors\" : \"T Brown, B Mann, N Ryder\",\n",
    "    \"citation_count\" : 39209,\n",
    "    \"link_description\" : \"\"\n",
    "}}\"\"\"\n",
    "\n",
    "REQUEST_REAL_CITATION_PROMPT = \"\"\"What is the real citation count of the below paper title and authors?\n",
    "- Return with given format using only Candidates' information.\n",
    "- If an exact match for the paper cannot be found in Candidates, say only 'NO'.\n",
    "\n",
    "### The paper whose citation count I want to know\n",
    "paper title : {ref_paper_title}\n",
    "paper authors : {ref_paper_authors}\n",
    "\n",
    "### Candidates\n",
    "{request_box_collect}\n",
    "\n",
    "### Return Format\n",
    "{{\n",
    "    \"title\" : ,\n",
    "    \"authors\" : ,\n",
    "    \"citation_count\" : {{\n",
    "                        'value' : citation_count,\n",
    "                        }}\n",
    "}}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "b6806bc2-5f60-4beb-b165-c3bfbf4837ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Timeout exceeded! Moving to the next step.\n",
      "⚠ No results found or timeout occurred.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "from scholarly import scholarly\n",
    "\n",
    "# 검색할 논문 제목\n",
    "ref_paper_title = \"GPT-4 Technical Report\"\n",
    "\n",
    "# 타임아웃 설정 (예: 10초)\n",
    "TIMEOUT = 5\n",
    "\n",
    "# 결과 저장 변수\n",
    "search_result = None\n",
    "\n",
    "# ✅ 함수 실행을 위한 쓰레드 클래스\n",
    "class ScholaryThread(threading.Thread):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.result = None\n",
    "\n",
    "    def run(self):\n",
    "        try:\n",
    "            # search_pubs 실행\n",
    "            self.result = scholarly.search_pubs(ref_paper_title)\n",
    "        except Exception as e:\n",
    "            self.result = None\n",
    "\n",
    "# ✅ 실행 시간 측정 및 타임아웃 적용\n",
    "def search_with_timeout():\n",
    "    global search_result\n",
    "\n",
    "    thread = ScholaryThread()\n",
    "    thread.start()\n",
    "    thread.join(TIMEOUT)  # 타임아웃 적용\n",
    "\n",
    "    if thread.is_alive():\n",
    "        print(\"⏳ Timeout exceeded! Moving to the next step.\")\n",
    "        thread.join(0)  # 강제 종료\n",
    "    else:\n",
    "        search_result = thread.result  # 검색 결과 저장\n",
    "\n",
    "# ✅ 실행\n",
    "search_with_timeout()\n",
    "\n",
    "# ✅ 결과 확인\n",
    "if search_result:\n",
    "    print(\"✅ Search successful!\")\n",
    "else:\n",
    "    print(\"⚠ No results found or timeout occurred.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "f936ea1c-2c92-4b6c-ac65-6f79d865853e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[677], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m search_query \u001b[38;5;241m=\u001b[39m \u001b[43mscholarly\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_pubs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_paper_title\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_scholarly.py:160\u001b[0m, in \u001b[0;36m_Scholarly.search_pubs\u001b[0;34m(self, query, patents, citations, year_low, year_high, sort_by, include_last_year, start_index)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Searches by query and returns a generator of Publication objects\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m:param query: terms to be searched\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_url(_PUBSEARCH\u001b[38;5;241m.\u001b[39mformat(requests\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mquote(query)), patents\u001b[38;5;241m=\u001b[39mpatents,\n\u001b[1;32m    158\u001b[0m                           citations\u001b[38;5;241m=\u001b[39mcitations, year_low\u001b[38;5;241m=\u001b[39myear_low, year_high\u001b[38;5;241m=\u001b[39myear_high,\n\u001b[1;32m    159\u001b[0m                           sort_by\u001b[38;5;241m=\u001b[39msort_by, include_last_year\u001b[38;5;241m=\u001b[39minclude_last_year, start_index\u001b[38;5;241m=\u001b[39mstart_index)\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__nav\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_publications\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:296\u001b[0m, in \u001b[0;36mNavigator.search_publications\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msearch_publications\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _SearchScholarIterator:\n\u001b[1;32m    289\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a Publication Generator given a url\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    :param url: the url where publications can be found.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    :rtype: {_SearchScholarIterator}\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_SearchScholarIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/publication_parser.py:53\u001b[0m, in \u001b[0;36m_SearchScholarIterator.__init__\u001b[0;34m(self, nav, url)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pubtype \u001b[38;5;241m=\u001b[39m PublicationSource\u001b[38;5;241m.\u001b[39mPUBLICATION_SEARCH_SNIPPET \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/scholar?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m url \u001b[38;5;28;01melse\u001b[39;00m PublicationSource\u001b[38;5;241m.\u001b[39mJOURNAL_CITATION_LIST\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nav \u001b[38;5;241m=\u001b[39m nav\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_total_results()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_parser \u001b[38;5;241m=\u001b[39m PublicationParser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nav)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/publication_parser.py:59\u001b[0m, in \u001b[0;36m_SearchScholarIterator._load_url\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_load_url\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# this is temporary until setup json file\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nav\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_soup\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgs_r gs_or gs_scl\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsc_mpat_ttl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:239\u001b[0m, in \u001b[0;36mNavigator._get_soup\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_soup\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BeautifulSoup:\n\u001b[1;32m    238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the BeautifulSoup for a page on scholar.google.com\"\"\"\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://scholar.google.com\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     html \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    241\u001b[0m     res \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_navigator.py:132\u001b[0m, in \u001b[0;36mNavigator._get_page\u001b[0;34m(self, pagerequest, premium)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m has_captcha:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot a captcha request.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 132\u001b[0m     session \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_captcha2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpagerequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Retry request within same session\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/scholarly/_proxy_generator.py:422\u001b[0m, in \u001b[0;36mProxyGenerator._handle_captcha2\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    421\u001b[0m     cur \u001b[38;5;241m=\u001b[39m cur \u001b[38;5;241m+\u001b[39m log_interval \u001b[38;5;66;03m# Update before exceptions can happen\u001b[39;00m\n\u001b[0;32m--> 422\u001b[0m     \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_webdriver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil_not\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdrv\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_webdriver_has_captcha\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutException:\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/selenium/webdriver/support/wait.py:127\u001b[0m, in \u001b[0;36mWebDriverWait.until_not\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "search_query = scholarly.search_pubs(ref_paper_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "6ebcfcb7-7b13-4647-869e-d29253392222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scholarly import scholarly\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import threading\n",
    "import time\n",
    "from scholarly import scholarly\n",
    "from datetime import datetime\n",
    "\n",
    "def get_citation_count_using_scholarly(\n",
    "    ref_paper_title, \n",
    "    ref_paper_authors, \n",
    "    ref_paper_source,\n",
    "    comp_try_limit = 20,\n",
    "    TIMEOUT = 20):  # 타임아웃 설정 추가\n",
    "    \n",
    "    print(f\"\\tSearch using scholarly\")\n",
    "\n",
    "    # ✅ 검색 수행을 위한 쓰레드 클래스\n",
    "    class ScholarlyThread(threading.Thread):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.result = None\n",
    "\n",
    "        def run(self):\n",
    "            try:\n",
    "                self.result = scholarly.search_pubs(ref_paper_title)\n",
    "            except Exception as e:\n",
    "                self.result = None\n",
    "\n",
    "    # ✅ 실행 시간 측정 및 타임아웃 적용\n",
    "    def search_with_timeout():\n",
    "        thread = ScholarlyThread()\n",
    "        thread.start()\n",
    "        thread.join(TIMEOUT)  # 타임아웃 적용\n",
    "\n",
    "        if thread.is_alive():\n",
    "            print(f\"⏳ Timeout {TIMEOUT} sec exceeded! Moving to the next step.\")\n",
    "            return None  # 타임아웃 발생 시 None 반환\n",
    "        return thread.result  # 성공하면 결과 반환\n",
    "\n",
    "    # ✅ Google Scholar에서 논문 검색 (타임아웃 적용)\n",
    "    search_query = search_with_timeout()\n",
    "    \n",
    "    if search_query is None:\n",
    "        print(f\"\\tscholarly search timed out or failed\")\n",
    "        return None\n",
    "    \n",
    "    cnt = 0\n",
    "    if not len(search_query._rows):  # 검색 결과 없을 때\n",
    "        print(f\"\\tscholarly no result\")\n",
    "        return None\n",
    "        \n",
    "    for result in search_query:\n",
    "        cnt += 1\n",
    "        b_paper_title = result['bib']['title']\n",
    "        b_paper_authors = ', '.join(result['bib']['author'])\n",
    "        b_paper_source = result.get('pub_url', '')\n",
    "\n",
    "        # ✅ 논문 비교 (paper_compare 함수 사용)\n",
    "        if paper_compare(ref_paper_title, ref_paper_authors, ref_paper_source, \n",
    "                         b_paper_title, b_paper_authors, b_paper_source) == 'YES':\n",
    "            citation_count = result.get('num_citations', 0)  # 인용수 가져오기\n",
    "            return {\n",
    "                \"title\": b_paper_title,\n",
    "                \"authors\": b_paper_authors,\n",
    "                \"citation_count\": {\n",
    "                    'value': citation_count,\n",
    "                    'date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                }\n",
    "            }\n",
    "\n",
    "        # 검색 횟수 제한 도달 시 종료\n",
    "        if cnt >= comp_try_limit:\n",
    "            print(f\"scholarly couldn't find a match within {comp_try_limit} attempts\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "id": "9c20eaee-1561-4746-a01d-355645053558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSearch using Request\n"
     ]
    }
   ],
   "source": [
    "    print(f\"\\tSearch using Request\")\n",
    "    url = f\"https://scholar.google.com/scholar?q={ref_paper_title}\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "id": "c2402d60-9c52-406b-803c-8bb2d6c78928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(response.status_code == 200) and (response.text != \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "5f86ea85-d3d1-41e2-9f82-3a796d86d0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t# of results : 0\n"
     ]
    }
   ],
   "source": [
    "# HTML 파싱\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# 논문 제목과 관련 정보 추출\n",
    "results = soup.select(\".gs_ri\")\n",
    "print(f\"\\t# of results : {len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "id": "583d2842-8c28-4848-bba4-54729bab962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_citation_count_using_request(ref_paper_title, ref_paper_authors):\n",
    "    print(f\"\\tSearch using Request\")\n",
    "    url = f\"https://scholar.google.com/scholar?q={ref_paper_title}\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    # 상태 코드 확인\n",
    "    if (response.status_code == 200) and (response.text != \"\"):\n",
    "        # HTML 파싱\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        # 논문 제목과 관련 정보 추출\n",
    "        results = soup.select(\".gs_ri\")\n",
    "        print(f\"\\t# of results : {len(results)}\")\n",
    "        if not len(results):\n",
    "            return None\n",
    "        request_box_collect = \"\"\n",
    "        for one_paper_box_html in results:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": REQUEST_HTML_PARSING_PROMPT.format(one_paper_box_html=one_paper_box_html)\n",
    "                    },\n",
    "                ]\n",
    "            )\n",
    "            answer = response.choices[0].message.content\n",
    "            request_box_collect += answer.replace(\"```json\", \"\").replace(\"```\", \"\") + \"\\n\"\n",
    "            \n",
    "        print(f\"\\trequest_box_collect : \\n\\t{request_box_collect}\")\n",
    "        answer = llm.invoke(\n",
    "            REQUEST_REAL_CITATION_PROMPT.format(\n",
    "                ref_paper_title=ref_paper_title,\n",
    "                ref_paper_authors=ref_paper_authors,\n",
    "                request_box_collect=request_box_collect\n",
    "            )\n",
    "        )\n",
    "        if answer.content != 'NO':\n",
    "            answer_dict = eval(answer.content.replace(\"```json\", \"\").replace(\"```\", \"\"))\n",
    "            answer_dict['citation_count']['date'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            return answer_dict\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    else:\n",
    "        print(f\"get_citation_count_using_scholarly : BAD Response\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def paper_compare(ref_paper_title, ref_paper_authors, ref_paper_source, b_paper_title, b_paper_authors, b_paper_source):\n",
    "    print(f\"\\tΓref_paper_title : {ref_paper_title}({ref_paper_authors[:20]}...)\\n\\tL  b_paper_title : {b_paper_title}({b_paper_authors[:20]}...)\")\n",
    "    prompt = PAPER_COMPARE_PROMPT.format(\n",
    "        a_paper_title=ref_paper_title,\n",
    "        a_paper_authors=ref_paper_authors,\n",
    "        a_paper_source=ref_paper_source,\n",
    "        b_paper_title=b_paper_title,  # 오타 수정\n",
    "        b_paper_authors=b_paper_authors,\n",
    "        b_paper_source=b_paper_source,\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    answer = response.choices[0].message.content\n",
    "    print(f\"\\t{answer}\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e89175-21c1-4341-8b04-0ad45e82aca1",
   "metadata": {},
   "source": [
    "## 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "a344922d-b168-4296-bb71-1babae256030",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, one_ref_info in ref_dict.items():\n",
    "    if 'from_scholary' in one_ref_info:\n",
    "        del one_ref_info['from_scholary']\n",
    "    if 'from_request' in one_ref_info:\n",
    "        del one_ref_info['from_request']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "4b97f0dc-7a04-4503-aa69-db3009749fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, one_ref_info in ref_dict.items():\n",
    "    \n",
    "    ref_paper_title = one_ref_info['from_paper']['title']\n",
    "    ref_paper_authors = one_ref_info['from_paper']['authors']\n",
    "    ref_paper_source = one_ref_info['from_paper']['source']\n",
    "    print(f\"\".ljust(120, '-'))\n",
    "    break\n",
    "    scholary_result = get_citation_count_using_scholarly(ref_paper_title, ref_paper_authors, ref_paper_source)\n",
    "\n",
    "    if scholary_result is not None:\n",
    "        ref_dict[i]['from_scholary'] = scholary_result\n",
    "    else:\n",
    "        request_result = get_citation_count_using_request(ref_paper_title, ref_paper_authors)\n",
    "        if request_result is not None:\n",
    "            ref_dict[i]['from_request'] = request_result\n",
    "\n",
    "    pprint(f\"from_scholary : {ref_dict[i]['from_scholary'] if 'from_scholary' in ref_dict[i] else ''}\")\n",
    "    pprint(f\"from_request : {ref_dict[i]['from_request'] if 'from_request' in ref_dict[i] else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c471ac9-7028-448a-9852-5b7dd90ae4ca",
   "metadata": {},
   "source": [
    "## tavily_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "c6e74e2b-7901-41a0-8d11-8ef852d9d97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.retrievers import TavilySearchAPIRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "fb9c9efc-77d4-4c4e-975b-43257fc7f784",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_URL_SEARCH_PROMPT = \"\"\"The Paper '{paper_title}'s official webpage\"\"\"\n",
    "\n",
    "def tavily_search(paper_title, k=3):\n",
    "    \n",
    "    retriever = TavilySearchAPIRetriever(k=k)\n",
    "    result = retriever.invoke(PAPER_URL_SEARCH_PROMPT.format(paper_title=paper_title))\n",
    "\n",
    "    \"\"\"\n",
    "    result\n",
    "\n",
    "    [\n",
    "        Document(\n",
    "            metadata={\n",
    "                        'title': '[PDF] Intelligent agents: theory ...',\n",
    "                        'source': 'https://www.semanticscholar.org...',\n",
    "                        'score': 0.67885995,\n",
    "                        'images': [],\n",
    "                     },\n",
    "            page_content='The aim of thi...'\n",
    "                )\n",
    "         Document(...)\n",
    "         Document(...),\n",
    "    ]\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "35d3d5ba-ae9e-48fe-ac3e-d38a8f024b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content section not found.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL 지정\n",
    "url = \"https://aclanthology.org/2024.naacl-long.24/\"\n",
    "\n",
    "# HTTP GET 요청\n",
    "response = requests.get(url)\n",
    "\n",
    "# 상태 코드 확인\n",
    "if response.status_code == 200:\n",
    "    # HTML 파싱\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    # 제목 추출 (예: 페이지의 `<title>` 태그)\n",
    "    title = soup.title.string\n",
    "    \n",
    "    # 본문 내용 추출\n",
    "    # ACL Anthology의 논문 본문은 <div id=\"content\"> 내부에 들어 있음\n",
    "    content_div = soup.find(\"div\", {\"id\": \"content\"})\n",
    "    \n",
    "    if content_div:\n",
    "        content_text = content_div.get_text(separator=\"\\n\").strip()  # 줄바꿈으로 텍스트 구분\n",
    "        print(\"Page Title:\", title)\n",
    "        print(\"\\nContent:\\n\")\n",
    "        print(content_text)\n",
    "    else:\n",
    "        print(\"Content section not found.\")\n",
    "else:\n",
    "    print(f\"Failed to fetch the page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92638b86-331d-4126-bbe3-642aacd2c1ef",
   "metadata": {},
   "source": [
    "## parse_conference_paper_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "f19f6ef7-456f-41b5-b274-cad8c257cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import HTMLNodeParser\n",
    "from llama_index.core import Document\n",
    "\n",
    "\n",
    "CONFERENCE_PAPER_PARSING_PROMPT = \"\"\"Based on the information from the given website, return it in the provided format. Do not say anything else.\n",
    "\n",
    "### Example\n",
    "{{\n",
    "    \"conference\" : \"Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n",
    "    \"conference_abbreviation\" : \"NAACL\",\n",
    "    \"published_year\" : 2024,\n",
    "    \"published_month\" : 6\n",
    "}}\n",
    "\n",
    "### Website's text\n",
    "{page_content}\n",
    "\n",
    "### Answer\n",
    "{{\n",
    "    \"title\" : \"\",\n",
    "    \"conference\" : \"\",\n",
    "    \"conference_abbreviation\" : \"\",\n",
    "    \"published_year\" : ,\n",
    "    \"published_month\" : \n",
    "}}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def parse_conference_paper_info(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    # 상태 코드 확인\n",
    "    if response.status_code == 200:\n",
    "        html_content = response.text  # HTML 원본 가져오기\n",
    "        document = Document(text=html_content)\n",
    "        parser = HTMLNodeParser()\n",
    "        nodes = parser.get_nodes_from_documents([document])\n",
    "        parsed_page_content = \"\"\n",
    "        for node in nodes:\n",
    "            parsed_page_content += node.get_text() + \"\\n\"\n",
    "        answer = llm.invoke(CONFERENCE_PAPER_PARSING_PROMPT.format(page_content=parsed_page_content))\n",
    "        return answer.content\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "f72e51ae-098a-4d0d-97e0-fceabb63d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_result = tavily_search(paper_title=ref_paper_title, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "5f27af91-dc45-4536-9206-e8ecf893c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPREHENSIVE_DECISION_PROMPT = \"\"\"Based on the website below and the information retrieved from it, make a comprehensive judgment and determine the accurate Conference, Conference abbreviation, Published year, and Published month for the paper below, then return the results. Do not say anything else.\n",
    "\n",
    "### Paper's title : {paper_title}\n",
    "\n",
    "### Information from Website\n",
    "\n",
    "{information_from_website}\n",
    "\n",
    "### Format example\n",
    "{{\n",
    "    \"title\" : \"\",\n",
    "    \"conference\" : \"\",\n",
    "    \"conference_abbreviation\" : \"\",\n",
    "    \"published_year\" : ,\n",
    "    \"published_month\" : \n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "def comprehensive_decision(paper_title, )\n",
    "\n",
    "information_from_website = \"\"\n",
    "for d in tavily_result:\n",
    "    information_from_website += '\\n webpage : ' + d.metadata['title']\n",
    "    information_from_website += '\\n url : ' + d.metadata['source']\n",
    "    information_from_website += '\\n' + parse_conference_paper_info(url=d.metadata['source'])\n",
    "    information_from_website += '\\n'\n",
    "\n",
    "answer = llm.invoke(\n",
    "    COMPREHENSIVE_DECISION_PROMPT.format(\n",
    "        paper_title=paper_title,\n",
    "        information_from_website=information_from_website\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "45c6b682-c032-4b28-9456-673c77f07c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Language models are few-shot learners',\n",
       " 'author(s)': 'Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al',\n",
       " 'conference': 'Advances in neural information processing systems 33 (2020), 1877–1901',\n",
       " 'year': 2020,\n",
       " 'citation_count': {'value': 39232, 'date': '2025-01-30 18:28:04'}}"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_dict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "fa8e1108-6a4a-40eb-a9ec-ce8cff9dd13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Language Models are Few-Shot Learners',\n",
       " 'conference': 'NeurIPS',\n",
       " 'conference_abbreviation': 'NeurIPS',\n",
       " 'published_year': 2020,\n",
       " 'published_month': 12}"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "a9519bbf-062d-4dd5-a915-a9ae4e262ece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " webpage : Paper Summary: Language Models are Few-Shot Learners\n",
      " url : https://queirozf.com/entries/paper-summary-language-models-are-few-shot-learners\n",
      "{\n",
      "    \"title\" : \"Language Models are Few-Shot Learners\",\n",
      "    \"conference\" : \"\",\n",
      "    \"conference_abbreviation\" : \"\",\n",
      "    \"published_year\" : 2020,\n",
      "    \"published_month\" : 5\n",
      "}\n",
      "\n",
      " webpage : Review for NeurIPS paper: Language Models are Few-Shot Learners\n",
      " url : https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-MetaReview.html\n",
      "{\n",
      "    \"title\" : \"Language Models are Few-Shot Learners\",\n",
      "    \"conference\" : \"NeurIPS\",\n",
      "    \"conference_abbreviation\" : \"NeurIPS\",\n",
      "    \"published_year\" : 2020,\n",
      "    \"published_month\" : 12\n",
      "}\n",
      "\n",
      " webpage : [2005.14165] Language Models are Few-Shot Learners - arXiv.org\n",
      " url : https://arxiv.org/abs/2005.14165\n",
      "{\n",
      "    \"title\" : \"Language Models are Few-Shot Learners\",\n",
      "    \"conference\" : \"\",\n",
      "    \"conference_abbreviation\" : \"\",\n",
      "    \"published_year\" : ,\n",
      "    \"published_month\" : \n",
      "}\n",
      "\n",
      " webpage : [2409.15700] Making Text Embedders Few-Shot Learners - arXiv.org\n",
      " url : https://arxiv.org/abs/2409.15700\n",
      "{\n",
      "    \"title\" : \"Making Text Embedders Few-Shot Learners\",\n",
      "    \"conference\" : \"\",\n",
      "    \"conference_abbreviation\" : \"\",\n",
      "    \"published_year\" : ,\n",
      "    \"published_month\" : \n",
      "}\n",
      "\n",
      " webpage : Review for NeurIPS paper: Language Models are Few-Shot Learners\n",
      " url : https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Review.html\n",
      "{\n",
      "    \"title\" : \"Language Models are Few-Shot Learners\",\n",
      "    \"conference\" : \"NeurIPS 2020\",\n",
      "    \"conference_abbreviation\" : \"NeurIPS\",\n",
      "    \"published_year\" : 2020,\n",
      "    \"published_month\" : 12\n",
      "}\n",
      "\n",
      " webpage : Paper Summary: Language Models are Few-Shot Learner (GPT-3 Paper)\n",
      " url : https://medium.com/@dataturka/paper-summary-language-models-are-few-shot-learner-gpt-3-paper-a435d3052b4a\n",
      "{\n",
      "    \"title\" : \"Language Models are Few-Shot Learner (GPT-3 Paper)\",\n",
      "    \"conference\" : \"\",\n",
      "    \"conference_abbreviation\" : \"\",\n",
      "    \"published_year\" : 2020,\n",
      "    \"published_month\" : \"\"\n",
      "}\n",
      "\n",
      " webpage : Title: Language Models are Few-shot Multilingual Learners - arXiv.org\n",
      " url : https://arxiv.org/abs/2109.07684v1\n",
      "{\n",
      "    \"title\" : \"Language Models are Few-shot Multilingual Learners\",\n",
      "    \"conference\" : \"\",\n",
      "    \"conference_abbreviation\" : \"\",\n",
      "    \"published_year\" : ,\n",
      "    \"published_month\" : \n",
      "}\n",
      "\n",
      " webpage : Language Models are Few-Shot Learners - NIPS\n",
      " url : https://papers.nips.cc/paper_files/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html\n",
      "{\n",
      "    \"title\" : \"Language Models are Few-Shot Learners\",\n",
      "    \"conference\" : \"Advances in Neural Information Processing Systems 33 (NeurIPS 2020)\",\n",
      "    \"conference_abbreviation\" : \"NeurIPS\",\n",
      "    \"published_year\" : 2020,\n",
      "    \"published_month\" : null\n",
      "}\n",
      "\n",
      " webpage : Language models are few-shot learners | Proceedings of the 34th ...\n",
      " url : https://dl.acm.org/doi/abs/10.5555/3495724.3495883\n",
      "{\n",
      "    \"title\" : \"Language models are few-shot learners\",\n",
      "    \"conference\" : \"NIPS '20: Proceedings of the 34th International Conference on Neural Information Processing Systems\",\n",
      "    \"conference_abbreviation\" : \"NIPS\",\n",
      "    \"published_year\" : 2020,\n",
      "    \"published_month\" : 12\n",
      "}\n",
      "\n",
      " webpage : Language Models are Few-Shot Learners - Papers With Code\n",
      " url : https://paperswithcode.com/paper/language-models-are-few-shot-learners?from=n7\n",
      "{\n",
      "    \"title\" : \"Language Models are Few-Shot Learners\",\n",
      "    \"conference\" : \"NeurIPS 2020\",\n",
      "    \"conference_abbreviation\" : \"NeurIPS\",\n",
      "    \"published_year\" : 2020,\n",
      "    \"published_month\" : 12\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(information_from_website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "9b176d91-ce6c-4cc0-ad19-3e2151a99a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_dict_with_cnt = {}\n",
    "for i, one_ref in ref_dict.items():\n",
    "    if ('citation_count' in one_ref) and (one_ref['citation_count']['value'] is not None):\n",
    "        ref_dict_with_cnt[i] = one_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35645a10-ccd4-41db-936c-3c219f43ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  'Title': 'MACRec: A Multi-Agent Collaboration Framework for Recommendation',\n",
    "  'Author(s)': 'Z. Wang, Y. Yu, W. Zheng, W. Ma, M. Zhang',\n",
    "  'Conference': 'Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval (2024, July), 2760-2764',\n",
    "  'citation_count': {'value': 'unknown', 'date': '2025-01-22 16:50:59'}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "3f02b907-9d2d-4f21-842f-bc68451d22ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'Title': 'Language models are few-shot learners',\n",
       "  'Author(s)': 'Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al.',\n",
       "  'Conference': 'Advances in neural information processing systems 33 (2020), 1877–1901',\n",
       "  'citation_count': {'value': 39209, 'date': '2025-01-28 21:45:37'}},\n",
       " 2: {'Title': 'Trends in distributed artificial intelligence',\n",
       "  'Author(s)': 'Brahim Chaib-Draa, Bernard Moulin, René Mandiau, and Patrick Millot',\n",
       "  'Conference': 'Artificial Intelligence Review 6 (1992), 35–66',\n",
       "  'citation_count': {'value': 282, 'date': '2025-01-28 21:45:46'}},\n",
       " 3: {'Title': 'Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents',\n",
       "  'Author(s)': 'Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, et al.',\n",
       "  'Conference': 'arXiv preprint arXiv:2308.10848 (2023)',\n",
       "  'citation_count': {'value': 156, 'date': '2025-01-28 21:45:49'}},\n",
       " 4: {'Title': 'Improving Factuality and Reasoning in Language Models through Multiagent Debate',\n",
       "  'Author(s)': 'Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch',\n",
       "  'Conference': 'arXiv preprint arXiv:2305.14325 (2023)',\n",
       "  'citation_count': {'value': 446, 'date': '2025-01-28 21:45:51'}},\n",
       " 5: {'Title': 'Recommender ai agent: Integrating large language models for interactive recommendations',\n",
       "  'Author(s)': 'Xu Huang, Jianxun Lian, Yuxuan Lei, Jing Yao, Defu Lian, and Xing Xie',\n",
       "  'Conference': 'arXiv preprint arXiv:2308.16505 (2023)',\n",
       "  'citation_count': {'value': 79, 'date': '2025-01-28 21:45:56'}},\n",
       " 6: {'Title': \"Camel: Communicative agents for 'mind' exploration of large scale language model society\",\n",
       "  'Author(s)': 'Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem',\n",
       "  'Conference': 'arXiv preprint arXiv:2303.17760 (2023)',\n",
       "  'citation_count': {'value': 531, 'date': '2025-01-28 21:45:58'}},\n",
       " 7: {'Title': 'Webgpt: Browser-assisted question-answering with human feedback',\n",
       "  'Author(s)': 'Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al.',\n",
       "  'Conference': 'arXiv preprint arXiv:2112.09332 (2021)',\n",
       "  'citation_count': {'value': 1108, 'date': '2025-01-28 21:46:01'}},\n",
       " 8: {'Title': 'GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems',\n",
       "  'Author(s)': 'Nathalia Nascimento, Paulo Alencar, and Donald Cowan',\n",
       "  'Conference': 'arXiv preprint arXiv:2308.10435 (2023)',\n",
       "  'citation_count': {'value': 11, 'date': '2025-01-28 21:46:07'}},\n",
       " 9: {'Title': 'GPT-4 Technical Report',\n",
       "  'Author(s)': 'OpenAI',\n",
       "  'Conference': 'arXiv preprint arXiv:2303.08774 (2023)',\n",
       "  'citation_count': {'value': 7486, 'date': '2025-01-28 21:46:10'}},\n",
       " 10: {'Title': 'Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface',\n",
       "  'Author(s)': 'Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang',\n",
       "  'Conference': 'arXiv preprint arXiv:2303.17580 (2023)',\n",
       "  'citation_count': {'value': 1029, 'date': '2025-01-28 21:46:13'}},\n",
       " 11: {'Title': 'RAH! RecSys-Assistant-Human: A Human-Central Recommendation Framework with Large Language Models',\n",
       "  'Author(s)': 'Yubo Shu, Hansu Gu, Peng Zhang, Haonan Zhang, Tun Lu, Dongsheng Li, and Ning Gu',\n",
       "  'Conference': 'arXiv preprint arXiv:2308.09904 (2023)',\n",
       "  'citation_count': {'value': 17, 'date': '2025-01-28 21:46:18'}},\n",
       " 12: {'Title': 'Multiagent systems: A survey from a machine learning perspective',\n",
       "  'Author(s)': 'Peter Stone and Manuela Veloso',\n",
       "  'Conference': 'Autonomous Robots 8 (2000), 345–383',\n",
       "  'citation_count': {'value': 2064, 'date': '2025-01-28 21:46:23'}},\n",
       " 13: {'Title': 'Collaborative-Enhanced Prediction of Spending on Newly Downloaded Mobile Games under Consumption Uncertainty',\n",
       "  'Author(s)': 'Peijie Sun, Yifan Wang, Min Zhang, Chuhan Wu, Yan Fang, Hong Zhu, Yuan Fang, and Meng Wang',\n",
       "  'Conference': 'WWW2024, Industry Track (2024)',\n",
       "  'citation_count': {'value': 9, 'date': '2025-01-28 21:46:29'}},\n",
       " 14: {'Title': 'Neighborhood-Enhanced Supervised Contrastive Learning for Collaborative Filtering',\n",
       "  'Author(s)': 'Peijie Sun, Le Wu, Kun Zhang, Xiangzhi Chen, and Meng Wang',\n",
       "  'Conference': 'IEEE Transactions on Knowledge and Data Engineering (2023)',\n",
       "  'citation_count': {'value': 24, 'date': '2025-01-28 21:46:34'}},\n",
       " 15: {'Title': 'Llama: Open and efficient foundation language models',\n",
       "  'Author(s)': 'Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al.',\n",
       "  'Conference': 'arXiv preprint arXiv:2302.13971 (2023)',\n",
       "  'citation_count': {'value': 12263, 'date': '2025-01-28 21:46:36'}},\n",
       " 16: {'Title': 'Grandmaster level in StarCraft II using multi-agent reinforcement learning',\n",
       "  'Author(s)': 'Oriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung, David H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, et al.',\n",
       "  'Conference': 'Nature 575, 7782 (2019), 350–354',\n",
       "  'citation_count': {'value': 5054, 'date': '2025-01-28 21:46:42'}},\n",
       " 17: {'Title': 'When Large Language Model based Agent Meets User Behavior Analysis: A Novel User Simulation Paradigm',\n",
       "  'Author(s)': 'Lei Wang, Jingsen Zhang, Hao Yang, Zhiyuan Chen, Jiakai Tang, Zeyu Zhang, Xu Chen, Yankai Lin, Ruihua Song, Wayne Xin Zhao, et al.',\n",
       "  'Conference': 'arXiv preprint ArXiv:2306.02552 (2023)',\n",
       "  'citation_count': {'value': 22, 'date': '2025-01-28 21:46:45'}},\n",
       " 18: {'Title': 'Rec-mind: Large language model powered agent for recommendation',\n",
       "  'Author(s)': 'Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah Cho, Xing Fan, Xiaojiang Huang, Yanbin Lu, and Yingzhen Yang',\n",
       "  'Conference': 'arXiv preprint arXiv:2308.14296 (2023)',\n",
       "  'citation_count': {'value': 97, 'date': '2025-01-28 21:46:50'}},\n",
       " 19: {'Title': 'Intelligent agents: Theory and practice',\n",
       "  'Author(s)': 'Michael Wooldridge and Nicholas R Jennings',\n",
       "  'Conference': 'The knowledge engineering review 10, 2 (1995), 115–152',\n",
       "  'citation_count': {'value': 11878, 'date': '2025-01-28 21:46:54'}},\n",
       " 20: {'Title': 'Autogen: Enabling next-gen llm applications via multi-agent conversation framework',\n",
       "  'Author(s)': 'Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang',\n",
       "  'Conference': 'arXiv preprint arXiv:2308.08155 (2023)',\n",
       "  'citation_count': {'value': 692, 'date': '2025-01-28 21:46:57'}},\n",
       " 21: {'Title': 'React: Synergizing reasoning and acting in language models',\n",
       "  'Author(s)': 'Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao',\n",
       "  'Conference': 'arXiv preprint arXiv:2210.03629 (2022)',\n",
       "  'citation_count': {'value': 2096, 'date': '2025-01-28 21:46:59'}},\n",
       " 22: {'Title': 'Glm-130b: An open bilingual pre-trained model',\n",
       "  'Author(s)': 'Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al.',\n",
       "  'Conference': 'arXiv preprint arXiv:2210.02414 (2022)',\n",
       "  'citation_count': {'value': 589, 'date': '2025-01-28 21:47:05'}},\n",
       " 23: {'Title': 'On generative agents in recommendation',\n",
       "  'Author(s)': 'An Zhang, Leheng Sheng, Yuxin Chen, Hao Li, Yang Deng, Xiang Wang, and Tat-Seng Chua',\n",
       "  'Conference': 'arXiv preprint arXiv:2310.10108 (2023)',\n",
       "  'citation_count': {'value': 91, 'date': '2025-01-28 21:47:11'}},\n",
       " 24: {'Title': 'Building cooperative embodied agents modularly with large language models',\n",
       "  'Author(s)': 'Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B Tenenbaum, Tianmin Shu, and Chuang Gan',\n",
       "  'Conference': 'arXiv preprint arXiv:2307.02485 (2023)',\n",
       "  'citation_count': {'value': 85, 'date': '2025-01-28 21:47:17'}},\n",
       " 25: {'Title': 'Agentcf: Collaborative learning with autonomous language agents for recommender systems',\n",
       "  'Author(s)': 'Junjie Zhang, Yupeng Hou, Ruobing Xie, Wenqi Sun, Julian McAuley, Wayne Xin Zhao, Leyu Lin, and Ji-Rong Wen',\n",
       "  'Conference': 'arXiv preprint arXiv:2310.09233 (2023)',\n",
       "  'citation_count': {'value': 55, 'date': '2025-01-28 21:47:24'}}}"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_dict_with_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61e0017-fc4d-4294-a3a0-eb7bdb838545",
   "metadata": {},
   "source": [
    "# Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "0b498e03-46ef-4f68-a259-e88a2ec13f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "0e4bec72-a1ea-4387-bccc-3e0124a44a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "2a3934f9-c286-4226-bdcb-8eaeab76fe61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1:\n",
      "Title: Patent classification by fine-tuning BERT language model\n",
      "Authors and Year: JS Lee, J Hsiang - World Patent Information, 2020 - Elsevier\n",
      "Snippet: … In this work we focus on fine-tuning a pre-trained BERT model and applying it to patent … Our \n",
      "contributions include: (1) a new state-of-the-art result based on pre-trained BERT model and …\n",
      "Link: https://www.sciencedirect.com/science/article/pii/S0172219019300742\n",
      "Citation Count: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Result 2:\n",
      "Title: BERT has a mouth, and it must speak: BERT as a Markov random field language model\n",
      "Authors and Year: A Wang, K Cho - arXiv preprint arXiv:1902.04094, 2019 - arxiv.org\n",
      "Snippet: … these questions by showing that BERT is a combination of a Markov random field language \n",
      "… BERT are well-formed and are assigned high probabilities by an off-theshelf language model…\n",
      "Link: https://arxiv.org/abs/1902.04094\n",
      "Citation Count: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Result 3:\n",
      "Title: BERT: a review of applications in natural language processing and understanding\n",
      "Authors and Year: MV Koroteev - arXiv preprint arXiv:2103.11943, 2021 - arxiv.org\n",
      "Snippet: … language models - BERT. The paper describes the mechanism of operation of this model, … \n",
      ", comparisons with similar models in each task, as well as a description of some proprietary …\n",
      "Link: https://arxiv.org/abs/2103.11943\n",
      "Citation Count: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Result 4:\n",
      "Title: What BERT is not: Lessons from a new suite of psycholinguistic diagnostics for language models\n",
      "Authors and Year: A Ettinger - Transactions of the Association for Computational …, 2020 - direct.mit.edu\n",
      "Snippet: … apply these diagnostics to the popular BERT model, finding that it can … BERT model here \n",
      "as an illustrative case study, these diagnostics are applicable for testing of any language model…\n",
      "Link: https://direct.mit.edu/tacl/article-abstract/doi/10.1162/tacl_a_00298/43535\n",
      "Citation Count: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Result 5:\n",
      "Title: Adapt or get left behind: Domain adaptation through BERT language model finetuning for aspect-target sentiment classification\n",
      "Authors and Year: A Rietzler, S Stabinger, P Opitz, S Engl - arXiv preprint arXiv:1908.11860, 2019 - arxiv.org\n",
      "Snippet: … In addition, to explore the real-world robustness of our models, we perform cross-… BERT \n",
      "language model performs significantly better than strong baseline models like vanilla BERT-…\n",
      "Link: https://arxiv.org/abs/1908.11860\n",
      "Citation Count: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Result 6:\n",
      "Title: What does BERT learn about the structure of language?\n",
      "Authors and Year: G Jawahar, B Sagot, D Seddah - ACL 2019-57th Annual Meeting of …, 2019 - inria.hal.science\n",
      "Snippet: … if this holds true for models not trained with a traditional language modeling objective, such \n",
      "as BERT. Even if it does, would the information be present in multiple layers of the model? To …\n",
      "Link: https://inria.hal.science/hal-02131630/\n",
      "Citation Count: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Result 7:\n",
      "Title: Roberta: A robustly optimized bert pretraining approach\n",
      "Authors and Year: Y Liu, M Ott, N Goyal, J Du, M Joshi, D Chen… - arXiv preprint arXiv …, 2019 - arxiv.org\n",
      "Snippet: … ; (3) Our training improvements show that masked language model pretraining, under the \n",
      "right design choices, is competitive with all other recently published methods. We release our …\n",
      "Link: https://arxiv.org/abs/1907.11692\n",
      "Citation Count: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Result 8:\n",
      "Title: What the [mask]? making sense of language-specific BERT models\n",
      "Authors and Year: D Nozza, F Bianchi, D Hovy - arXiv preprint arXiv:2003.02912, 2020 - arxiv.org\n",
      "Snippet: … trained on a corpus of 104 languages, which can serve as a universal language model. This \n",
      "… models. This paper presents the current state of the art in language-specific BERT models, …\n",
      "Link: https://arxiv.org/abs/2003.02912\n",
      "Citation Count: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Result 9:\n",
      "Title: [HTML][HTML] Using the contextual language model BERT for multi-criteria classification of scientific articles\n",
      "Authors and Year: AK Ambalavanan, MV Devarakonda - Journal of biomedical informatics, 2020 - Elsevier\n",
      "Snippet: … The performance impact of the modern contextual language models on the task is also not \n",
      "… BERT model pre-trained on a corpus of scientific articles, as the core model in our study. The …\n",
      "Link: https://www.sciencedirect.com/science/article/pii/S1532046420302069\n",
      "Citation Count: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Result 10:\n",
      "Title: Re-bert: automatic extraction of software requirements from app reviews using bert language model\n",
      "Authors and Year: AF de Araújo, RM Marcacini - Proceedings of the 36th annual ACM …, 2021 - dl.acm.org\n",
      "Snippet: … language models to generate semantic textual representations with contextual word embeddings. \n",
      "Our RE-BERT performs fine-tuning of the BERT model … RE-BERT outperforms existing …\n",
      "Link: https://dl.acm.org/doi/abs/10.1145/3412841.3442006\n",
      "Citation Count: 0\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyeongchanlee/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/soupsieve/css_parser.py:862: FutureWarning: The pseudo class ':contains' is deprecated, ':-soup-contains' should be used moving forward.\n",
      "  warnings.warn(  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_citation_count_using_scholarly(ref_paper_title):\n",
    "    url = f\"https://scholar.google.com/scholar?q={ref_paper_title}\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    # 상태 코드 확인\n",
    "    if response.status_code == 200:\n",
    "        # HTML 파싱\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        # 논문 제목과 관련 정보 추출\n",
    "        results = soup.select(\".gs_ri\")\n",
    "        for one_paper_box_html in results:\n",
    "            html_code = results\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"\"\"Parse the given HTML code like the given format. Never answer the other comments but formatted information.\n",
    "                        \n",
    "                        HTML : {one_paper_box_html}\n",
    "                        \n",
    "                        Format example : \n",
    "                        {{\n",
    "                            \"title\" : \"Language models are few-shot learners\",\n",
    "                            \"authors\" : \"T Brown, B Mann, N Ryder\",\n",
    "                            \"citation_count\" : 39209\n",
    "                        }}\n",
    "                        \"\"\"\n",
    "                    },\n",
    "                ]\n",
    "            )\n",
    "            answer = response.choices[0].message.content\n",
    "            llm_parsed_result = eval(answer.replace(\"```json\", \"\").replace(\"```\", \"\"))\n",
    "            \n",
    "    else:\n",
    "        print(f\"Failed to fetch the page. Status code: {response.status_code}\")\n",
    "\n",
    "# 테스트 실행\n",
    "request_google_scholar_url(\"BERT language model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e7ea68dc-8355-4800-8655-bfe4057824f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Trends in distributed artificial intelligence'"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = ref_paper_title\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "065fc204-ffcd-4f0a-bc09-85602e719797",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://scholar.google.com/scholar?q={query}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "cbcd7e67-09ef-4ae0-96e6-c70a190a6d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://scholar.google.com/scholar?q=Trends in distributed artificial intelligence'"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "0edf9815-3d13-4cf3-ab97-b5930114a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "cfd4cd1c-9764-4627-b425-f433330dd46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b6bcc8ed-2577-4928-a0d9-6fa923bc773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "7e525685-76cd-4a67-80f0-2a46361e3024",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = soup.select(\".gs_ri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "7c467c53-517d-4b75-8ffc-90cf488a60f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1:\n",
      "Title: Trends in distributed artificial intelligence\n",
      "Authors and Year: B Chaib-Draa, B Moulin, R Mandiau, P Millot - Artificial Intelligence Review, 1992 - Springer\n",
      "Snippet: Distributed artificial intelligence (DAI) is a subfield of artificial intelligence that deals with interactions of intelligent agents. Precisely, DAI attempts to construct intelligent agents that make decisions that allow them to achieve their goals in a world populated by other intelligent agents with their own goals. This paper discusses major concepts used in DAI today. To do this, a taxonomy of DAI is presented, based on the social abilities of an individual agent, the organization of agents, and the dynamics of this organization through …\n",
      "Link: https://link.springer.com/article/10.1007/BF00155579\n"
     ]
    }
   ],
   "source": [
    "for i, result in enumerate(results):\n",
    "    title = result.select_one(\".gs_rt\").text\n",
    "    authors_and_year = result.select_one(\".gs_a\").text\n",
    "    snippet = result.select_one(\".gs_rs\").text if result.select_one(\".gs_rs\") else \"No snippet available\"\n",
    "    link = result.select_one(\".gs_rt a\")[\"href\"] if result.select_one(\".gs_rt a\") else \"No link available\"\n",
    "\n",
    "    print(f\"Result {i+1}:\")\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Authors and Year: {authors_and_year}\")\n",
    "    print(f\"Snippet: {snippet}\")\n",
    "    print(f\"Link: {link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5baaa9e-7687-4357-9fb4-f05326a5e617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0436f-657d-4e59-9268-c20fdc5e6ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8e12b8-35b0-49a8-9c1d-c5737d373a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d4b4e1-c3be-4c41-abd5-d57b2e6b29ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6ae6e4cc-8db0-4b09-812a-adfd4671acdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Google Scholar 검색 URL\n",
    "query = \"MACRec: A Multi-Agent Collaboration Framework for Recommendation\"\n",
    "url = f\"https://scholar.google.com/scholar?q={query}\"\n",
    "\n",
    "# 요청 헤더 설정 (실제 브라우저에서의 요청처럼 위장)\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# GET 요청 보내기\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# 상태 코드 확인\n",
    "if response.status_code == 200:\n",
    "    # HTML 파싱\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # 논문 제목과 관련 정보 추출\n",
    "    results = soup.select(\".gs_ri\")\n",
    "    for i, result in enumerate(results):\n",
    "        title = result.select_one(\".gs_rt\").text\n",
    "        authors_and_year = result.select_one(\".gs_a\").text\n",
    "        snippet = result.select_one(\".gs_rs\").text if result.select_one(\".gs_rs\") else \"No snippet available\"\n",
    "        link = result.select_one(\".gs_rt a\")[\"href\"] if result.select_one(\".gs_rt a\") else \"No link available\"\n",
    "\n",
    "        print(f\"Result {i+1}:\")\n",
    "        print(f\"Title: {title}\")\n",
    "        print(f\"Authors and Year: {authors_and_year}\")\n",
    "        print(f\"Snippet: {snippet}\")\n",
    "        print(f\"Link: {link}\")\n",
    "        print(\"-\" * 80)\n",
    "else:\n",
    "    print(f\"Failed to fetch the page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "18550f4c-75df-41fe-b332-1d0859402af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "331fcc6e-afaa-4de8-913b-d7bcb8bef5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response saved to response.html. Open it in a browser to check if it's a Captcha page.\n"
     ]
    }
   ],
   "source": [
    "# 응답 HTML 저장 및 확인\n",
    "with open(\"response.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "print(\"Response saved to response.html. Open it in a browser to check if it's a Captcha page.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526eb4b8-0bce-4d0e-a215-ff645172193d",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a362ef7e-8661-491c-8b86-afc010800dd3",
   "metadata": {},
   "source": [
    "https://medium.com/kx-systems/rag-llamaparse-advanced-pdf-parsing-for-retrieval-c393ab29891b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf6aaa7-1786-4de6-9c1f-7636a64e0e8d",
   "metadata": {},
   "source": [
    "https://www.devkuma.com/docs/d3-js/append/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb2d5d8-1805-49df-9269-55025219bd13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recom_paper_crawling",
   "language": "python",
   "name": "recom_paper_crawling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
