{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e8e19a8-e328-46a7-8c15-d0c3746c544e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.vector_stores.kdbai import KDBAIVectorStore\n",
    "from getpass import getpass\n",
    "import kdbai_client as kdbai\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc341bf4-fc1e-45db-92d9-b16b234968c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama-parse is async-first, running the async code in a notebook requires the use of nest_asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "# API access to llama-cloud\n",
    "# os.environ[\"LLAMA_CLOUD_API_KEY\"] = os.getenv('LLAMA_CLOUD_API_KEY')\n",
    "\n",
    "KDBAI_ENDPOINT = (os.environ[\"KDBAI_ENDPOINT\"] if \"KDBAI_ENDPOINT\" in os.environ else input(\"KDB.AI endpoint: \"))\n",
    "KDBAI_API_KEY = (os.environ[\"KDBAI_API_KEY\"] if \"KDBAI_API_KEY\" in os.environ else getpass(\"KDB.AI API key: \"))\n",
    "\n",
    "#connect to KDB.AI\n",
    "session = kdbai.Session(api_key=KDBAI_API_KEY, endpoint=KDBAI_ENDPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7665c95-00d5-4b28-ab74-9f652f72e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect with kdbai database\n",
    "db = session.database(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2323dfcb-70fc-4275-89fb-71c4fabf4b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The schema contains two metadata columns (document_id, text) and one embeddings column\n",
    "schema = [\n",
    "        dict(name=\"document_id\", type=\"str\"),\n",
    "        dict(name=\"text\", type=\"str\"),\n",
    "        dict(name=\"embeddings\", type=\"float32s\"),\n",
    "    ]\n",
    "\n",
    "# indexflat, define the index name, type, column to apply the index to (embeddings)\n",
    "# and params which include thesearch metric (Euclidean distance), and dims\n",
    "indexFlat = {\n",
    "        \"name\": \"flat\",\n",
    "        \"type\": \"flat\",\n",
    "        \"column\": \"embeddings\",\n",
    "        \"params\": {'dims': 1536, 'metric': 'L2'},\n",
    "    }\n",
    "\n",
    "KDBAI_TABLE_NAME = \"LlamaParse_Table\"\n",
    "\n",
    "# First ensure the table does not already exist\n",
    "try:\n",
    "    db.table(KDBAI_TABLE_NAME).drop()\n",
    "except kdbai.KDBAIException:\n",
    "    pass\n",
    "\n",
    "#Create the table\n",
    "table = db.create_table(table=KDBAI_TABLE_NAME, schema=schema, indexes=[indexFlat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04bae3a7-f981-4e1c-9ba7-533dfb7aed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL  = \"text-embedding-3-small\"\n",
    "GENERATION_MODEL = \"gpt-4o\"\n",
    "\n",
    "llm = OpenAI(model=GENERATION_MODEL)\n",
    "embed_model = OpenAIEmbedding(model=EMBEDDING_MODEL)\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "pdf_file_name = './MACRec.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b900c37-275e-419c-b6a9-29c901983541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id aa583c54-abd1-4eee-947a-f13adbfc51c2\n",
      ".."
     ]
    }
   ],
   "source": [
    "# parsing_instructions = '''The document titled \"LLM In-Context Recall is Prompt Dependent\" is an academic preprint from April 2024, authored by Daniel Machlab and Rick Battle from the VMware NLP Lab. It explores the in-context recall capabilities of Large Language Models (LLMs) using a method called \"needle-in-a-haystack,\" where a specific factoid is embedded in a block of unrelated text. The study investigates how the recall performance of various LLMs is influenced by the content of prompts and the biases in their training data. The research involves testing multiple LLMs with varying context window sizes to assess their ability to recall information accurately when prompted differently. The paper includes detailed methodologies, results from numerous tests, discussions on the impact of prompt variations and training data, and conclusions on improving LLM utility in practical applications. It contains many tables. Answer questions using the information in this article and be precise.'''\n",
    "# print(parsing_instructions)\n",
    "\n",
    "documents = LlamaParse(\n",
    "    result_type=\"markdown\", \n",
    "    # parsing_instructions=parsing_instructions\n",
    ").load_data(pdf_file_name)\n",
    "# print(documents[0].text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adc4634d-1439-40b1-b19e-13e567dffb21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1---------------------------------------------------------------------------------------------------\n",
      "# MACRec: a Multi-Agent Collaboration Framework for Recommendation\n",
      "\n",
      "Zhefan Wang∗\n",
      "\n",
      "DCST, Tsinghua University\n",
      "\n",
      "Beijing 100084, China\n",
      "\n",
      "wzf23@mails.tsinghua.edu.cn\n",
      "\n",
      "Yuanqing Yu∗\n",
      "\n",
      "DCST, Tsinghua University\n",
      "\n",
      "Beijing 100084, China\n",
      "\n",
      "yyq23@mails.tsinghua.edu.cn\n",
      "\n",
      "Wendi Zheng\n",
      "\n",
      "DCST, Tsinghua University\n",
      "\n",
      "Beijing 100084, China\n",
      "\n",
      "zhengwd23@mails.tsinghua.edu.cn\n",
      "\n",
      "Weizhi Ma†\n",
      "\n",
      "AIR, Tsinghua University\n",
      "\n",
      "Beijing 100084, China\n",
      "\n",
      "mawz@tsinghua.edu.cn\n",
      "\n",
      "Min Zhang†\n",
      "\n",
      "DCST, Tsinghua University\n",
      "\n",
      "Beijing 100084, China\n",
      "\n",
      "z-m@tsinghua.edu.cn\n",
      "\n",
      "arXiv:2402.15235v3 [cs.IR] 1 Nov 2024\n",
      "\n",
      "# ABSTRACT\n",
      "\n",
      "LLM-based agents have gained considerable attention for their decision-making skills and ability to handle complex tasks. Recognizing the current gap in leveraging agent capabilities for multi-agent collaboration in recommendation systems, we introduce MACRec, a novel framework designed to enhance recommendation systems through multi-agent collaboration. Unlike existing work on using agents for user/item simulation, we aim to deploy multi-agents to tackle recommendation tasks directly. In our framework, recommendation tasks are addressed through the collaborative efforts of various specialized agents, including Manager, User/Item Analyst, Reflector, Searcher, and Task Interpreter, with different working flows. Furthermore, we provide application examples of how developers can easily use MACRec on various recommendation tasks, including rating prediction, sequential recommendation, conversational recommendation, and explanation generation of recommendation results. The framework and demonstration video are publicly available at https://github.com/wzf2000/MACRec.\n",
      "\n",
      "# 1 INTRODUCTION\n",
      "\n",
      "Recommender systems (RSs) play a vital role in improving user experience and platform economic benefits, which have become an essential part of various domains, such as e-commerce, social media, and so on. Currently, the advancement of Large Language Models (LLMs) [1, 9, 15, 22] has introduced LLM-based agents [7, 10, 21] capable of completing complex tasks. These agents’ semantic understanding, planning, and decision-making skills unlock new potentials for more nuanced and context-aware recommendations. Researchers have started to utilize the capabilities of agents to solve recommendation tasks. Existing work like [17, 23, 25] primarily focuses on employing agents for simulating user or item behaviors, providing insights into user preferences but falling short of integration into RSs. On the other hand, some studies [5, 18] attempt to leverage the capabilities of agents to directly build a recommender, primarily using one single agent with planning and memory components and auxiliary tools (e.g., search engine). However, there are various complex decision-making tasks in recommendation scenarios [13, 14], on which single-agent instances are unable to perform well. Multi-agent collaboration, which is near to human workflows, is believed to accomplish complex tasks better with collective intelligence. Although work [11] proposes a multi-agent recommendation framework, it only has limited agent types and a fixed collaboration mode.\n",
      "\n",
      "# CCS CONCEPTS\n",
      "\n",
      "• Information systems → Recommender systems.\n",
      "\n",
      "# KEYWORDS\n",
      "\n",
      "Multi-agents; Large Language Models; Recommender Systems\n",
      "\n",
      "# ACM Reference Format:\n",
      "\n",
      "Zhefan Wang, Yuanqing Yu, Wendi Zheng, Weizhi Ma, and Min Zhang. 2024. MACRec: a Multi-Agent Collaboration Framework for Recommendation. In Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ’24), July 14–18, 2024, Washington, DC, USA. ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/3626772.3657669\n",
      "\n",
      "∗Both authors contributed equally to this research.\n",
      "\n",
      "†Corresponding author. This work is supported by the Natural Science Foundation of China (Grant No. U21B2026, 62372260).\n",
      "\n",
      "Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s).\n",
      "\n",
      "SIGIR ’24, July 14–18, 2024, Washington, DC, USA\n",
      "\n",
      "© 2024 Copyright held by the owner/author(s).\n",
      "\n",
      "ACM ISBN 979-8-4007-0431-4/24/07.\n",
      "\n",
      "https://doi.org/10.1145/3626772.3657669\n",
      "2---------------------------------------------------------------------------------------------------\n",
      "# SIGIR ’24, July 14–18, 2024, Washington, DC, USA\n",
      "\n",
      "Zhefan Wang, Yuanqing Yu, Wendi Zheng, Weizhi Ma, & Min Zhang\n",
      "\n",
      "# Table 1: Comparison between previous work and our MACRec\n",
      "\n",
      "Note that Single-type Agents indicate all agents serve the same role (e.g., users), while Multi-type Agents refer to agents having multiple roles and capabilities (e.g., managers, reflectors).\n",
      "\n",
      "|Model|Objectives|Single-type Agents|Multi-type Agents|Diverse Rec. Scenarios|Open-source|\n",
      "|---|---|---|---|---|---|\n",
      "|RecAgent [17]|User Simulation|!| | |!|\n",
      "|Agent4Rec [23]|User Simulation|!| | |!|\n",
      "|AgentCF [25]|U-I Inter Simulation| |!| | |\n",
      "|RAH [11]|Recommender| |!| | |\n",
      "|RecMind [18]|Recommender|!| | |!|\n",
      "|InteRecAgent [5]|Recommender|!| | | |\n",
      "|MACRec|Recommender|!|!|!| |\n",
      "\n",
      "Varying requirements for agents in different scenarios, we show case examples of selecting and customizing agents to collaborate on diverse recommendation tasks. Furthermore, we developed an online web interface for our MACRec, providing a user-friendly visualization of the agents’ collaboration process. The main strengths of this work can be summarized as follows:\n",
      "\n",
      "- A New Multi-agent Collaboration Framework for Recommendation. Unlike previous studies focused on user/item simulation with agents, we propose a new multi-agent collaboration framework for recommendation MACRec. In this framework, agents with different abilities work collaboratively to tackle specific recommendation tasks.\n",
      "- Diverse Applications on Recommendation Scenarios. We present application examples on various recommendation scenarios, including rating prediction, sequential recommendation, explanation generation, and conversational recommendation.\n",
      "- A User-friendly Online Web Interface. We developed an online web interface for MACRec, visualizing how agents collaboratively tackle tasks.\n",
      "\n",
      "# 2.2 Multi-agent Collaboration\n",
      "\n",
      "Multi-agent systems, initially grounded in DAI [2] and MAS [12], evolved with foundational concepts of agent coordination and communication by Wooldridge and Jennings [19]. The advent of powerful LLMs [1, 9, 15, 22] has shifted focus towards their application in multi-agent collaboration. Brown et al. [1] demonstrated LLMs’ potential in human-like dialogues, applicable to agent-agent communication. Nascimento et al. [8], Vinyals et al. [16] illustrate how LLM agents can collaborate for shared objectives, achieving specific and complex task solutions. Recent work [3, 4, 24] leverage multi-agent collaboration to achieve better performance on complex tasks. CAMEL [6] and AutoGen [20] focus on communicative agent systems for complex task solutions through inter-agent dialogue. However, existing research on multi-agent collaboration has not investigated its potential in recommendation scenarios.\n",
      "\n",
      "# 2.1 Agents-based Recommendation\n",
      "\n",
      "Currently, research on integrating LLM-based agents for recommendation can be categorized into two primary orientations: simulation-oriented and recommender-oriented approaches. Table 1 compares our MACRec and previous agents-based work.\n",
      "\n",
      "The simulation-oriented work focuses on using agents to simulate user behaviors and item characteristics in RSs. RecAgent [23] and Agent4Rec [17] both propose to use agents as user simulators to empower the evaluation of RSs, which feature single-type agents (as users). AgentCF [25] explores the simulation of user-item interactions through user-agents and item-agents. It belongs to a multi-type agent system, with only two types and simple interactions. This line of research aims to provide a deeper understanding of user preferences but falls short of integration into RSs.\n",
      "\n",
      "The goal of recommender-oriented studies is to build a \"recommender agent\" with planning and memory components to tackle recommendation tasks. InteRecAgent [5] and RecMind [18] primarily focus on improving a single recommender agent’s planning and reflection ability. RAH [11] proposes a human-centered framework using LLM Agents as assistants. It supports collaboration.\n",
      "\n",
      "# 3 THE MACREC FRAMEWORK\n",
      "\n",
      "# 3.1 Framework Overview\n",
      "\n",
      "Figure 1 illustrates our proposed multi-agent collaboration recommendation framework. A sequential recommendation task is given as an example.\n",
      "\n",
      "As shown in the example in Figure 1, the Task Interpreter first translates the task in a better way to understand. Then, as the central component of the entire system, the Manager starts calling other agents to obtain detailed analyses of the user and items. These agents, including the Searcher and the User/Item Analyst, support the call of some tools, e.g., the Searcher has access to the search engine and the User/Item Analyst can access detailed information about users and items. After receiving responses from the Searcher and Analyst, the Manager will attempt to provide an answer, i.e., give a ranking order of the candidate sets. The Reflector will be responsible for analyzing and reflecting on the Manager’s answer in the last trial and giving suggestions, e.g., modifying the answer format to follow the task requirements. Eventually, the Manager.\n",
      "3---------------------------------------------------------------------------------------------------\n",
      "# MACRec: a Multi-Agent Collaboration Framework for Recommendation\n",
      "\n",
      "# SIGIR ’24, July 14–18, 2024, Washington, DC, USA\n",
      "\n",
      "# Task: Sequential Recommendation\n",
      "\n",
      "User ID: 46\n",
      "\n",
      "Candidate Item ID: [849, 376, 291, 125, 151, 132, 16, 814]\n",
      "\n",
      "Rank the above candidates for the user:\n",
      "\n",
      "UserInfo [UserID: 46]\n",
      "\n",
      "Finish:\n",
      "\n",
      "The user 46 is a 27-year-old female marketing professional who has interacted with a variety of movie genres including Drama, Sci-Fi, Adventure, Childrens, and Comedy:\n",
      "\n",
      "ItemInfo [ItemID: 849]\n",
      "\n",
      "Finish:\n",
      "\n",
      "The movie 'Days of Thunder' (1990) has been interacted with by users of various ages and genders, indicating a broad appeal across different demographics.\n",
      "\n",
      "ItemAnalyst\n",
      "\n",
      "Output: [151, 125, 814, 291, 376, 132, 849, 16]\n",
      "\n",
      "Figure 1: The Framework of MACRec. We take a sequential recommendation task as an example to show how these agents work collaboratively.\n",
      "\n",
      "According to user_46's preference, give a rank order of the following will reattempt to solve the task based on the reflections and provide a more reasonable answer, e.g., adding the missed item ID.\n",
      "\n",
      "The following sections will detail each agent’s specific characteristics and functions.\n",
      "\n",
      "# 3.2 Agent Roles\n",
      "\n",
      "# 3.2.1 Manager\n",
      "\n",
      "For the given task, the Manager would assign sub-tasks to other agents and complete the main execution process. It oversees the collaboration among all other agents.\n",
      "\n",
      "The Manager always performs the three steps of Thought, Action, and Observation alternately. In the Thought phase, the Manager reasons about the current situation of the task (e.g., whether the analysis is sufficient, whether additional information is needed, etc.). During the Action phase, the Manager can choose to give an answer to end the task or seek help from other agents (under a particular interface format). Responses given by other agents will be given in the Observation phase of the Manager.\n",
      "\n",
      "# 3.2.2 Reflector\n",
      "\n",
      "The Reflector is responsible for judging the correctness of the answer given by the Manager. A further reflection will be given if the Reflector determines the answer is correct. The Reflector will step in when the Manager is about to perform the second or more runs on the same task input. If the Reflector judges that the answer given by the Manager has no room for improvement, the Manager will no longer perform the current run. Otherwise, the Reflector will further summarize where the Manager can be improved, e.g., not considering the few highly rated items/movies in the user’s historical interactions.\n",
      "\n",
      "# 3.2.3 User/Item Analyst\n",
      "\n",
      "User/Item Analyst specializes in examining and understanding the characteristics and preferences of users, as well as the attributes of items. The Analyst will be given access to two tools to assist in the analysis, including info database and interaction retriever. The Analyst can get the user profile of each user and the attributes of each item through the info database. Through the interaction retriever, the Analyst can get the user/item interaction history before the current time. With the combination of these two tools, the Analyst can have an in-depth analysis of the user or the item.\n",
      "\n",
      "# 3.2.4 Searcher\n",
      "\n",
      "The Searcher is responsible for searching under the requirements given by the Manager with the search tool, and finally summarizing the text reply to the Manager. Take Wikipedia as an example of a search tool. The Searcher can give a search query to get the most relevant entry in Wikipedia. The Searcher can further retrieve passages in a specific entry where the given keywords exist. Eventually, the Searcher is asked to summarize the paragraph to respond to the Manager’s query.\n",
      "\n",
      "# 3.2.5 Task Interpreter\n",
      "\n",
      "The Task Interpreter translates the dialogs into executable recommendation tasks. The Task Interpreter will get the conversation history when starts running. Since conversation histories can be long, the Task Interpreter will only get the last part of the history. The Task Interpreter also has access to call the text summarization tool to get a more concise overview of the history. Eventually, the Task Interpreter will give a specific description of the task requirements that will be used to guide the subsequent runs of the Manager.\n",
      "\n",
      "# 4 APPLICATIONS ON RECOMMENDATION SCENARIOS\n",
      "\n",
      "Here, we present the applications of MACRec on four recommendation scenarios. Table 2 summarizes the agents’ selection for each scenario.\n",
      "\n",
      "|Task|U.Analy.|I.Analy.|Reflector|Searcher|Interpreter|\n",
      "|---|---|---|---|---|---|\n",
      "|RP| | | | | |\n",
      "|SR| | | | | |\n",
      "|EG| | | | | |\n",
      "|CR| | | | | |\n",
      "\n",
      "Code is available at https://github.com/wzf2000/MACRec.\n",
      "\n",
      "Table 2: The agents’ selection for four applications supported by MACRec. means required and means optional.\n",
      "4---------------------------------------------------------------------------------------------------\n",
      "# SIGIR ’24, July 14–18, 2024, Washington, DC, USA\n",
      "\n",
      "# Zhefan Wang, Yuanqing Yu, Wendi Zheng, Weizhi Ma, & Min Zhang\n",
      "\n",
      "# ChatSystem for Conversational Recommendation\n",
      "\n",
      "# Tasks\n",
      "\n",
      "Manager: Calling Searcher with movies about history.\n",
      "\n",
      "Manager: Calling Searcher with historical movies similar to Schindler's List.\n",
      "\n",
      "Searcher: Search for movies about history.\n",
      "\n",
      "Searcher: Search for historical movies similar to Schindler's List.\n",
      "\n",
      "Choose a task\n",
      "\n",
      "I have watched the movie Schindler's List recently: Found 3 documents. Their titles: Skin: A History of Nudity in the Movies, List of ghost films, List of drug films.\n",
      "\n",
      "(summary: Schindler's List (Schindler's List is a 1993 American epic historical drama film directed and produced by Steven Spielberg and written by Steven Spielberg).\n",
      "\n",
      "Amistad (film) (Amistad is a 1997 American historical drama film directed by Steven Spielberg, based on the events in 1839 aboard the...\n",
      "\n",
      "System is running...\n",
      "\n",
      "Skin: A History of Nudity in the Movies is a 2020 documentary film about the history of nudity in film. It was directed by Danny Wolf and executive produced by Jim 'Mr: Skin' McBride, who is also interviewed in the film.\n",
      "\n",
      "Interpreter: Summarize input.\n",
      "\n",
      "Searcher: Finish with results:\n",
      "\n",
      "Summarized text: user: I am very touched by the movie Schindler's List.\n",
      "\n",
      "Skin: A History of Nudity in the Movies is a 2020 documentary film about the history of nudity in film.\n",
      "\n",
      "Manager: Response from Searcher with historical movies similar to Schindler's List:\n",
      "\n",
      "Manager: Response from Searcher with movies about history:\n",
      "\n",
      "Can you recommend other movies that can teach me about history like Schindler's List?\n",
      "\n",
      "Search result: Skin: A History of Nudity in the Movies is a 2020 documentary film about the history of nudity in film.\n",
      "\n",
      "Manager: Thought 3: Amistad is a historical movie that can teach about the history of slavery and the fight for freedom: should recommend this movie to the user.\n",
      "\n",
      "Manager: Thought 1: There are many movies that can teach about history, but need to consider the specific themes and time periods that the user is interested in.\n",
      "\n",
      "Manager: Thought 2: Skin: A History of Nudity in the Movies is not relevant to the user's request: need to refine the search to find movies that specifically teach about historical events and themes.\n",
      "\n",
      "a) Interpret the dialog into a task (b) Search for movies about history: Search for movies similar to Schindler's List.\n",
      "\n",
      "# Figure 2:\n",
      "\n",
      "The web interfaces of our MACRec, along with a case of how three agents collaboratively address a conversational recommendation task. The interface is composed by the leftmost configuration panel and the main interaction panel.\n",
      "\n",
      "# 4.1 Rating Prediction (RP)\n",
      "\n",
      "Rating prediction task involves predicting the numerical rating a user might give to an item, such as a movie or a product, based on their preferences and historical interactions.\n",
      "\n",
      "In the rating prediction task, each user will have different rating preferences. The User Analyst can provide a detailed analysis of the user’s historical interactions and preferences. Meanwhile, the Manager also needs characteristic analysis of the target item, which can be provided by the Item Analyst. With the help of two types of Analysts, the Manager can know the user’s tendency to rate and the item’s recent ratings before giving a prediction.\n",
      "\n",
      "# 4.2 Sequential Recommendation (SR)\n",
      "\n",
      "Sequential recommendation systems analyze the sequence of items a user has interacted with to predict their next likely interest.\n",
      "\n",
      "Modeling of user’s long-term and short-term interests is important in sequential recommendation tasks. Hence, the User Analyst’s role is self-evident. The number of relevant items in the sequence is significantly higher than the rating prediction task. It is hard to ask the Item Analyst to analyze every item that appeared in either the history or the candidate set. Moreover, given that the answers to the sequential recommendation task are much more complex (i.e., a ranking order of the candidate set), the Reflector can help to avoid the Manager getting into formatting troubles. A single round of behavioral analysis may omit consideration of long-term user behavior, and reflection on this is something the Reflector can do.\n",
      "\n",
      "# 4.3 Explanation Generation (EG)\n",
      "\n",
      "This task involves generating understandable and relevant explanations for the recommendations provided to users.\n",
      "\n",
      "The explanation generation task also requires a detailed analysis of both the user and the item. In addition, more information about the item may also help the Manager understand the user’s behavior towards it. For example, a user may have similar preferences for multiple movies by the same director. The information about the director may not be contained in the dataset. Retrieving these extra pieces of information is suitable for the Searcher to perform.\n",
      "\n",
      "Figure 2 presents the web interfaces of our framework, along with a detailed case study demonstrating the collaborative efforts of three agents in addressing a conversational recommendation task.\n",
      "\n",
      "The interface can be divided into two main panels. 1) Configuration panel, where users can select different tasks to tackle, such as \"Rating Prediction.\" Users can also customize different systems and configuration files for the task execution. 2) Interaction panel, where the whole collaboration process takes place. Agents with different abilities would complete the task collaboratively.\n",
      "\n",
      "In Figure 2, the user has expressed a preference for the movie \"Schindler’s List\" and seeks recommendations for similar historical movies. The Interpreter summarizes this input and translates it into a clearer task. Then, the Manager calls for the help of the Searcher for two rounds, searching for movies about history and movies similar to \"Schindler’s List\". According to all the information, the Manager gives the final recommendation movie \"Amistad\".\n",
      "\n",
      "# 6 CONCLUSION\n",
      "\n",
      "In this work, we propose a novel LLM-based multi-agent collaboration framework for recommendation, called MACRec. Unlike existing studies on using agents for user/item simulation, we directly tackle recommendation tasks through the collaboration of various agents. We present applications of MACRec on four different recommendation tasks. Moreover, we developed an online web interface for MACRec, visualizing how agents work collaboratively.\n",
      "5---------------------------------------------------------------------------------------------------\n",
      "# MACRec: a Multi-Agent Collaboration Framework for Recommendation\n",
      "\n",
      "# SIGIR ’24, July 14–18, 2024, Washington, DC, USA\n",
      "\n",
      "# REFERENCES\n",
      "\n",
      "1. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877–1901.\n",
      "2. Brahim Chaib-Draa, Bernard Moulin, René Mandiau, and Patrick Millot. 1992. Trends in distributed artificial intelligence. Artificial Intelligence Review 6 (1992), 35–66.\n",
      "3. Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, et al. 2023. Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents. arXiv preprint arXiv:2308.10848 (2023).\n",
      "4. Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch. 2023. Improving Factuality and Reasoning in Language Models through Multiagent Debate. arXiv preprint arXiv:2305.14325 (2023).\n",
      "5. Xu Huang, Jianxun Lian, Yuxuan Lei, Jing Yao, Defu Lian, and Xing Xie. 2023. Recommender ai agent: Integrating large language models for interactive recommendations. arXiv preprint arXiv:2308.16505 (2023).\n",
      "6. Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. 2023. Camel: Communicative agents for \"mind\" exploration of large scale language model society. arXiv preprint arXiv:2303.17760 (2023).\n",
      "7. Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al. 2021. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332 (2021).\n",
      "8. Nathalia Nascimento, Paulo Alencar, and Donald Cowan. 2023. GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems. arXiv preprint arXiv:2308.10435 (2023).\n",
      "9. OpenAI. 2023. GPT-4 Technical Report. arXiv preprint arXiv:2303.08774 (2023).\n",
      "10. Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. 2023. Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface. arXiv preprint arXiv:2303.17580 (2023).\n",
      "11. Yubo Shu, Hansu Gu, Peng Zhang, Haonan Zhang, Tun Lu, Dongsheng Li, and Ning Gu. 2023. RAH! RecSys-Assistant-Human: A Human-Central Recommendation Framework with Large Language Models. arXiv preprint arXiv:2308.09904 (2023).\n",
      "12. Peter Stone and Manuela Veloso. 2000. Multiagent systems: A survey from a machine learning perspective. Autonomous Robots 8 (2000), 345–383.\n",
      "13. Peijie Sun, Yifan Wang, Min Zhang, Chuhan Wu, Yan Fang, Hong Zhu, Yuan Fang, and Meng Wang. 2024. Collaborative-Enhanced Prediction of Spending on Newly Downloaded Mobile Games under Consumption Uncertainty. WWW2024, Industry Track (2024).\n",
      "14. Peijie Sun, Le Wu, Kun Zhang, Xiangzhi Chen, and Meng Wang. 2023. Neighborhood-Enhanced Supervised Contrastive Learning for Collaborative Filtering. IEEE Transactions on Knowledge and Data Engineering (2023).\n",
      "15. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971 (2023).\n",
      "16. Oriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung, David H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, et al. 2019. Grandmaster level in StarCraft II using multi-agent reinforcement learning. Nature 575, 7782 (2019), 350–354.\n",
      "17. Lei Wang, Jingsen Zhang, Hao Yang, Zhiyuan Chen, Jiakai Tang, Zeyu Zhang, Xu Chen, Yankai Lin, Ruihua Song, Wayne Xin Zhao, et al. 2023. When Large Language Model based Agent Meets User Behavior Analysis: A Novel User Simulation Paradigm. arXiv preprint ArXiv:2306.02552 (2023).\n",
      "18. Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah Cho, Xing Fan, Xiaojiang Huang, Yanbin Lu, and Yingzhen Yang. 2023. Rec-mind: Large language model powered agent for recommendation. arXiv preprint arXiv:2308.14296 (2023).\n",
      "19. Michael Wooldridge and Nicholas R Jennings. 1995. Intelligent agents: Theory and practice. The knowledge engineering review 10, 2 (1995), 115–152.\n",
      "20. Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. 2023. Autogen: Enabling next-gen llm applications via multi-agent conversation framework. arXiv preprint arXiv:2308.08155 (2023).\n",
      "21. Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2022. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629 (2022).\n",
      "22. Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al. 2022. Glm-130b: An open bilingual pre-trained model. arXiv preprint arXiv:2210.02414 (2022).\n",
      "23. An Zhang, Leheng Sheng, Yuxin Chen, Hao Li, Yang Deng, Xiang Wang, and Tat-Seng Chua. 2023. On generative agents in recommendation. arXiv preprint arXiv:2310.10108 (2023).\n",
      "24. Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B Tenenbaum, Tianmin Shu, and Chuang Gan. 2023. Building cooperative embodied agents modularly with large language models. arXiv preprint arXiv:2307.02485 (2023).\n",
      "25. Junjie Zhang, Yupeng Hou, Ruobing Xie, Wenqi Sun, Julian McAuley, Wayne Xin Zhao, Leyu Lin, and Ji-Rong Wen. 2023. Agentcf: Collaborative learning with autonomous language agents for recommender systems. arXiv preprint arXiv:2310.09233 (2023).\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(documents, start=1):\n",
    "    print(f\"{i}\".ljust(100, '-'))\n",
    "    print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66f86e59-e556-46cf-804f-8c2ed540741d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 18558.87it/s]\n",
      "1it [00:00, 15650.39it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Parse the documents using MarkdownElementNodeParser\n",
    "node_parser = MarkdownElementNodeParser(llm=llm, num_workers=8).from_defaults()\n",
    "\n",
    "# Retrieve nodes (text) and objects (table)\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "\n",
    "base_nodes, objects = node_parser.get_nodes_and_objects(nodes)\n",
    "\n",
    "# insert the table markdown into the text of each table object\n",
    "for i in range(len(objects)):\n",
    "  ㅁ = objects[i].obj.text[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13911fe1-e63d-49fd-b52e-3c75aad09b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2b516ba5-4f80-4723-85bd-1210fc2131e4</td>\n",
       "      <td>MACRec: a Multi-Agent Collaboration Framework ...</td>\n",
       "      <td>[-0.0010586621, 0.041707043, 0.02925757, 0.029...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a6c378f2-ab9d-46fd-89cb-25f4cf62b35e</td>\n",
       "      <td>SIGIR ’24, July 14–18, 2024, Washington, DC, U...</td>\n",
       "      <td>[-0.0015073667, 0.03517134, 0.057041712, 0.030...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b1dd3c00-1b68-47fc-917d-d2543f7c36a9</td>\n",
       "      <td>Varying requirements for agents in different s...</td>\n",
       "      <td>[-0.004967418, 0.037573203, 0.04944687, 0.0059...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6a286a2e-717a-4419-a3e3-fd5c173631a3</td>\n",
       "      <td>MACRec: a Multi-Agent Collaboration Framework ...</td>\n",
       "      <td>[-0.0118856495, 0.06537797, 0.021507366, 0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2ad81017-66f8-4e74-8598-c902244f810c</td>\n",
       "      <td>Code is available at https://github.com/wzf200...</td>\n",
       "      <td>[-0.018466502, 0.047101013, 0.060254864, 0.020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dfda5935-52df-4254-98a0-58761eb9b69a</td>\n",
       "      <td>SIGIR ’24, July 14–18, 2024, Washington, DC, U...</td>\n",
       "      <td>[-0.027369712, 0.04296594, -0.007082258, 0.006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>224ab1d8-a8f7-4fe9-bdb7-e1a7fa37e50b</td>\n",
       "      <td>Moreover, given that the answers to the sequen...</td>\n",
       "      <td>[-0.013393156, 0.05124579, 0.016177049, 0.0100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>79c2c0d4-1557-43c8-9d29-5fce9c418069</td>\n",
       "      <td>MACRec: a Multi-Agent Collaboration Framework ...</td>\n",
       "      <td>[-0.02555791, 0.009939187, 0.06459412, 0.02189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19d54e30-e5e8-40c1-b1c2-7642ac3adb95</td>\n",
       "      <td>arXiv preprint arXiv:2308.09904 (2023).\\n12. P...</td>\n",
       "      <td>[-0.0062998543, 0.022451159, 0.04597343, 0.013...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5e1b00ab-6c49-417f-80ac-d812d56e0501</td>\n",
       "      <td>2022. Glm-130b: An open bilingual pre-trained ...</td>\n",
       "      <td>[-0.0017179978, -0.0010304812, 0.04113033, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0fceed1d-7f0e-4190-aeb0-4cd188b3f0b8</td>\n",
       "      <td>The table compares different models based on t...</td>\n",
       "      <td>[-0.04988417, 0.02925188, 0.050212536, -0.0178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0e2e8a7f-43dd-46dc-8172-9b0cef171d57</td>\n",
       "      <td>The table lists various tasks (RP, SR, EG, CR)...</td>\n",
       "      <td>[-0.04078693, 0.080757536, 0.07323572, -0.0346...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             document_id  \\\n",
       "0   2b516ba5-4f80-4723-85bd-1210fc2131e4   \n",
       "1   a6c378f2-ab9d-46fd-89cb-25f4cf62b35e   \n",
       "2   b1dd3c00-1b68-47fc-917d-d2543f7c36a9   \n",
       "3   6a286a2e-717a-4419-a3e3-fd5c173631a3   \n",
       "4   2ad81017-66f8-4e74-8598-c902244f810c   \n",
       "5   dfda5935-52df-4254-98a0-58761eb9b69a   \n",
       "6   224ab1d8-a8f7-4fe9-bdb7-e1a7fa37e50b   \n",
       "7   79c2c0d4-1557-43c8-9d29-5fce9c418069   \n",
       "8   19d54e30-e5e8-40c1-b1c2-7642ac3adb95   \n",
       "9   5e1b00ab-6c49-417f-80ac-d812d56e0501   \n",
       "10  0fceed1d-7f0e-4190-aeb0-4cd188b3f0b8   \n",
       "11  0e2e8a7f-43dd-46dc-8172-9b0cef171d57   \n",
       "\n",
       "                                                 text  \\\n",
       "0   MACRec: a Multi-Agent Collaboration Framework ...   \n",
       "1   SIGIR ’24, July 14–18, 2024, Washington, DC, U...   \n",
       "2   Varying requirements for agents in different s...   \n",
       "3   MACRec: a Multi-Agent Collaboration Framework ...   \n",
       "4   Code is available at https://github.com/wzf200...   \n",
       "5   SIGIR ’24, July 14–18, 2024, Washington, DC, U...   \n",
       "6   Moreover, given that the answers to the sequen...   \n",
       "7   MACRec: a Multi-Agent Collaboration Framework ...   \n",
       "8   arXiv preprint arXiv:2308.09904 (2023).\\n12. P...   \n",
       "9   2022. Glm-130b: An open bilingual pre-trained ...   \n",
       "10  The table compares different models based on t...   \n",
       "11  The table lists various tasks (RP, SR, EG, CR)...   \n",
       "\n",
       "                                           embeddings  \n",
       "0   [-0.0010586621, 0.041707043, 0.02925757, 0.029...  \n",
       "1   [-0.0015073667, 0.03517134, 0.057041712, 0.030...  \n",
       "2   [-0.004967418, 0.037573203, 0.04944687, 0.0059...  \n",
       "3   [-0.0118856495, 0.06537797, 0.021507366, 0.003...  \n",
       "4   [-0.018466502, 0.047101013, 0.060254864, 0.020...  \n",
       "5   [-0.027369712, 0.04296594, -0.007082258, 0.006...  \n",
       "6   [-0.013393156, 0.05124579, 0.016177049, 0.0100...  \n",
       "7   [-0.02555791, 0.009939187, 0.06459412, 0.02189...  \n",
       "8   [-0.0062998543, 0.022451159, 0.04597343, 0.013...  \n",
       "9   [-0.0017179978, -0.0010304812, 0.04113033, 0.0...  \n",
       "10  [-0.04988417, 0.02925188, 0.050212536, -0.0178...  \n",
       "11  [-0.04078693, 0.080757536, 0.07323572, -0.0346...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store = KDBAIVectorStore(table)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "#Create the index, inserts base_nodes and objects into KDB.AI\n",
    "recursive_index = VectorStoreIndex(\n",
    "    nodes= base_nodes + objects, storage_context=storage_context\n",
    ")\n",
    "\n",
    "# Query KDB.AI to ensure the nodes were inserted\n",
    "table.query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c20dd18-5cdd-466b-867f-7b9b710dae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def embed_query(query):\n",
    "    query_embedding = client.embeddings.create(\n",
    "            input=query,\n",
    "            model=\"text-embedding-3-small\"\n",
    "        )\n",
    "    return query_embedding.data[0].embedding\n",
    "\n",
    "def retrieve_data(query):\n",
    "    query_embedding = embed_query(query)\n",
    "    results = table.search(vectors={'flat':[query_embedding]},n=5,filter=[('<>','document_id','4a9551df-5dec-4410-90bb-43d17d722918')])\n",
    "    retrieved_data_for_RAG = []\n",
    "    for index, row in results[0].iterrows():\n",
    "      retrieved_data_for_RAG.append(row['text'])\n",
    "    return retrieved_data_for_RAG\n",
    "\n",
    "def RAG(query):\n",
    "  question = \"You will answer this question based on the provided reference material: \" + query\n",
    "  messages = \"Here is the provided context: \" + \"\\n\"\n",
    "  results = retrieve_data(query)\n",
    "  if results:\n",
    "    for data in results:\n",
    "      messages += data + \"\\n\"\n",
    "  response = client.chat.completions.create(\n",
    "      model=\"gpt-4o\",\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": question},\n",
    "          {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "              {\"type\": \"text\", \"text\": messages},\n",
    "          ],\n",
    "          }\n",
    "      ],\n",
    "      # max_tokens=300,\n",
    "  )\n",
    "  content = response.choices[0].message.content\n",
    "  return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9646799a-5734-40b1-96e8-9229cc19bb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 논문의 핵심은 MACRec이라는 새로운 프레임워크를 소개하는 것입니다. MACRec는 LLM 기반의 다중 에이전트 협업 프레임워크로, 추천 시스템에서의 멀티 에이전트 협업을 통해 추천 작업을 직접적으로 해결하는 것을 목표로 합니다. 이 프레임워크는 매니저, 사용자/아이템 분석가, 반성자, 탐색자, 작업 해석자와 같은 여러 전문화된 에이전트들의 협력을 통해 추천 작업을 수행합니다. MACRec는 평가 예측, 순차적 추천, 대화형 추천, 추천 결과 설명 생성과 같은 다양한 추천 작업에 쉽게 활용할 수 있습니다. 이 프레임워크는 특히 단일 에이전트가 수행하기 어려운 복잡한 의사결정 작업에서 유용하며, 인간의 작업 흐름에 가까운 다중 에이전트 협업이 이를 보다 효과적으로 수행할 수 있다고 설명합니다. \"In this work, we propose a novel LLM-based multi-agent collaboration framework for recommendation, called MACRec. Unlike existing studies on using agents for user/item simulation, we directly tackle recommendation tasks through the collaboration of various agents.\"(본문에서 발췌)\n"
     ]
    }
   ],
   "source": [
    "print(RAG(\"이 논문의 핵심은 뭐야? 본문의 내용을 인용/발췌해서 설명해줘. 한글로 대답해.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f672d5-eb16-49af-a473-d5cf426f1744",
   "metadata": {},
   "source": [
    "# Reference 파싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1f5a8cd-8010-498f-9d02-949eed682c8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "answer = RAG(f\"\"\"Find this paper's References. Give me that References with the given json form. Don't return any other comments except that References\n",
    "\n",
    "EXAMPLE : \n",
    "{{\n",
    "    1 : {{\n",
    "    \"Title\" : \"Language models are few-shot learners\",\n",
    "    \"Author(s)\" : \"Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al\",\n",
    "    \"Conference\" : \"Advances in neural information processing systems 33 (2020), 1877–1901\"\n",
    "    }},\n",
    "    2 : {{\n",
    "        ...\n",
    "    }},\n",
    "    ...\n",
    "}}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "125bf082-3b17-405c-8ab1-6072b9c97573",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_dict = eval(answer.replace(\"```json\\n\", \"\").replace(\"```\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83fc0c1c-1525-41db-b162-03774710adbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'Title': 'Language models are few-shot learners',\n",
       "  'Author(s)': 'Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al.',\n",
       "  'Conference': 'Advances in neural information processing systems 33 (2020), 1877–1901'},\n",
       " 2: {'Title': 'Trends in distributed artificial intelligence',\n",
       "  'Author(s)': 'Brahim Chaib-Draa, Bernard Moulin, René Mandiau, and Patrick Millot',\n",
       "  'Conference': 'Artificial Intelligence Review 6 (1992), 35–66'},\n",
       " 3: {'Title': 'Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents',\n",
       "  'Author(s)': 'Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, et al.',\n",
       "  'Conference': 'arXiv preprint arXiv:2308.10848 (2023)'},\n",
       " 4: {'Title': 'Improving Factuality and Reasoning in Language Models through Multiagent Debate',\n",
       "  'Author(s)': 'Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch',\n",
       "  'Conference': 'arXiv preprint arXiv:2305.14325 (2023)'},\n",
       " 5: {'Title': 'Recommender ai agent: Integrating large language models for interactive recommendations',\n",
       "  'Author(s)': 'Xu Huang, Jianxun Lian, Yuxuan Lei, Jing Yao, Defu Lian, and Xing Xie',\n",
       "  'Conference': 'arXiv preprint arXiv:2308.16505 (2023)'},\n",
       " 6: {'Title': \"Camel: Communicative agents for 'mind' exploration of large scale language model society\",\n",
       "  'Author(s)': 'Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem',\n",
       "  'Conference': 'arXiv preprint arXiv:2303.17760 (2023)'},\n",
       " 7: {'Title': 'Webgpt: Browser-assisted question-answering with human feedback',\n",
       "  'Author(s)': 'Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al.',\n",
       "  'Conference': 'arXiv preprint arXiv:2112.09332 (2021)'},\n",
       " 8: {'Title': 'GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems',\n",
       "  'Author(s)': 'Nathalia Nascimento, Paulo Alencar, and Donald Cowan',\n",
       "  'Conference': 'arXiv preprint arXiv:2308.10435 (2023)'},\n",
       " 9: {'Title': 'GPT-4 Technical Report',\n",
       "  'Author(s)': 'OpenAI',\n",
       "  'Conference': 'arXiv preprint arXiv:2303.08774 (2023)'},\n",
       " 10: {'Title': 'Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface',\n",
       "  'Author(s)': 'Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang',\n",
       "  'Conference': 'arXiv preprint arXiv:2303.17580 (2023)'},\n",
       " 11: {'Title': 'RAH! RecSys-Assistant-Human: A Human-Central Recommendation Framework with Large Language Models',\n",
       "  'Author(s)': 'Yubo Shu, Hansu Gu, Peng Zhang, Haonan Zhang, Tun Lu, Dongsheng Li, and Ning Gu',\n",
       "  'Conference': 'arXiv preprint arXiv:2308.09904 (2023)'},\n",
       " 12: {'Title': 'Multiagent systems: A survey from a machine learning perspective',\n",
       "  'Author(s)': 'Peter Stone and Manuela Veloso',\n",
       "  'Conference': 'Autonomous Robots 8 (2000), 345–383'},\n",
       " 13: {'Title': 'Collaborative-Enhanced Prediction of Spending on Newly Downloaded Mobile Games under Consumption Uncertainty',\n",
       "  'Author(s)': 'Peijie Sun, Yifan Wang, Min Zhang, Chuhan Wu, Yan Fang, Hong Zhu, Yuan Fang, and Meng Wang',\n",
       "  'Conference': 'WWW2024, Industry Track (2024)'},\n",
       " 14: {'Title': 'Neighborhood-Enhanced Supervised Contrastive Learning for Collaborative Filtering',\n",
       "  'Author(s)': 'Peijie Sun, Le Wu, Kun Zhang, Xiangzhi Chen, and Meng Wang',\n",
       "  'Conference': 'IEEE Transactions on Knowledge and Data Engineering (2023)'},\n",
       " 15: {'Title': 'Llama: Open and efficient foundation language models',\n",
       "  'Author(s)': 'Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al.',\n",
       "  'Conference': 'arXiv preprint arXiv:2302.13971 (2023)'},\n",
       " 16: {'Title': 'Grandmaster level in StarCraft II using multi-agent reinforcement learning',\n",
       "  'Author(s)': 'Oriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung, David H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, et al.',\n",
       "  'Conference': 'Nature 575, 7782 (2019), 350–354'},\n",
       " 17: {'Title': 'When Large Language Model based Agent Meets User Behavior Analysis: A Novel User Simulation Paradigm',\n",
       "  'Author(s)': 'Lei Wang, Jingsen Zhang, Hao Yang, Zhiyuan Chen, Jiakai Tang, Zeyu Zhang, Xu Chen, Yankai Lin, Ruihua Song, Wayne Xin Zhao, et al.',\n",
       "  'Conference': 'arXiv preprint ArXiv:2306.02552 (2023)'},\n",
       " 18: {'Title': 'Rec-mind: Large language model powered agent for recommendation',\n",
       "  'Author(s)': 'Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah Cho, Xing Fan, Xiaojiang Huang, Yanbin Lu, and Yingzhen Yang',\n",
       "  'Conference': 'arXiv preprint arXiv:2308.14296 (2023)'},\n",
       " 19: {'Title': 'Intelligent agents: Theory and practice',\n",
       "  'Author(s)': 'Michael Wooldridge and Nicholas R Jennings',\n",
       "  'Conference': 'The knowledge engineering review 10, 2 (1995), 115–152'},\n",
       " 20: {'Title': 'Autogen: Enabling next-gen llm applications via multi-agent conversation framework',\n",
       "  'Author(s)': 'Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang',\n",
       "  'Conference': 'arXiv preprint arXiv:2308.08155 (2023)'},\n",
       " 21: {'Title': 'React: Synergizing reasoning and acting in language models',\n",
       "  'Author(s)': 'Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao',\n",
       "  'Conference': 'arXiv preprint arXiv:2210.03629 (2022)'},\n",
       " 22: {'Title': 'Glm-130b: An open bilingual pre-trained model',\n",
       "  'Author(s)': 'Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al.',\n",
       "  'Conference': 'arXiv preprint arXiv:2210.02414 (2022)'},\n",
       " 23: {'Title': 'On generative agents in recommendation',\n",
       "  'Author(s)': 'An Zhang, Leheng Sheng, Yuxin Chen, Hao Li, Yang Deng, Xiang Wang, and Tat-Seng Chua',\n",
       "  'Conference': 'arXiv preprint arXiv:2310.10108 (2023)'},\n",
       " 24: {'Title': 'Building cooperative embodied agents modularly with large language models',\n",
       "  'Author(s)': 'Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B Tenenbaum, Tianmin Shu, and Chuang Gan',\n",
       "  'Conference': 'arXiv preprint arXiv:2307.02485 (2023)'},\n",
       " 25: {'Title': 'Agentcf: Collaborative learning with autonomous language agents for recommender systems',\n",
       "  'Author(s)': 'Junjie Zhang, Yupeng Hou, Ruobing Xie, Wenqi Sun, Julian McAuley, Wayne Xin Zhao, Leyu Lin, and Ji-Rong Wen',\n",
       "  'Conference': 'arXiv preprint arXiv:2310.09233 (2023)'}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f981bfe4-19a5-4ddd-91c5-56c57f40960d",
   "metadata": {},
   "source": [
    "## get_citation_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "583d2842-8c28-4848-bba4-54729bab962f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scholarly import scholarly\n",
    "\n",
    "PAPER_COMPARE_PROMPT = \"\"\"Do the two papers refer to the same paper? If yes, answer YES; otherwise, answer NO.\n",
    "          \n",
    "          A paper title : {a_paper_title}\n",
    "          A paper authors : {a_paper_authors}\n",
    "          \n",
    "          B paper title : {b_paper_title}\n",
    "          B paper authors : {b_paper_authors}\"\"\"\n",
    "\n",
    "def get_citation_count(ref_paper_title, ref_paper_authors, author=None):\n",
    "    # Google Scholar에서 논문 검색\n",
    "    search_query = scholarly.search_pubs(ref_paper_title)\n",
    "    cnt = 0\n",
    "    if not len(search_query._rows):\n",
    "        return None\n",
    "    for result in search_query:\n",
    "        cnt += 1\n",
    "        b_paper_title = result['bib']['title']\n",
    "        b_paper_authors = ', '.join(result['bib']['author'])\n",
    "        if paper_compare(ref_paper_title, ref_paper_authors, b_paper_title, b_paper_authors) == 'YES':\n",
    "            citation_count = result.get('num_citations', 0)  # 인용수 가져오기\n",
    "            return citation_count\n",
    "        if cnt >= 20:\n",
    "            return None\n",
    "\n",
    "def paper_compare(ref_paper_title, ref_paper_authors, b_paper_title, b_paper_authors):\n",
    "    print(f\"\\tref_paper_title : {ref_paper_title}\\n\\t  b_paper_title : {b_paper_title}\")\n",
    "    prompt = PAPER_COMPARE_PROMPT.format(\n",
    "                    a_paper_title=ref_paper_title,\n",
    "                    a_paper_authors=ref_paper_authors,\n",
    "                    b_paper_title=b_paper_title,  # 오타 수정\n",
    "                    b_paper_authors=b_paper_authors\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    answer = response.choices[0].message.content\n",
    "    print(f\"\\t{answer}\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a6d9af6a-bb07-44ff-820c-66e0f60be2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scholarly import scholarly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8b13a10b-fa54-47ab-91b9-4bbad2977766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Camel: Communicative agents for 'mind' exploration of large scale language model society\""
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_paper_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4a0c5cbe-3bcf-4fe7-b94f-7589fd5c2ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_paper_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "99469131-ef53-432f-8ddf-47148e6f65a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = scholarly.search_pubs(ref_paper_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "63acb0f6-a0ba-41e7-bb8a-1a3472c2525c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search_query._rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9ef608e8-2193-4b35-a9d5-257e343e6aa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for result in search_query:\n",
    "    cnt += 1\n",
    "    b_paper_title = result['bib']['title']\n",
    "    b_paper_authors = ', '.join(result['bib']['author'])\n",
    "    break\n",
    "    if paper_compare(ref_paper_title, ref_paper_authors, b_paper_title, b_paper_authors) == 'YES':\n",
    "        citation_count = result.get('num_citations', 0)  # 인용수 가져오기\n",
    "        break\n",
    "    if cnt >= 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5deb09b4-07a4-4faf-8d1b-abcc3973d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PAPER_COMPARE_PROMPT.format(\n",
    "                a_paper_title=ref_paper_title,\n",
    "                a_paper_authors=ref_paper_authors,\n",
    "                b_paper_title=b_paper_title,  # 오타 수정\n",
    "                b_paper_authors=b_paper_authors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d010e177-21f4-4a54-bbad-c5572771a58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do the two papers refer to the same paper? If yes, answer YES; otherwise, answer NO.\n",
      "          \n",
      "          A paper title : Camel: Communicative agents for 'mind' exploration of large scale language model society\n",
      "          A paper authors : Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem\n",
      "          \n",
      "          B paper title : Camel: Communicative agents for\" mind\" exploration of large language model society\n",
      "          B paper authors : G Li, H Hammoud, H Itani\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "87caf484-ace6-4fd0-8f82-a54869b6920c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tYES\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "answer = response.choices[0].message.content\n",
    "print(f\"\\t{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4b97f0dc-7a04-4503-aa69-db3009749fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tref_paper_title : Language models are few-shot learners\n",
      "\tb_paper_title : Language models are few-shot learners\n",
      "[    38,863] [1] Language models are few-shot learners\n",
      "[None      ] [2] Trends in distributed artificial intelligence\n",
      "\tref_paper_title : Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents\n",
      "\tb_paper_title : Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents\n",
      "[       155] [3] Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents\n",
      "\tref_paper_title : Improving Factuality and Reasoning in Language Models through Multiagent Debate\n",
      "\tb_paper_title : Improving Factuality and Reasoning in Language Models through Multiagent Debate\n",
      "[       437] [4] Improving Factuality and Reasoning in Language Models through Multiagent Debate\n",
      "[None      ] [5] Recommender ai agent: Integrating large language models for interactive recommendations\n",
      "\tref_paper_title : Camel: Communicative agents for 'mind' exploration of large scale language model society\n",
      "\tb_paper_title : Camel: Communicative agents for 'mind' exploration of large scale language model society\n",
      "\tref_paper_title : Camel: Communicative agents for 'mind' exploration of large scale language model society\n",
      "\tb_paper_title : Camel: Communicative agents for 'mind' exploration of large scale language model society\n",
      "\tref_paper_title : Camel: Communicative agents for 'mind' exploration of large scale language model society\n",
      "\tb_paper_title : Camel: Communicative agents for 'mind' exploration of large scale language model society\n",
      "\tref_paper_title : Camel: Communicative agents for 'mind' exploration of large scale language model society\n",
      "\tb_paper_title : Camel: Communicative agents for 'mind' exploration of large scale language model society\n",
      "\tref_paper_title : Camel: Communicative agents for 'mind' exploration of large scale language model society\n",
      "\tb_paper_title : Camel: Communicative agents for 'mind' exploration of large scale language model society\n",
      "\tref_paper_title : Camel: Communicative agents for 'mind' exploration of large scale language model society\n",
      "\tb_paper_title : Camel: Communicative agents for 'mind' exploration of large scale language model society\n",
      "\tref_paper_title : Camel: Communicative agents for 'mind' exploration of large scale language model society\n",
      "\tb_paper_title : Camel: Communicative agents for 'mind' exploration of large scale language model society\n",
      "\tref_paper_title : Camel: Communicative agents for 'mind' exploration of large scale language model society\n",
      "\tb_paper_title : Camel: Communicative agents for 'mind' exploration of large scale language model society\n",
      "\tref_paper_title : Camel: Communicative agents for 'mind' exploration of large scale language model society\n",
      "\tb_paper_title : Camel: Communicative agents for 'mind' exploration of large scale language model society\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[138], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m ref_paper_title \u001b[38;5;241m=\u001b[39m one_ref_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m ref_paper_authors \u001b[38;5;241m=\u001b[39m one_ref_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAuthor(s)\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m citation_cnt \u001b[38;5;241m=\u001b[39m \u001b[43mget_citation_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_paper_title\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_paper_authors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m citation_cnt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcitation_cnt\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m10,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_paper_title\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[136], line 21\u001b[0m, in \u001b[0;36mget_citation_count\u001b[0;34m(ref_paper_title, ref_paper_authors, author)\u001b[0m\n\u001b[1;32m     19\u001b[0m b_paper_title \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbib\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     20\u001b[0m b_paper_authors \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbib\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpaper_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_paper_title\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_paper_authors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_paper_title\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_paper_authors\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYES\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     22\u001b[0m     citation_count \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_citations\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# 인용수 가져오기\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m citation_count\n",
      "Cell \u001b[0;32mIn[136], line 35\u001b[0m, in \u001b[0;36mpaper_compare\u001b[0;34m(ref_paper_title, ref_paper_authors, b_paper_title, b_paper_authors)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mref_paper_title : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_paper_title\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mb_paper_title : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb_paper_title\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PAPER_COMPARE_PROMPT\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     30\u001b[0m                 a_paper_title\u001b[38;5;241m=\u001b[39mref_paper_title,\n\u001b[1;32m     31\u001b[0m                 a_paper_authors\u001b[38;5;241m=\u001b[39mref_paper_authors,\n\u001b[1;32m     32\u001b[0m                 b_paper_title\u001b[38;5;241m=\u001b[39mb_paper_title,  \u001b[38;5;66;03m# 오타 수정\u001b[39;00m\n\u001b[1;32m     33\u001b[0m                 b_paper_authors\u001b[38;5;241m=\u001b[39mb_paper_authors\n\u001b[1;32m     34\u001b[0m )\n\u001b[0;32m---> 35\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/openai/resources/chat/completions.py:859\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    856\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    857\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    858\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/openai/_base_client.py:1283\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1271\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1279\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1280\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1281\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1282\u001b[0m     )\n\u001b[0;32m-> 1283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/openai/_base_client.py:960\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/openai/_base_client.py:996\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    993\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 996\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1002\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/.pyenv/versions/recom_paper_crawling/lib/python3.10/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.16/lib/python3.10/ssl.py:1292\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1290\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1291\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.16/lib/python3.10/ssl.py:1165\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, one_ref_info in ref_dict.items():\n",
    "    ref_paper_title = one_ref_info['Title']\n",
    "    ref_paper_authors = one_ref_info['Author(s)']\n",
    "    citation_cnt = get_citation_count(ref_paper_title, ref_paper_authors)\n",
    "    if citation_cnt is not None:\n",
    "        print(f\"[{citation_cnt:10,}] [{i}] {ref_paper_title}\")\n",
    "        ref_dict[i]['citation_count'] = {\n",
    "            'value' : citation_cnt,\n",
    "            'date' : datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "    else:\n",
    "        print(f\"[{'None':10}] [{i}] {ref_paper_title}\")\n",
    "        ref_dict[i]['citation_count'] = {\n",
    "            'value' : citation_cnt,\n",
    "            'date' : datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61e0017-fc4d-4294-a3a0-eb7bdb838545",
   "metadata": {},
   "source": [
    "# Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ae6e4cc-8db0-4b09-812a-adfd4671acdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Google Scholar 검색 URL\n",
    "query = \"recommendation\"\n",
    "url = f\"https://scholar.google.com/scholar?q={query}\"\n",
    "\n",
    "# 요청 헤더 설정 (실제 브라우저에서의 요청처럼 위장)\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# GET 요청 보내기\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# 상태 코드 확인\n",
    "if response.status_code == 200:\n",
    "    # HTML 파싱\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # 논문 제목과 관련 정보 추출\n",
    "    results = soup.select(\".gs_ri\")\n",
    "    for i, result in enumerate(results):\n",
    "        title = result.select_one(\".gs_rt\").text\n",
    "        authors_and_year = result.select_one(\".gs_a\").text\n",
    "        snippet = result.select_one(\".gs_rs\").text if result.select_one(\".gs_rs\") else \"No snippet available\"\n",
    "        link = result.select_one(\".gs_rt a\")[\"href\"] if result.select_one(\".gs_rt a\") else \"No link available\"\n",
    "\n",
    "        print(f\"Result {i+1}:\")\n",
    "        print(f\"Title: {title}\")\n",
    "        print(f\"Authors and Year: {authors_and_year}\")\n",
    "        print(f\"Snippet: {snippet}\")\n",
    "        print(f\"Link: {link}\")\n",
    "        print(\"-\" * 80)\n",
    "else:\n",
    "    print(f\"Failed to fetch the page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "331fcc6e-afaa-4de8-913b-d7bcb8bef5c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response saved to response.html. Open it in a browser to check if it's a Captcha page.\n"
     ]
    }
   ],
   "source": [
    "# 응답 HTML 저장 및 확인\n",
    "with open(\"response.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "print(\"Response saved to response.html. Open it in a browser to check if it's a Captcha page.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526eb4b8-0bce-4d0e-a215-ff645172193d",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a362ef7e-8661-491c-8b86-afc010800dd3",
   "metadata": {},
   "source": [
    "https://medium.com/kx-systems/rag-llamaparse-advanced-pdf-parsing-for-retrieval-c393ab29891b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recom_paper_crawling",
   "language": "python",
   "name": "recom_paper_crawling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
